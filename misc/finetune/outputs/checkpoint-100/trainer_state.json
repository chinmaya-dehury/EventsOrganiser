{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 12.533333333333333,
  "eval_steps": 20,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.7106937170028687,
      "learning_rate": 4e-05,
      "loss": 2.8983,
      "step": 1
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.7012939453125,
      "learning_rate": 8e-05,
      "loss": 2.7996,
      "step": 2
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7262578010559082,
      "learning_rate": 0.00012,
      "loss": 2.8272,
      "step": 3
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.7258148193359375,
      "learning_rate": 0.00016,
      "loss": 2.8419,
      "step": 4
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.7517582774162292,
      "learning_rate": 0.0002,
      "loss": 2.7181,
      "step": 5
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7253507971763611,
      "learning_rate": 0.00019789473684210526,
      "loss": 2.514,
      "step": 6
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.43326061964035034,
      "learning_rate": 0.00019578947368421054,
      "loss": 2.3101,
      "step": 7
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.36219140887260437,
      "learning_rate": 0.0001936842105263158,
      "loss": 2.3305,
      "step": 8
    },
    {
      "epoch": 1.1333333333333333,
      "grad_norm": 0.3845836818218231,
      "learning_rate": 0.00019157894736842104,
      "loss": 2.2162,
      "step": 9
    },
    {
      "epoch": 1.2666666666666666,
      "grad_norm": 0.435708224773407,
      "learning_rate": 0.00018947368421052632,
      "loss": 2.1394,
      "step": 10
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.45862746238708496,
      "learning_rate": 0.0001873684210526316,
      "loss": 2.0545,
      "step": 11
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 0.4544493556022644,
      "learning_rate": 0.00018526315789473685,
      "loss": 1.9945,
      "step": 12
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.4605497121810913,
      "learning_rate": 0.0001831578947368421,
      "loss": 2.0008,
      "step": 13
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.4523555338382721,
      "learning_rate": 0.00018105263157894739,
      "loss": 1.7664,
      "step": 14
    },
    {
      "epoch": 1.9333333333333333,
      "grad_norm": 0.48265767097473145,
      "learning_rate": 0.00017894736842105264,
      "loss": 1.782,
      "step": 15
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.4534353017807007,
      "learning_rate": 0.0001768421052631579,
      "loss": 1.647,
      "step": 16
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 0.5049903392791748,
      "learning_rate": 0.00017473684210526317,
      "loss": 1.5097,
      "step": 17
    },
    {
      "epoch": 2.2666666666666666,
      "grad_norm": 0.6246924996376038,
      "learning_rate": 0.00017263157894736842,
      "loss": 1.4648,
      "step": 18
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.5383219122886658,
      "learning_rate": 0.0001705263157894737,
      "loss": 1.3209,
      "step": 19
    },
    {
      "epoch": 2.533333333333333,
      "grad_norm": 0.4508473575115204,
      "learning_rate": 0.00016842105263157895,
      "loss": 1.2246,
      "step": 20
    },
    {
      "epoch": 2.533333333333333,
      "eval_loss": 1.2038135528564453,
      "eval_runtime": 27.0623,
      "eval_samples_per_second": 8.868,
      "eval_steps_per_second": 1.109,
      "step": 20
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.48748141527175903,
      "learning_rate": 0.00016631578947368423,
      "loss": 1.2111,
      "step": 21
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.41993725299835205,
      "learning_rate": 0.00016421052631578948,
      "loss": 1.1629,
      "step": 22
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 0.3100644648075104,
      "learning_rate": 0.00016210526315789473,
      "loss": 1.2254,
      "step": 23
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2951701581478119,
      "learning_rate": 0.00016,
      "loss": 1.086,
      "step": 24
    },
    {
      "epoch": 3.1333333333333333,
      "grad_norm": 0.308882474899292,
      "learning_rate": 0.00015789473684210527,
      "loss": 1.0741,
      "step": 25
    },
    {
      "epoch": 3.2666666666666666,
      "grad_norm": 0.21015754342079163,
      "learning_rate": 0.00015578947368421052,
      "loss": 1.0325,
      "step": 26
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.18019290268421173,
      "learning_rate": 0.0001536842105263158,
      "loss": 1.1203,
      "step": 27
    },
    {
      "epoch": 3.533333333333333,
      "grad_norm": 0.18074744939804077,
      "learning_rate": 0.00015157894736842108,
      "loss": 0.9486,
      "step": 28
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 0.20488905906677246,
      "learning_rate": 0.00014947368421052633,
      "loss": 1.0684,
      "step": 29
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.1837800145149231,
      "learning_rate": 0.00014736842105263158,
      "loss": 1.0161,
      "step": 30
    },
    {
      "epoch": 3.9333333333333336,
      "grad_norm": 0.17107553780078888,
      "learning_rate": 0.00014526315789473686,
      "loss": 1.03,
      "step": 31
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2306700497865677,
      "learning_rate": 0.0001431578947368421,
      "loss": 1.025,
      "step": 32
    },
    {
      "epoch": 4.133333333333334,
      "grad_norm": 0.18238390982151031,
      "learning_rate": 0.00014105263157894736,
      "loss": 0.9436,
      "step": 33
    },
    {
      "epoch": 4.266666666666667,
      "grad_norm": 0.16364015638828278,
      "learning_rate": 0.00013894736842105264,
      "loss": 0.934,
      "step": 34
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.1651875376701355,
      "learning_rate": 0.0001368421052631579,
      "loss": 0.932,
      "step": 35
    },
    {
      "epoch": 4.533333333333333,
      "grad_norm": 0.16663792729377747,
      "learning_rate": 0.00013473684210526317,
      "loss": 1.0266,
      "step": 36
    },
    {
      "epoch": 4.666666666666667,
      "grad_norm": 0.19697558879852295,
      "learning_rate": 0.00013263157894736842,
      "loss": 1.0439,
      "step": 37
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.19286572933197021,
      "learning_rate": 0.0001305263157894737,
      "loss": 0.9285,
      "step": 38
    },
    {
      "epoch": 4.933333333333334,
      "grad_norm": 0.19563454389572144,
      "learning_rate": 0.00012842105263157895,
      "loss": 0.9833,
      "step": 39
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.22922442853450775,
      "learning_rate": 0.0001263157894736842,
      "loss": 1.0072,
      "step": 40
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.9323152899742126,
      "eval_runtime": 26.2882,
      "eval_samples_per_second": 9.13,
      "eval_steps_per_second": 1.141,
      "step": 40
    },
    {
      "epoch": 5.133333333333334,
      "grad_norm": 0.18080854415893555,
      "learning_rate": 0.00012421052631578949,
      "loss": 0.9257,
      "step": 41
    },
    {
      "epoch": 5.266666666666667,
      "grad_norm": 0.183699369430542,
      "learning_rate": 0.00012210526315789474,
      "loss": 1.0017,
      "step": 42
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.22119267284870148,
      "learning_rate": 0.00012,
      "loss": 0.8982,
      "step": 43
    },
    {
      "epoch": 5.533333333333333,
      "grad_norm": 0.22809329628944397,
      "learning_rate": 0.00011789473684210525,
      "loss": 0.8535,
      "step": 44
    },
    {
      "epoch": 5.666666666666667,
      "grad_norm": 0.20254842936992645,
      "learning_rate": 0.00011578947368421053,
      "loss": 0.939,
      "step": 45
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.2184932827949524,
      "learning_rate": 0.0001136842105263158,
      "loss": 0.9071,
      "step": 46
    },
    {
      "epoch": 5.933333333333334,
      "grad_norm": 0.17561689019203186,
      "learning_rate": 0.00011157894736842105,
      "loss": 0.9552,
      "step": 47
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2706286609172821,
      "learning_rate": 0.00010947368421052633,
      "loss": 0.995,
      "step": 48
    },
    {
      "epoch": 6.133333333333334,
      "grad_norm": 12.095450401306152,
      "learning_rate": 0.00010736842105263158,
      "loss": 0.928,
      "step": 49
    },
    {
      "epoch": 6.266666666666667,
      "grad_norm": 0.46879705786705017,
      "learning_rate": 0.00010526315789473685,
      "loss": 0.8739,
      "step": 50
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.41385093331336975,
      "learning_rate": 0.00010315789473684211,
      "loss": 0.8391,
      "step": 51
    },
    {
      "epoch": 6.533333333333333,
      "grad_norm": 0.29556167125701904,
      "learning_rate": 0.00010105263157894738,
      "loss": 0.8707,
      "step": 52
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.24604085087776184,
      "learning_rate": 9.894736842105263e-05,
      "loss": 0.8797,
      "step": 53
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.2218758761882782,
      "learning_rate": 9.68421052631579e-05,
      "loss": 0.8639,
      "step": 54
    },
    {
      "epoch": 6.933333333333334,
      "grad_norm": 0.2179049700498581,
      "learning_rate": 9.473684210526316e-05,
      "loss": 0.8517,
      "step": 55
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.28068873286247253,
      "learning_rate": 9.263157894736843e-05,
      "loss": 0.9341,
      "step": 56
    },
    {
      "epoch": 7.133333333333334,
      "grad_norm": 0.2005329728126526,
      "learning_rate": 9.052631578947369e-05,
      "loss": 0.7919,
      "step": 57
    },
    {
      "epoch": 7.266666666666667,
      "grad_norm": 0.2019500881433487,
      "learning_rate": 8.842105263157894e-05,
      "loss": 0.8597,
      "step": 58
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.21114708483219147,
      "learning_rate": 8.631578947368421e-05,
      "loss": 0.8605,
      "step": 59
    },
    {
      "epoch": 7.533333333333333,
      "grad_norm": 0.19184833765029907,
      "learning_rate": 8.421052631578948e-05,
      "loss": 0.8533,
      "step": 60
    },
    {
      "epoch": 7.533333333333333,
      "eval_loss": 0.7983059287071228,
      "eval_runtime": 27.8652,
      "eval_samples_per_second": 8.613,
      "eval_steps_per_second": 1.077,
      "step": 60
    },
    {
      "epoch": 7.666666666666667,
      "grad_norm": 0.24438387155532837,
      "learning_rate": 8.210526315789474e-05,
      "loss": 0.7824,
      "step": 61
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.2101765125989914,
      "learning_rate": 8e-05,
      "loss": 0.7968,
      "step": 62
    },
    {
      "epoch": 7.933333333333334,
      "grad_norm": 0.22268976271152496,
      "learning_rate": 7.789473684210526e-05,
      "loss": 0.77,
      "step": 63
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.2683155834674835,
      "learning_rate": 7.578947368421054e-05,
      "loss": 0.7977,
      "step": 64
    },
    {
      "epoch": 8.133333333333333,
      "grad_norm": 0.23010936379432678,
      "learning_rate": 7.368421052631579e-05,
      "loss": 0.7756,
      "step": 65
    },
    {
      "epoch": 8.266666666666667,
      "grad_norm": 0.20737028121948242,
      "learning_rate": 7.157894736842105e-05,
      "loss": 0.7194,
      "step": 66
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.22417251765727997,
      "learning_rate": 6.947368421052632e-05,
      "loss": 0.7531,
      "step": 67
    },
    {
      "epoch": 8.533333333333333,
      "grad_norm": 0.23329314589500427,
      "learning_rate": 6.736842105263159e-05,
      "loss": 0.7861,
      "step": 68
    },
    {
      "epoch": 8.666666666666666,
      "grad_norm": 0.22585701942443848,
      "learning_rate": 6.526315789473685e-05,
      "loss": 0.7922,
      "step": 69
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.25690850615501404,
      "learning_rate": 6.31578947368421e-05,
      "loss": 0.7632,
      "step": 70
    },
    {
      "epoch": 8.933333333333334,
      "grad_norm": 0.25897321105003357,
      "learning_rate": 6.105263157894737e-05,
      "loss": 0.7159,
      "step": 71
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.2876266539096832,
      "learning_rate": 5.894736842105263e-05,
      "loss": 0.8254,
      "step": 72
    },
    {
      "epoch": 9.133333333333333,
      "grad_norm": 0.22148354351520538,
      "learning_rate": 5.68421052631579e-05,
      "loss": 0.7571,
      "step": 73
    },
    {
      "epoch": 9.266666666666667,
      "grad_norm": 0.21893131732940674,
      "learning_rate": 5.4736842105263165e-05,
      "loss": 0.7517,
      "step": 74
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.24531477689743042,
      "learning_rate": 5.2631578947368424e-05,
      "loss": 0.7141,
      "step": 75
    },
    {
      "epoch": 9.533333333333333,
      "grad_norm": 893.3094482421875,
      "learning_rate": 5.052631578947369e-05,
      "loss": 0.6884,
      "step": 76
    },
    {
      "epoch": 9.666666666666666,
      "grad_norm": 0.7052178978919983,
      "learning_rate": 4.842105263157895e-05,
      "loss": 0.7207,
      "step": 77
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.3673896789550781,
      "learning_rate": 4.6315789473684214e-05,
      "loss": 0.6842,
      "step": 78
    },
    {
      "epoch": 9.933333333333334,
      "grad_norm": 0.37174156308174133,
      "learning_rate": 4.421052631578947e-05,
      "loss": 0.7319,
      "step": 79
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.44256138801574707,
      "learning_rate": 4.210526315789474e-05,
      "loss": 0.7223,
      "step": 80
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.6885576248168945,
      "eval_runtime": 26.2626,
      "eval_samples_per_second": 9.138,
      "eval_steps_per_second": 1.142,
      "step": 80
    },
    {
      "epoch": 10.133333333333333,
      "grad_norm": 0.3133507966995239,
      "learning_rate": 4e-05,
      "loss": 0.6971,
      "step": 81
    },
    {
      "epoch": 10.266666666666667,
      "grad_norm": 0.2522042393684387,
      "learning_rate": 3.789473684210527e-05,
      "loss": 0.6981,
      "step": 82
    },
    {
      "epoch": 10.4,
      "grad_norm": 0.23846003413200378,
      "learning_rate": 3.578947368421053e-05,
      "loss": 0.6735,
      "step": 83
    },
    {
      "epoch": 10.533333333333333,
      "grad_norm": 0.2292059361934662,
      "learning_rate": 3.368421052631579e-05,
      "loss": 0.6684,
      "step": 84
    },
    {
      "epoch": 10.666666666666666,
      "grad_norm": 0.22770553827285767,
      "learning_rate": 3.157894736842105e-05,
      "loss": 0.7001,
      "step": 85
    },
    {
      "epoch": 10.8,
      "grad_norm": 0.2790447771549225,
      "learning_rate": 2.9473684210526314e-05,
      "loss": 0.7126,
      "step": 86
    },
    {
      "epoch": 10.933333333333334,
      "grad_norm": 0.2291228473186493,
      "learning_rate": 2.7368421052631583e-05,
      "loss": 0.6568,
      "step": 87
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.3978552222251892,
      "learning_rate": 2.5263157894736845e-05,
      "loss": 0.6627,
      "step": 88
    },
    {
      "epoch": 11.133333333333333,
      "grad_norm": 69.6046142578125,
      "learning_rate": 2.3157894736842107e-05,
      "loss": 0.7126,
      "step": 89
    },
    {
      "epoch": 11.266666666666667,
      "grad_norm": 0.2546389400959015,
      "learning_rate": 2.105263157894737e-05,
      "loss": 0.6121,
      "step": 90
    },
    {
      "epoch": 11.4,
      "grad_norm": 0.22329171001911163,
      "learning_rate": 1.8947368421052634e-05,
      "loss": 0.6632,
      "step": 91
    },
    {
      "epoch": 11.533333333333333,
      "grad_norm": 0.2215619683265686,
      "learning_rate": 1.6842105263157896e-05,
      "loss": 0.7041,
      "step": 92
    },
    {
      "epoch": 11.666666666666666,
      "grad_norm": 0.25999215245246887,
      "learning_rate": 1.4736842105263157e-05,
      "loss": 0.6753,
      "step": 93
    },
    {
      "epoch": 11.8,
      "grad_norm": 0.2602508068084717,
      "learning_rate": 1.2631578947368422e-05,
      "loss": 0.6422,
      "step": 94
    },
    {
      "epoch": 11.933333333333334,
      "grad_norm": 0.2571133077144623,
      "learning_rate": 1.0526315789473684e-05,
      "loss": 0.6418,
      "step": 95
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.29800114035606384,
      "learning_rate": 8.421052631578948e-06,
      "loss": 0.622,
      "step": 96
    },
    {
      "epoch": 12.133333333333333,
      "grad_norm": 0.2267361432313919,
      "learning_rate": 6.315789473684211e-06,
      "loss": 0.6674,
      "step": 97
    },
    {
      "epoch": 12.266666666666667,
      "grad_norm": 0.22082549333572388,
      "learning_rate": 4.210526315789474e-06,
      "loss": 0.6576,
      "step": 98
    },
    {
      "epoch": 12.4,
      "grad_norm": 0.22268588840961456,
      "learning_rate": 2.105263157894737e-06,
      "loss": 0.6327,
      "step": 99
    },
    {
      "epoch": 12.533333333333333,
      "grad_norm": 0.21426922082901,
      "learning_rate": 0.0,
      "loss": 0.6652,
      "step": 100
    },
    {
      "epoch": 12.533333333333333,
      "eval_loss": 0.6438269019126892,
      "eval_runtime": 26.137,
      "eval_samples_per_second": 9.182,
      "eval_steps_per_second": 1.148,
      "step": 100
    }
  ],
  "logging_steps": 1,
  "max_steps": 100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.25430470695977e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
