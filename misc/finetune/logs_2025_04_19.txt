C:\Python312\python.exe: can't open file 'C:\\Users\\madis\\Desktop\\Ãœlikooli asjad\\EventsOrganiser\\EventsOrganiser\\misc\\finetune\\fine': [Errno 2] No such file or directory
PS C:\Users\madis\Desktop\Ãœlikooli asjad\EventsOrganiser\EventsOrganiser\misc\finetune> py .\finetune.py
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
C:\Python312\Lib\site-packages\unsloth_zoo\gradient_checkpointing.py:330: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f"cuda:{i}") for i in range(n_gpus)])
==((====))==  Unsloth 2025.3.17: Fast Llama patching. Transformers: 4.49.0.
   \\   /|    NVIDIA GeForce RTX 3090. Num GPUs = 1. Max memory: 24.0 GB. Platform: Windows.
O^O/ \_/ \    Torch: 2.6.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.2.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:06<00:00,  3.21s/it]
./trainable_llm/llama3.2-3b-instruct does not have a padding token! Will use pad_token = <|finetune_right_pad_id|>.
Unsloth: Making `model.base_model.model.model` require gradients
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00<00:00, 2847.16 examples/s]
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00<00:00, 9002.15 examples/s]
Unsloth: We found double BOS tokens - we shall remove one automatically.
Unsloth: Tokenizing ["text"] (num_proc=16):   0%|                                        | 0/90 [00:00<?, ? examples/s]ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Unsloth: Tokenizing ["text"] (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:26<00:00,  3.44 examples/s]
Unsloth: We found double BOS tokens - we shall remove one automatically.
Unsloth: Tokenizing ["text"] (num_proc=16):   0%|                                        | 0/90 [00:00<?, ? examples/s]ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Unsloth: Tokenizing ["text"] (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:25<00:00,  3.49 examples/s]
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 90 | Num Epochs = 100 | Total steps = 300
O^O/ \_/ \    Batch size per device = 8 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32
 "-____-"     Trainable parameters = 24,313,856/3,237,063,680 (0.75% trained)
  0%|                                                                                          | 0/300 [00:00<?, ?it/s]Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 2.6198, 'grad_norm': 0.4870617091655731, 'learning_rate': 0.00019933333333333334, 'epoch': 0.33}
{'loss': 2.7398, 'grad_norm': 0.6313886642456055, 'learning_rate': 0.00019866666666666668, 'epoch': 0.67}
{'loss': 2.4863, 'grad_norm': 14.83969497680664, 'learning_rate': 0.00019800000000000002, 'epoch': 1.0}
  1%|â–Š                                                                               | 3/300 [03:38<5:33:00, 67.27s/it]Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.
Using gradient accumulation will be very slightly less accurate.
Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient
{'eval_loss': 2.457242012023926, 'eval_runtime': 38.198, 'eval_samples_per_second': 2.356, 'eval_steps_per_second': 0.314, 'epoch': 1.0}
{'loss': 2.4817, 'grad_norm': 0.41754287481307983, 'learning_rate': 0.00019733333333333335, 'epoch': 1.33}
{'loss': 2.49, 'grad_norm': 0.2995349168777466, 'learning_rate': 0.00019666666666666666, 'epoch': 1.67}
{'loss': 2.2065, 'grad_norm': 0.22045399248600006, 'learning_rate': 0.000196, 'epoch': 2.0}
{'eval_loss': 2.3157267570495605, 'eval_runtime': 32.7222, 'eval_samples_per_second': 2.75, 'eval_steps_per_second': 0.367, 'epoch': 2.0}
{'loss': 2.3044, 'grad_norm': 0.28651976585388184, 'learning_rate': 0.00019533333333333336, 'epoch': 2.33}
{'loss': 2.1463, 'grad_norm': 0.2656219005584717, 'learning_rate': 0.0001946666666666667, 'epoch': 2.67}
{'loss': 2.3509, 'grad_norm': 0.2977295219898224, 'learning_rate': 0.000194, 'epoch': 3.0}
{'eval_loss': 2.1600608825683594, 'eval_runtime': 32.3697, 'eval_samples_per_second': 2.78, 'eval_steps_per_second': 0.371, 'epoch': 3.0}
{'loss': 2.2124, 'grad_norm': 0.2868539094924927, 'learning_rate': 0.00019333333333333333, 'epoch': 3.33}
{'loss': 2.137, 'grad_norm': 0.2879526615142822, 'learning_rate': 0.0001926666666666667, 'epoch': 3.67}
{'loss': 1.9216, 'grad_norm': 0.27521753311157227, 'learning_rate': 0.000192, 'epoch': 4.0}
{'eval_loss': 1.973442554473877, 'eval_runtime': 32.3574, 'eval_samples_per_second': 2.781, 'eval_steps_per_second': 0.371, 'epoch': 4.0}
{'loss': 1.9568, 'grad_norm': 0.32061728835105896, 'learning_rate': 0.00019133333333333334, 'epoch': 4.33}
{'loss': 1.9747, 'grad_norm': 0.30692487955093384, 'learning_rate': 0.00019066666666666668, 'epoch': 4.67}
{'loss': 1.7826, 'grad_norm': 0.3045295774936676, 'learning_rate': 0.00019, 'epoch': 5.0}
{'eval_loss': 1.7505351305007935, 'eval_runtime': 32.3812, 'eval_samples_per_second': 2.779, 'eval_steps_per_second': 0.371, 'epoch': 5.0}
{'loss': 1.7098, 'grad_norm': 0.3851480782032013, 'learning_rate': 0.00018933333333333335, 'epoch': 5.33}
{'loss': 1.7323, 'grad_norm': 0.5336425304412842, 'learning_rate': 0.00018866666666666668, 'epoch': 5.67}
{'loss': 1.6087, 'grad_norm': 0.41305044293403625, 'learning_rate': 0.000188, 'epoch': 6.0}
{'eval_loss': 1.545835256576538, 'eval_runtime': 32.3705, 'eval_samples_per_second': 2.78, 'eval_steps_per_second': 0.371, 'epoch': 6.0}
{'loss': 1.5472, 'grad_norm': 0.364044189453125, 'learning_rate': 0.00018733333333333335, 'epoch': 6.33}
{'loss': 1.548, 'grad_norm': 0.31727519631385803, 'learning_rate': 0.0001866666666666667, 'epoch': 6.67}
{'loss': 1.4211, 'grad_norm': 0.3956678807735443, 'learning_rate': 0.00018600000000000002, 'epoch': 7.0}
{'eval_loss': 1.4109171628952026, 'eval_runtime': 32.3656, 'eval_samples_per_second': 2.781, 'eval_steps_per_second': 0.371, 'epoch': 7.0}
{'loss': 1.3161, 'grad_norm': 0.28208214044570923, 'learning_rate': 0.00018533333333333333, 'epoch': 7.33}
{'loss': 1.4457, 'grad_norm': 0.23377083241939545, 'learning_rate': 0.00018466666666666666, 'epoch': 7.67}
{'loss': 1.4592, 'grad_norm': 5.98023796081543, 'learning_rate': 0.00018400000000000003, 'epoch': 8.0}
{'eval_loss': 1.3581140041351318, 'eval_runtime': 32.3593, 'eval_samples_per_second': 2.781, 'eval_steps_per_second': 0.371, 'epoch': 8.0}
{'loss': 1.3891, 'grad_norm': 0.29045370221138, 'learning_rate': 0.00018333333333333334, 'epoch': 8.33}
{'loss': 1.3029, 'grad_norm': 0.2585259675979614, 'learning_rate': 0.00018266666666666667, 'epoch': 8.67}
{'loss': 1.396, 'grad_norm': 0.19544993340969086, 'learning_rate': 0.000182, 'epoch': 9.0}
{'eval_loss': 1.3098039627075195, 'eval_runtime': 32.246, 'eval_samples_per_second': 2.791, 'eval_steps_per_second': 0.372, 'epoch': 9.0}
{'loss': 1.4369, 'grad_norm': 0.2136174589395523, 'learning_rate': 0.00018133333333333334, 'epoch': 9.33}
{'loss': 1.2379, 'grad_norm': 0.22762498259544373, 'learning_rate': 0.00018066666666666668, 'epoch': 9.67}
{'loss': 1.2356, 'grad_norm': 0.1845218390226364, 'learning_rate': 0.00018, 'epoch': 10.0}
{'eval_loss': 1.2702085971832275, 'eval_runtime': 32.2479, 'eval_samples_per_second': 2.791, 'eval_steps_per_second': 0.372, 'epoch': 10.0}
{'loss': 1.2707, 'grad_norm': 0.25407978892326355, 'learning_rate': 0.00017933333333333332, 'epoch': 10.33}
{'loss': 1.2363, 'grad_norm': 0.20105543732643127, 'learning_rate': 0.00017866666666666668, 'epoch': 10.67}
{'loss': 1.3466, 'grad_norm': 0.18127159774303436, 'learning_rate': 0.00017800000000000002, 'epoch': 11.0}
{'eval_loss': 1.2471330165863037, 'eval_runtime': 32.2545, 'eval_samples_per_second': 2.79, 'eval_steps_per_second': 0.372, 'epoch': 11.0}
{'loss': 1.2651, 'grad_norm': 0.25059956312179565, 'learning_rate': 0.00017733333333333335, 'epoch': 11.33}
{'loss': 1.2293, 'grad_norm': 0.16429908573627472, 'learning_rate': 0.00017666666666666666, 'epoch': 11.67}
{'loss': 1.3066, 'grad_norm': 0.22289742529392242, 'learning_rate': 0.00017600000000000002, 'epoch': 12.0}
{'eval_loss': 1.232367753982544, 'eval_runtime': 32.2319, 'eval_samples_per_second': 2.792, 'eval_steps_per_second': 0.372, 'epoch': 12.0}
{'loss': 1.2498, 'grad_norm': 0.22253313660621643, 'learning_rate': 0.00017533333333333336, 'epoch': 12.33}
{'loss': 1.2203, 'grad_norm': 0.18339644372463226, 'learning_rate': 0.00017466666666666667, 'epoch': 12.67}
{'loss': 1.2767, 'grad_norm': 0.19155997037887573, 'learning_rate': 0.000174, 'epoch': 13.0}
{'eval_loss': 1.2090082168579102, 'eval_runtime': 32.2404, 'eval_samples_per_second': 2.792, 'eval_steps_per_second': 0.372, 'epoch': 13.0}
{'loss': 1.2012, 'grad_norm': 0.23845817148685455, 'learning_rate': 0.00017333333333333334, 'epoch': 13.33}
{'loss': 1.1964, 'grad_norm': 0.16567035019397736, 'learning_rate': 0.00017266666666666667, 'epoch': 13.67}
{'loss': 1.2754, 'grad_norm': 0.27136296033859253, 'learning_rate': 0.000172, 'epoch': 14.0}
{'eval_loss': 1.182205319404602, 'eval_runtime': 32.2413, 'eval_samples_per_second': 2.791, 'eval_steps_per_second': 0.372, 'epoch': 14.0}
{'loss': 1.2598, 'grad_norm': 0.18228887021541595, 'learning_rate': 0.00017133333333333334, 'epoch': 14.33}
{'loss': 1.1426, 'grad_norm': 0.18758545815944672, 'learning_rate': 0.00017066666666666668, 'epoch': 14.67}
{'loss': 1.1675, 'grad_norm': 0.23523187637329102, 'learning_rate': 0.00017, 'epoch': 15.0}
{'eval_loss': 1.1498196125030518, 'eval_runtime': 32.2247, 'eval_samples_per_second': 2.793, 'eval_steps_per_second': 0.372, 'epoch': 15.0}
{'loss': 1.1437, 'grad_norm': 0.1486344039440155, 'learning_rate': 0.00016933333333333335, 'epoch': 15.33}
{'loss': 1.2415, 'grad_norm': 0.2082923948764801, 'learning_rate': 0.00016866666666666668, 'epoch': 15.67}
{'loss': 1.091, 'grad_norm': 0.2872529625892639, 'learning_rate': 0.000168, 'epoch': 16.0}
{'eval_loss': 1.1198655366897583, 'eval_runtime': 32.2427, 'eval_samples_per_second': 2.791, 'eval_steps_per_second': 0.372, 'epoch': 16.0}
{'loss': 1.2183, 'grad_norm': 0.1625719517469406, 'learning_rate': 0.00016733333333333335, 'epoch': 16.33}
{'loss': 1.0194, 'grad_norm': 0.24397000670433044, 'learning_rate': 0.0001666666666666667, 'epoch': 16.67}
{'loss': 1.1536, 'grad_norm': 0.21548020839691162, 'learning_rate': 0.000166, 'epoch': 17.0}
{'eval_loss': 1.092574954032898, 'eval_runtime': 32.2333, 'eval_samples_per_second': 2.792, 'eval_steps_per_second': 0.372, 'epoch': 17.0}
{'loss': 1.0928, 'grad_norm': 0.18732109665870667, 'learning_rate': 0.00016533333333333333, 'epoch': 17.33}
{'loss': 1.1524, 'grad_norm': 0.18956811726093292, 'learning_rate': 0.00016466666666666667, 'epoch': 17.67}
{'loss': 1.0568, 'grad_norm': 0.2873668968677521, 'learning_rate': 0.000164, 'epoch': 18.0}
{'eval_loss': 1.0646895170211792, 'eval_runtime': 32.2384, 'eval_samples_per_second': 2.792, 'eval_steps_per_second': 0.372, 'epoch': 18.0}
{'loss': 1.0406, 'grad_norm': 0.1773909479379654, 'learning_rate': 0.00016333333333333334, 'epoch': 18.33}
{'loss': 1.1784, 'grad_norm': 0.23471896350383759, 'learning_rate': 0.00016266666666666667, 'epoch': 18.67}
{'loss': 0.988, 'grad_norm': 0.2764715254306793, 'learning_rate': 0.000162, 'epoch': 19.0}
{'eval_loss': 1.0405336618423462, 'eval_runtime': 32.2484, 'eval_samples_per_second': 2.791, 'eval_steps_per_second': 0.372, 'epoch': 19.0}
{'loss': 1.097, 'grad_norm': 0.2389945536851883, 'learning_rate': 0.00016133333333333334, 'epoch': 19.33}
{'loss': 1.0552, 'grad_norm': 0.20931559801101685, 'learning_rate': 0.00016066666666666668, 'epoch': 19.67}
{'loss': 0.9999, 'grad_norm': 0.2581934630870819, 'learning_rate': 0.00016, 'epoch': 20.0}
{'eval_loss': 1.012036681175232, 'eval_runtime': 32.2346, 'eval_samples_per_second': 2.792, 'eval_steps_per_second': 0.372, 'epoch': 20.0}
{'loss': 1.0038, 'grad_norm': 0.213041752576828, 'learning_rate': 0.00015933333333333332, 'epoch': 20.33}
{'loss': 1.0784, 'grad_norm': 0.27953872084617615, 'learning_rate': 0.00015866666666666668, 'epoch': 20.67}
{'loss': 0.9658, 'grad_norm': 0.25789517164230347, 'learning_rate': 0.00015800000000000002, 'epoch': 21.0}
{'eval_loss': 0.9837474226951599, 'eval_runtime': 32.2504, 'eval_samples_per_second': 2.791, 'eval_steps_per_second': 0.372, 'epoch': 21.0}
{'loss': 1.0437, 'grad_norm': 0.2253243774175644, 'learning_rate': 0.00015733333333333333, 'epoch': 21.33}
{'loss': 0.9979, 'grad_norm': 30.780725479125977, 'learning_rate': 0.00015666666666666666, 'epoch': 21.67}
{'loss': 0.9385, 'grad_norm': 0.38443562388420105, 'learning_rate': 0.00015600000000000002, 'epoch': 22.0}
{'eval_loss': 0.9658518433570862, 'eval_runtime': 32.2526, 'eval_samples_per_second': 2.79, 'eval_steps_per_second': 0.372, 'epoch': 22.0}
{'loss': 0.9207, 'grad_norm': 0.31586721539497375, 'learning_rate': 0.00015533333333333333, 'epoch': 22.33}
{'loss': 1.0553, 'grad_norm': 25.74334144592285, 'learning_rate': 0.00015466666666666667, 'epoch': 22.67}
{'loss': 0.9528, 'grad_norm': 0.9406254887580872, 'learning_rate': 0.000154, 'epoch': 23.0}
{'eval_loss': 0.948063850402832, 'eval_runtime': 32.2428, 'eval_samples_per_second': 2.791, 'eval_steps_per_second': 0.372, 'epoch': 23.0}
{'loss': 1.0497, 'grad_norm': 0.4439585208892822, 'learning_rate': 0.00015333333333333334, 'epoch': 23.33}
{'loss': 0.9195, 'grad_norm': 0.3397527039051056, 'learning_rate': 0.00015266666666666667, 'epoch': 23.67}
{'loss': 0.9042, 'grad_norm': 0.36607515811920166, 'learning_rate': 0.000152, 'epoch': 24.0}
{'eval_loss': 0.9348552227020264, 'eval_runtime': 32.2352, 'eval_samples_per_second': 2.792, 'eval_steps_per_second': 0.372, 'epoch': 24.0}
{'loss': 0.9083, 'grad_norm': 0.4295697808265686, 'learning_rate': 0.00015133333333333334, 'epoch': 24.33}
{'loss': 1.0628, 'grad_norm': 0.26381397247314453, 'learning_rate': 0.00015066666666666668, 'epoch': 24.67}
{'loss': 0.8104, 'grad_norm': 0.38502204418182373, 'learning_rate': 0.00015000000000000001, 'epoch': 25.0}
{'eval_loss': 0.9025734663009644, 'eval_runtime': 32.2334, 'eval_samples_per_second': 2.792, 'eval_steps_per_second': 0.372, 'epoch': 25.0}
{'loss': 0.8732, 'grad_norm': 0.34973251819610596, 'learning_rate': 0.00014933333333333335, 'epoch': 25.33}
{'loss': 0.8945, 'grad_norm': 0.5033867359161377, 'learning_rate': 0.00014866666666666666, 'epoch': 25.67}
{'loss': 0.99, 'grad_norm': 0.2976767122745514, 'learning_rate': 0.000148, 'epoch': 26.0}
{'eval_loss': 0.8820977210998535, 'eval_runtime': 32.2357, 'eval_samples_per_second': 2.792, 'eval_steps_per_second': 0.372, 'epoch': 26.0}
{'loss': 0.935, 'grad_norm': 0.3896854519844055, 'learning_rate': 0.00014733333333333335, 'epoch': 26.33}
{'loss': 0.8668, 'grad_norm': 0.37020304799079895, 'learning_rate': 0.00014666666666666666, 'epoch': 26.67}
{'loss': 0.8668, 'grad_norm': 0.31627312302589417, 'learning_rate': 0.000146, 'epoch': 27.0}
{'eval_loss': 0.8557976484298706, 'eval_runtime': 32.23, 'eval_samples_per_second': 2.792, 'eval_steps_per_second': 0.372, 'epoch': 27.0}
{'loss': 0.9789, 'grad_norm': 0.3535858988761902, 'learning_rate': 0.00014533333333333333, 'epoch': 27.33}
{'loss': 0.82, 'grad_norm': 0.30969923734664917, 'learning_rate': 0.0001446666666666667, 'epoch': 27.67}
{'loss': 0.7403, 'grad_norm': 0.46634361147880554, 'learning_rate': 0.000144, 'epoch': 28.0}
{'eval_loss': 0.8326594233512878, 'eval_runtime': 32.3303, 'eval_samples_per_second': 2.784, 'eval_steps_per_second': 0.371, 'epoch': 28.0}
{'loss': 0.8593, 'grad_norm': 0.40124139189720154, 'learning_rate': 0.00014333333333333334, 'epoch': 28.33}
{'loss': 0.8359, 'grad_norm': 0.33559757471084595, 'learning_rate': 0.00014266666666666667, 'epoch': 28.67}
{'loss': 0.8276, 'grad_norm': 0.38036829233169556, 'learning_rate': 0.000142, 'epoch': 29.0}
{'eval_loss': 0.8085922002792358, 'eval_runtime': 32.3009, 'eval_samples_per_second': 2.786, 'eval_steps_per_second': 0.372, 'epoch': 29.0}
{'loss': 0.8552, 'grad_norm': 0.32868263125419617, 'learning_rate': 0.00014133333333333334, 'epoch': 29.33}
{'loss': 0.7706, 'grad_norm': 0.4624914824962616, 'learning_rate': 0.00014066666666666668, 'epoch': 29.67}
{'loss': 0.8195, 'grad_norm': 0.3750612735748291, 'learning_rate': 0.00014, 'epoch': 30.0}
{'eval_loss': 0.7857685685157776, 'eval_runtime': 32.5701, 'eval_samples_per_second': 2.763, 'eval_steps_per_second': 0.368, 'epoch': 30.0}
{'loss': 0.9008, 'grad_norm': 0.38388577103614807, 'learning_rate': 0.00013933333333333335, 'epoch': 30.33}
{'loss': 0.6935, 'grad_norm': 0.392039954662323, 'learning_rate': 0.00013866666666666669, 'epoch': 30.67}
{'loss': 0.767, 'grad_norm': 0.6287580132484436, 'learning_rate': 0.000138, 'epoch': 31.0}
{'eval_loss': 0.7602939009666443, 'eval_runtime': 32.323, 'eval_samples_per_second': 2.784, 'eval_steps_per_second': 0.371, 'epoch': 31.0}
{'loss': 0.8422, 'grad_norm': 0.33938780426979065, 'learning_rate': 0.00013733333333333333, 'epoch': 31.33}
{'loss': 0.6794, 'grad_norm': 0.5848956108093262, 'learning_rate': 0.00013666666666666666, 'epoch': 31.67}
{'loss': 0.7661, 'grad_norm': 0.3852609097957611, 'learning_rate': 0.00013600000000000003, 'epoch': 32.0}
{'eval_loss': 0.7391510605812073, 'eval_runtime': 32.3356, 'eval_samples_per_second': 2.783, 'eval_steps_per_second': 0.371, 'epoch': 32.0}
{'loss': 0.7935, 'grad_norm': 0.36071377992630005, 'learning_rate': 0.00013533333333333333, 'epoch': 32.33}
{'loss': 0.7219, 'grad_norm': 0.4656851291656494, 'learning_rate': 0.00013466666666666667, 'epoch': 32.67}
{'loss': 0.6971, 'grad_norm': 0.7217285633087158, 'learning_rate': 0.000134, 'epoch': 33.0}
{'eval_loss': 0.7172203063964844, 'eval_runtime': 32.6536, 'eval_samples_per_second': 2.756, 'eval_steps_per_second': 0.367, 'epoch': 33.0}
{'loss': 0.7507, 'grad_norm': 0.47668302059173584, 'learning_rate': 0.00013333333333333334, 'epoch': 33.33}
{'loss': 0.6952, 'grad_norm': 0.625280499458313, 'learning_rate': 0.00013266666666666667, 'epoch': 33.67}
{'loss': 0.7052, 'grad_norm': 594414.875, 'learning_rate': 0.000132, 'epoch': 34.0}
{'eval_loss': 0.7291088700294495, 'eval_runtime': 34.135, 'eval_samples_per_second': 2.637, 'eval_steps_per_second': 0.352, 'epoch': 34.0}
{'loss': 0.8072, 'grad_norm': 1.5122134685516357, 'learning_rate': 0.00013133333333333332, 'epoch': 34.33}
{'loss': 0.6007, 'grad_norm': 0.5644157528877258, 'learning_rate': 0.00013066666666666668, 'epoch': 34.67}
{'loss': 0.7445, 'grad_norm': 0.631915271282196, 'learning_rate': 0.00013000000000000002, 'epoch': 35.0}
{'eval_loss': 0.6897174715995789, 'eval_runtime': 32.3196, 'eval_samples_per_second': 2.785, 'eval_steps_per_second': 0.371, 'epoch': 35.0}
{'loss': 0.6992, 'grad_norm': 0.5247915387153625, 'learning_rate': 0.00012933333333333332, 'epoch': 35.33}
{'loss': 0.6494, 'grad_norm': 0.7888621091842651, 'learning_rate': 0.00012866666666666666, 'epoch': 35.67}
{'loss': 0.7144, 'grad_norm': 0.620625376701355, 'learning_rate': 0.00012800000000000002, 'epoch': 36.0}
{'eval_loss': 0.6749111413955688, 'eval_runtime': 32.3168, 'eval_samples_per_second': 2.785, 'eval_steps_per_second': 0.371, 'epoch': 36.0}
{'loss': 0.5969, 'grad_norm': 0.8042792081832886, 'learning_rate': 0.00012733333333333336, 'epoch': 36.33}
{'loss': 0.6081, 'grad_norm': 0.7335372567176819, 'learning_rate': 0.00012666666666666666, 'epoch': 36.67}
{'loss': 0.7914, 'grad_norm': 0.509063720703125, 'learning_rate': 0.000126, 'epoch': 37.0}
{'eval_loss': 0.6554957032203674, 'eval_runtime': 32.3121, 'eval_samples_per_second': 2.785, 'eval_steps_per_second': 0.371, 'epoch': 37.0}
{'loss': 0.6445, 'grad_norm': 0.6726970672607422, 'learning_rate': 0.00012533333333333334, 'epoch': 37.33}
{'loss': 0.5859, 'grad_norm': 0.5925354361534119, 'learning_rate': 0.00012466666666666667, 'epoch': 37.67}
{'loss': 0.6971, 'grad_norm': 0.5926327705383301, 'learning_rate': 0.000124, 'epoch': 38.0}
{'eval_loss': 0.6363499760627747, 'eval_runtime': 32.8463, 'eval_samples_per_second': 2.74, 'eval_steps_per_second': 0.365, 'epoch': 38.0}
{'loss': 0.6316, 'grad_norm': 0.6640504002571106, 'learning_rate': 0.00012333333333333334, 'epoch': 38.33}
{'loss': 0.5507, 'grad_norm': 0.6806546449661255, 'learning_rate': 0.00012266666666666668, 'epoch': 38.67}
{'loss': 0.7009, 'grad_norm': 0.4905424118041992, 'learning_rate': 0.000122, 'epoch': 39.0}
{'eval_loss': 0.6133221983909607, 'eval_runtime': 32.3168, 'eval_samples_per_second': 2.785, 'eval_steps_per_second': 0.371, 'epoch': 39.0}
{'loss': 0.6861, 'grad_norm': 0.5009899139404297, 'learning_rate': 0.00012133333333333335, 'epoch': 39.33}
{'loss': 0.5973, 'grad_norm': 0.7089147567749023, 'learning_rate': 0.00012066666666666668, 'epoch': 39.67}
{'loss': 0.4957, 'grad_norm': 0.5114712715148926, 'learning_rate': 0.00012, 'epoch': 40.0}
{'eval_loss': 0.6024004220962524, 'eval_runtime': 40.8615, 'eval_samples_per_second': 2.203, 'eval_steps_per_second': 0.294, 'epoch': 40.0}
{'loss': 0.454, 'grad_norm': 904.1937866210938, 'learning_rate': 0.00011933333333333334, 'epoch': 40.33}
{'loss': 0.6677, 'grad_norm': 1.688386082649231, 'learning_rate': 0.00011866666666666669, 'epoch': 40.67}
{'loss': 0.6662, 'grad_norm': 417008.71875, 'learning_rate': 0.000118, 'epoch': 41.0}
{'eval_loss': 0.6028836369514465, 'eval_runtime': 33.0066, 'eval_samples_per_second': 2.727, 'eval_steps_per_second': 0.364, 'epoch': 41.0}
{'loss': 0.6135, 'grad_norm': 0.6117897033691406, 'learning_rate': 0.00011733333333333334, 'epoch': 41.33}
{'loss': 0.5542, 'grad_norm': 0.5798671841621399, 'learning_rate': 0.00011666666666666668, 'epoch': 41.67}
{'loss': 0.5649, 'grad_norm': 0.6169959902763367, 'learning_rate': 0.000116, 'epoch': 42.0}
{'eval_loss': 0.5752390623092651, 'eval_runtime': 33.9987, 'eval_samples_per_second': 2.647, 'eval_steps_per_second': 0.353, 'epoch': 42.0}
{'loss': 0.62, 'grad_norm': 0.5960045456886292, 'learning_rate': 0.00011533333333333334, 'epoch': 42.33}
{'loss': 0.5517, 'grad_norm': 0.543855607509613, 'learning_rate': 0.00011466666666666667, 'epoch': 42.67}
{'loss': 0.462, 'grad_norm': 0.7046384215354919, 'learning_rate': 0.00011399999999999999, 'epoch': 43.0}
{'eval_loss': 0.5564672946929932, 'eval_runtime': 33.0696, 'eval_samples_per_second': 2.722, 'eval_steps_per_second': 0.363, 'epoch': 43.0}
{'loss': 0.5568, 'grad_norm': 0.49326303601264954, 'learning_rate': 0.00011333333333333334, 'epoch': 43.33}
{'loss': 0.4692, 'grad_norm': 0.5440999865531921, 'learning_rate': 0.00011266666666666668, 'epoch': 43.67}
{'loss': 0.5768, 'grad_norm': 0.5466434359550476, 'learning_rate': 0.00011200000000000001, 'epoch': 44.0}
{'eval_loss': 0.5395234227180481, 'eval_runtime': 32.4169, 'eval_samples_per_second': 2.776, 'eval_steps_per_second': 0.37, 'epoch': 44.0}
{'loss': 0.5642, 'grad_norm': 0.4298757016658783, 'learning_rate': 0.00011133333333333333, 'epoch': 44.33}
{'loss': 0.4353, 'grad_norm': 0.45649102330207825, 'learning_rate': 0.00011066666666666667, 'epoch': 44.67}
{'loss': 0.5324, 'grad_norm': 0.5630618333816528, 'learning_rate': 0.00011000000000000002, 'epoch': 45.0}
{'eval_loss': 0.5256418585777283, 'eval_runtime': 33.7645, 'eval_samples_per_second': 2.666, 'eval_steps_per_second': 0.355, 'epoch': 45.0}
{'loss': 0.4842, 'grad_norm': 0.5344577431678772, 'learning_rate': 0.00010933333333333333, 'epoch': 45.33}
{'loss': 0.6084, 'grad_norm': 0.42440956830978394, 'learning_rate': 0.00010866666666666667, 'epoch': 45.67}
{'loss': 0.357, 'grad_norm': 0.4539300799369812, 'learning_rate': 0.00010800000000000001, 'epoch': 46.0}
{'eval_loss': 0.5124375820159912, 'eval_runtime': 34.6913, 'eval_samples_per_second': 2.594, 'eval_steps_per_second': 0.346, 'epoch': 46.0}
{'loss': 0.4515, 'grad_norm': 0.46715888381004333, 'learning_rate': 0.00010733333333333333, 'epoch': 46.33}
{'loss': 0.4976, 'grad_norm': 0.4324280023574829, 'learning_rate': 0.00010666666666666667, 'epoch': 46.67}
{'loss': 0.4846, 'grad_norm': 0.5337996482849121, 'learning_rate': 0.00010600000000000002, 'epoch': 47.0}
{'eval_loss': 0.4959176778793335, 'eval_runtime': 33.7627, 'eval_samples_per_second': 2.666, 'eval_steps_per_second': 0.355, 'epoch': 47.0}
{'loss': 0.5075, 'grad_norm': 0.3613843321800232, 'learning_rate': 0.00010533333333333332, 'epoch': 47.33}
{'loss': 0.4162, 'grad_norm': 0.5485497117042542, 'learning_rate': 0.00010466666666666667, 'epoch': 47.67}
{'loss': 0.4498, 'grad_norm': 0.6717005968093872, 'learning_rate': 0.00010400000000000001, 'epoch': 48.0}
{'eval_loss': 0.4820834696292877, 'eval_runtime': 34.1639, 'eval_samples_per_second': 2.634, 'eval_steps_per_second': 0.351, 'epoch': 48.0}
{'loss': 0.4922, 'grad_norm': 0.38734856247901917, 'learning_rate': 0.00010333333333333334, 'epoch': 48.33}
{'loss': 0.4326, 'grad_norm': 0.5960872769355774, 'learning_rate': 0.00010266666666666666, 'epoch': 48.67}
{'loss': 0.3888, 'grad_norm': 0.5595276951789856, 'learning_rate': 0.00010200000000000001, 'epoch': 49.0}
{'eval_loss': 0.47625237703323364, 'eval_runtime': 32.6782, 'eval_samples_per_second': 2.754, 'eval_steps_per_second': 0.367, 'epoch': 49.0}
{'loss': 0.4388, 'grad_norm': 0.48975110054016113, 'learning_rate': 0.00010133333333333335, 'epoch': 49.33}
{'loss': 0.4234, 'grad_norm': 0.7224727869033813, 'learning_rate': 0.00010066666666666667, 'epoch': 49.67}
{'loss': 0.4203, 'grad_norm': 0.5391109585762024, 'learning_rate': 0.0001, 'epoch': 50.0}
{'eval_loss': 0.46485382318496704, 'eval_runtime': 32.6676, 'eval_samples_per_second': 2.755, 'eval_steps_per_second': 0.367, 'epoch': 50.0}
{'loss': 0.5052, 'grad_norm': 0.5949917435646057, 'learning_rate': 9.933333333333334e-05, 'epoch': 50.33}
{'loss': 0.3662, 'grad_norm': 0.4926738440990448, 'learning_rate': 9.866666666666668e-05, 'epoch': 50.67}
{'loss': 0.3548, 'grad_norm': 0.6329906582832336, 'learning_rate': 9.8e-05, 'epoch': 51.0}
{'eval_loss': 0.4543513357639313, 'eval_runtime': 33.6243, 'eval_samples_per_second': 2.677, 'eval_steps_per_second': 0.357, 'epoch': 51.0}
{'loss': 0.3201, 'grad_norm': 0.521894633769989, 'learning_rate': 9.733333333333335e-05, 'epoch': 51.33}
{'loss': 0.4163, 'grad_norm': 0.5930529832839966, 'learning_rate': 9.666666666666667e-05, 'epoch': 51.67}
{'loss': 0.456, 'grad_norm': 0.6250091791152954, 'learning_rate': 9.6e-05, 'epoch': 52.0}
{'eval_loss': 0.44448503851890564, 'eval_runtime': 32.4335, 'eval_samples_per_second': 2.775, 'eval_steps_per_second': 0.37, 'epoch': 52.0}
{'loss': 0.3527, 'grad_norm': 0.5904732942581177, 'learning_rate': 9.533333333333334e-05, 'epoch': 52.33}
{'loss': 0.4213, 'grad_norm': 0.5404500365257263, 'learning_rate': 9.466666666666667e-05, 'epoch': 52.67}
{'loss': 0.3634, 'grad_norm': 0.6632883548736572, 'learning_rate': 9.4e-05, 'epoch': 53.0}
{'eval_loss': 0.43733707070350647, 'eval_runtime': 32.488, 'eval_samples_per_second': 2.77, 'eval_steps_per_second': 0.369, 'epoch': 53.0}
{'loss': 0.3451, 'grad_norm': 0.533936083316803, 'learning_rate': 9.333333333333334e-05, 'epoch': 53.33}
{'loss': 0.4515, 'grad_norm': 0.6663476824760437, 'learning_rate': 9.266666666666666e-05, 'epoch': 53.67}
{'loss': 0.3058, 'grad_norm': 0.9077898263931274, 'learning_rate': 9.200000000000001e-05, 'epoch': 54.0}
{'eval_loss': 0.42477288842201233, 'eval_runtime': 32.4416, 'eval_samples_per_second': 2.774, 'eval_steps_per_second': 0.37, 'epoch': 54.0}
{'loss': 0.4088, 'grad_norm': 29.106264114379883, 'learning_rate': 9.133333333333334e-05, 'epoch': 54.33}
{'loss': 0.3595, 'grad_norm': 0.9691389203071594, 'learning_rate': 9.066666666666667e-05, 'epoch': 54.67}
{'loss': 0.2948, 'grad_norm': 0.7698699235916138, 'learning_rate': 9e-05, 'epoch': 55.0}
{'eval_loss': 0.42694300413131714, 'eval_runtime': 32.397, 'eval_samples_per_second': 2.778, 'eval_steps_per_second': 0.37, 'epoch': 55.0}
{'loss': 0.4325, 'grad_norm': 1722.864990234375, 'learning_rate': 8.933333333333334e-05, 'epoch': 55.33}
{'loss': 0.3291, 'grad_norm': 1.3181324005126953, 'learning_rate': 8.866666666666668e-05, 'epoch': 55.67}
{'loss': 0.312, 'grad_norm': 0.8577224612236023, 'learning_rate': 8.800000000000001e-05, 'epoch': 56.0}
{'eval_loss': 0.42399123311042786, 'eval_runtime': 34.3109, 'eval_samples_per_second': 2.623, 'eval_steps_per_second': 0.35, 'epoch': 56.0}
{'loss': 0.2974, 'grad_norm': 0.660152792930603, 'learning_rate': 8.733333333333333e-05, 'epoch': 56.33}
{'loss': 0.3867, 'grad_norm': 0.6934272050857544, 'learning_rate': 8.666666666666667e-05, 'epoch': 56.67}
{'loss': 0.3982, 'grad_norm': 58.9337272644043, 'learning_rate': 8.6e-05, 'epoch': 57.0}
{'eval_loss': 0.4549200236797333, 'eval_runtime': 32.416, 'eval_samples_per_second': 2.776, 'eval_steps_per_second': 0.37, 'epoch': 57.0}
{'loss': 0.2596, 'grad_norm': 1.3864693641662598, 'learning_rate': 8.533333333333334e-05, 'epoch': 57.33}
{'loss': 0.3501, 'grad_norm': 1.0244919061660767, 'learning_rate': 8.466666666666667e-05, 'epoch': 57.67}
{'loss': 0.4906, 'grad_norm': 0.9317503571510315, 'learning_rate': 8.4e-05, 'epoch': 58.0}
{'eval_loss': 0.415041446685791, 'eval_runtime': 32.334, 'eval_samples_per_second': 2.783, 'eval_steps_per_second': 0.371, 'epoch': 58.0}
{'loss': 0.4167, 'grad_norm': 0.737282931804657, 'learning_rate': 8.333333333333334e-05, 'epoch': 58.33}
{'loss': 0.2731, 'grad_norm': 0.6927375197410583, 'learning_rate': 8.266666666666667e-05, 'epoch': 58.67}
{'loss': 0.3512, 'grad_norm': 1.0767769813537598, 'learning_rate': 8.2e-05, 'epoch': 59.0}
{'eval_loss': 0.4164741039276123, 'eval_runtime': 32.5558, 'eval_samples_per_second': 2.764, 'eval_steps_per_second': 0.369, 'epoch': 59.0}
{'loss': 0.3115, 'grad_norm': 0.8295163512229919, 'learning_rate': 8.133333333333334e-05, 'epoch': 59.33}
{'loss': 0.3524, 'grad_norm': 0.7423495650291443, 'learning_rate': 8.066666666666667e-05, 'epoch': 59.67}
{'loss': 0.309, 'grad_norm': 0.7858762741088867, 'learning_rate': 8e-05, 'epoch': 60.0}
{'eval_loss': 0.400608092546463, 'eval_runtime': 32.4274, 'eval_samples_per_second': 2.775, 'eval_steps_per_second': 0.37, 'epoch': 60.0}
{'loss': 0.3527, 'grad_norm': 0.6829372048377991, 'learning_rate': 7.933333333333334e-05, 'epoch': 60.33}
{'loss': 0.3322, 'grad_norm': 0.7848385572433472, 'learning_rate': 7.866666666666666e-05, 'epoch': 60.67}
{'loss': 0.2504, 'grad_norm': 0.6175446510314941, 'learning_rate': 7.800000000000001e-05, 'epoch': 61.0}
{'eval_loss': 0.4046989381313324, 'eval_runtime': 32.409, 'eval_samples_per_second': 2.777, 'eval_steps_per_second': 0.37, 'epoch': 61.0}
{'loss': 0.3758, 'grad_norm': 0.8727972507476807, 'learning_rate': 7.733333333333333e-05, 'epoch': 61.33}
{'loss': 0.259, 'grad_norm': 0.5525627136230469, 'learning_rate': 7.666666666666667e-05, 'epoch': 61.67}
{'loss': 0.2724, 'grad_norm': 0.6567720174789429, 'learning_rate': 7.6e-05, 'epoch': 62.0}
{'eval_loss': 0.3913452625274658, 'eval_runtime': 32.4065, 'eval_samples_per_second': 2.777, 'eval_steps_per_second': 0.37, 'epoch': 62.0}
{'loss': 0.2583, 'grad_norm': 0.5194605588912964, 'learning_rate': 7.533333333333334e-05, 'epoch': 62.33}
{'loss': 0.361, 'grad_norm': 0.5885672569274902, 'learning_rate': 7.466666666666667e-05, 'epoch': 62.67}
{'loss': 0.24, 'grad_norm': 0.6185957193374634, 'learning_rate': 7.4e-05, 'epoch': 63.0}
{'eval_loss': 0.39332419633865356, 'eval_runtime': 32.4031, 'eval_samples_per_second': 2.778, 'eval_steps_per_second': 0.37, 'epoch': 63.0}
{'loss': 0.2565, 'grad_norm': 0.5949185490608215, 'learning_rate': 7.333333333333333e-05, 'epoch': 63.33}
{'loss': 0.2541, 'grad_norm': 0.6031932830810547, 'learning_rate': 7.266666666666667e-05, 'epoch': 63.67}
{'loss': 0.3421, 'grad_norm': 0.5447643399238586, 'learning_rate': 7.2e-05, 'epoch': 64.0}
{'eval_loss': 0.38734132051467896, 'eval_runtime': 32.3118, 'eval_samples_per_second': 2.785, 'eval_steps_per_second': 0.371, 'epoch': 64.0}
{'loss': 0.2325, 'grad_norm': 0.4816957414150238, 'learning_rate': 7.133333333333334e-05, 'epoch': 64.33}
{'loss': 0.3285, 'grad_norm': 0.6531486511230469, 'learning_rate': 7.066666666666667e-05, 'epoch': 64.67}
{'loss': 0.2528, 'grad_norm': 0.6292489767074585, 'learning_rate': 7e-05, 'epoch': 65.0}
{'eval_loss': 0.3914555013179779, 'eval_runtime': 32.3218, 'eval_samples_per_second': 2.784, 'eval_steps_per_second': 0.371, 'epoch': 65.0}
{'loss': 0.2285, 'grad_norm': 0.5601384043693542, 'learning_rate': 6.933333333333334e-05, 'epoch': 65.33}
{'loss': 0.2797, 'grad_norm': 0.7376607656478882, 'learning_rate': 6.866666666666666e-05, 'epoch': 65.67}
{'loss': 0.2792, 'grad_norm': 0.585993766784668, 'learning_rate': 6.800000000000001e-05, 'epoch': 66.0}
{'eval_loss': 0.3842643201351166, 'eval_runtime': 32.3028, 'eval_samples_per_second': 2.786, 'eval_steps_per_second': 0.371, 'epoch': 66.0}
{'loss': 0.2989, 'grad_norm': 0.6311798095703125, 'learning_rate': 6.733333333333333e-05, 'epoch': 66.33}
{'loss': 0.2659, 'grad_norm': 0.6919301748275757, 'learning_rate': 6.666666666666667e-05, 'epoch': 66.67}
{'loss': 0.1796, 'grad_norm': 0.5853099822998047, 'learning_rate': 6.6e-05, 'epoch': 67.0}
{'eval_loss': 0.38778454065322876, 'eval_runtime': 32.3239, 'eval_samples_per_second': 2.784, 'eval_steps_per_second': 0.371, 'epoch': 67.0}
{'loss': 0.2503, 'grad_norm': 0.5861093997955322, 'learning_rate': 6.533333333333334e-05, 'epoch': 67.33}
{'loss': 0.2697, 'grad_norm': 0.6373558044433594, 'learning_rate': 6.466666666666666e-05, 'epoch': 67.67}
{'loss': 0.1999, 'grad_norm': 0.6374396681785583, 'learning_rate': 6.400000000000001e-05, 'epoch': 68.0}
{'eval_loss': 0.3819514513015747, 'eval_runtime': 32.425, 'eval_samples_per_second': 2.776, 'eval_steps_per_second': 0.37, 'epoch': 68.0}
{'loss': 0.2184, 'grad_norm': 0.588066816329956, 'learning_rate': 6.333333333333333e-05, 'epoch': 68.33}
{'loss': 0.2323, 'grad_norm': 0.6601846814155579, 'learning_rate': 6.266666666666667e-05, 'epoch': 68.67}
{'loss': 0.2426, 'grad_norm': 0.49416637420654297, 'learning_rate': 6.2e-05, 'epoch': 69.0}
{'eval_loss': 0.39730697870254517, 'eval_runtime': 32.3145, 'eval_samples_per_second': 2.785, 'eval_steps_per_second': 0.371, 'epoch': 69.0}
{'loss': 0.1433, 'grad_norm': 0.4603492319583893, 'learning_rate': 6.133333333333334e-05, 'epoch': 69.33}
{'loss': 0.2246, 'grad_norm': 0.8006458282470703, 'learning_rate': 6.066666666666667e-05, 'epoch': 69.67}
{'loss': 0.3006, 'grad_norm': 0.6846377849578857, 'learning_rate': 6e-05, 'epoch': 70.0}
{'eval_loss': 0.38118937611579895, 'eval_runtime': 32.2996, 'eval_samples_per_second': 2.786, 'eval_steps_per_second': 0.372, 'epoch': 70.0}
{'loss': 0.1888, 'grad_norm': 0.5583198666572571, 'learning_rate': 5.9333333333333343e-05, 'epoch': 70.33}
{'loss': 0.1785, 'grad_norm': 0.5567729473114014, 'learning_rate': 5.866666666666667e-05, 'epoch': 70.67}
{'loss': 0.2912, 'grad_norm': 0.7573270797729492, 'learning_rate': 5.8e-05, 'epoch': 71.0}
{'eval_loss': 0.39386940002441406, 'eval_runtime': 32.3128, 'eval_samples_per_second': 2.785, 'eval_steps_per_second': 0.371, 'epoch': 71.0}
{'loss': 0.2537, 'grad_norm': 0.5495215058326721, 'learning_rate': 5.7333333333333336e-05, 'epoch': 71.33}
{'loss': 0.1646, 'grad_norm': 0.6967417001724243, 'learning_rate': 5.666666666666667e-05, 'epoch': 71.67}
{'loss': 0.1918, 'grad_norm': 0.6507428288459778, 'learning_rate': 5.6000000000000006e-05, 'epoch': 72.0}
{'eval_loss': 0.39313650131225586, 'eval_runtime': 32.4076, 'eval_samples_per_second': 2.777, 'eval_steps_per_second': 0.37, 'epoch': 72.0}
{'loss': 0.1559, 'grad_norm': 0.5195906162261963, 'learning_rate': 5.5333333333333334e-05, 'epoch': 72.33}
{'loss': 0.1833, 'grad_norm': 0.8385326266288757, 'learning_rate': 5.466666666666666e-05, 'epoch': 72.67}
{'loss': 0.2567, 'grad_norm': 0.7050284147262573, 'learning_rate': 5.4000000000000005e-05, 'epoch': 73.0}
{'eval_loss': 0.3915489614009857, 'eval_runtime': 32.3829, 'eval_samples_per_second': 2.779, 'eval_steps_per_second': 0.371, 'epoch': 73.0}
{'loss': 0.2295, 'grad_norm': 0.7092825174331665, 'learning_rate': 5.333333333333333e-05, 'epoch': 73.33}
{'loss': 0.1438, 'grad_norm': 0.48809683322906494, 'learning_rate': 5.266666666666666e-05, 'epoch': 73.67}
{'loss': 0.2028, 'grad_norm': 1.0059988498687744, 'learning_rate': 5.2000000000000004e-05, 'epoch': 74.0}
{'eval_loss': 0.40042585134506226, 'eval_runtime': 32.4146, 'eval_samples_per_second': 2.777, 'eval_steps_per_second': 0.37, 'epoch': 74.0}
{'loss': 0.2173, 'grad_norm': 0.5804405212402344, 'learning_rate': 5.133333333333333e-05, 'epoch': 74.33}
{'loss': 0.1625, 'grad_norm': 0.7191111445426941, 'learning_rate': 5.0666666666666674e-05, 'epoch': 74.67}
{'loss': 0.161, 'grad_norm': 0.6456953883171082, 'learning_rate': 5e-05, 'epoch': 75.0}
{'eval_loss': 0.3991815447807312, 'eval_runtime': 32.404, 'eval_samples_per_second': 2.777, 'eval_steps_per_second': 0.37, 'epoch': 75.0}
{'loss': 0.2051, 'grad_norm': 0.6724667549133301, 'learning_rate': 4.933333333333334e-05, 'epoch': 75.33}
{'loss': 0.1456, 'grad_norm': 0.655897855758667, 'learning_rate': 4.866666666666667e-05, 'epoch': 75.67}
{'loss': 0.1604, 'grad_norm': 0.7352232336997986, 'learning_rate': 4.8e-05, 'epoch': 76.0}
{'eval_loss': 0.40556809306144714, 'eval_runtime': 32.3914, 'eval_samples_per_second': 2.779, 'eval_steps_per_second': 0.37, 'epoch': 76.0}
{'loss': 0.1875, 'grad_norm': 0.709800660610199, 'learning_rate': 4.7333333333333336e-05, 'epoch': 76.33}
{'loss': 0.1651, 'grad_norm': 0.9255936145782471, 'learning_rate': 4.666666666666667e-05, 'epoch': 76.67}
{'loss': 0.1458, 'grad_norm': 0.7116905450820923, 'learning_rate': 4.600000000000001e-05, 'epoch': 77.0}
{'eval_loss': 0.408333420753479, 'eval_runtime': 32.6365, 'eval_samples_per_second': 2.758, 'eval_steps_per_second': 0.368, 'epoch': 77.0}
{'loss': 0.1788, 'grad_norm': 0.7516869306564331, 'learning_rate': 4.5333333333333335e-05, 'epoch': 77.33}
{'loss': 0.1442, 'grad_norm': 0.6750248670578003, 'learning_rate': 4.466666666666667e-05, 'epoch': 77.67}
{'loss': 0.1528, 'grad_norm': 0.7800553441047668, 'learning_rate': 4.4000000000000006e-05, 'epoch': 78.0}
{'eval_loss': 0.412111759185791, 'eval_runtime': 32.3117, 'eval_samples_per_second': 2.785, 'eval_steps_per_second': 0.371, 'epoch': 78.0}
{'loss': 0.1524, 'grad_norm': 0.6883150339126587, 'learning_rate': 4.3333333333333334e-05, 'epoch': 78.33}
{'loss': 0.1673, 'grad_norm': 0.6389543414115906, 'learning_rate': 4.266666666666667e-05, 'epoch': 78.67}
{'loss': 0.1291, 'grad_norm': 0.8008160591125488, 'learning_rate': 4.2e-05, 'epoch': 79.0}
{'eval_loss': 0.4195154011249542, 'eval_runtime': 32.3147, 'eval_samples_per_second': 2.785, 'eval_steps_per_second': 0.371, 'epoch': 79.0}
{'loss': 0.103, 'grad_norm': 0.45983558893203735, 'learning_rate': 4.133333333333333e-05, 'epoch': 79.33}
{'loss': 0.1825, 'grad_norm': 0.9240504503250122, 'learning_rate': 4.066666666666667e-05, 'epoch': 79.67}
{'loss': 0.1522, 'grad_norm': 0.8525151610374451, 'learning_rate': 4e-05, 'epoch': 80.0}
{'eval_loss': 0.4145122170448303, 'eval_runtime': 32.4181, 'eval_samples_per_second': 2.776, 'eval_steps_per_second': 0.37, 'epoch': 80.0}
{'loss': 0.1421, 'grad_norm': 0.7856587767601013, 'learning_rate': 3.933333333333333e-05, 'epoch': 80.33}
{'loss': 0.1168, 'grad_norm': 0.6154540777206421, 'learning_rate': 3.866666666666667e-05, 'epoch': 80.67}
{'loss': 0.1603, 'grad_norm': 0.997184157371521, 'learning_rate': 3.8e-05, 'epoch': 81.0}
{'eval_loss': 0.42826902866363525, 'eval_runtime': 32.3953, 'eval_samples_per_second': 2.778, 'eval_steps_per_second': 0.37, 'epoch': 81.0}
{'loss': 0.1491, 'grad_norm': 0.533204972743988, 'learning_rate': 3.733333333333334e-05, 'epoch': 81.33}
{'loss': 0.142, 'grad_norm': 0.9494452476501465, 'learning_rate': 3.6666666666666666e-05, 'epoch': 81.67}
{'loss': 0.0923, 'grad_norm': 0.7110123634338379, 'learning_rate': 3.6e-05, 'epoch': 82.0}
{'eval_loss': 0.4182770550251007, 'eval_runtime': 33.044, 'eval_samples_per_second': 2.724, 'eval_steps_per_second': 0.363, 'epoch': 82.0}
{'loss': 0.1503, 'grad_norm': 2.09413480758667, 'learning_rate': 3.5333333333333336e-05, 'epoch': 82.33}
{'loss': 0.1064, 'grad_norm': 0.8746907114982605, 'learning_rate': 3.466666666666667e-05, 'epoch': 82.67}
{'loss': 0.1427, 'grad_norm': 0.9707403779029846, 'learning_rate': 3.4000000000000007e-05, 'epoch': 83.0}
{'eval_loss': 0.438030868768692, 'eval_runtime': 33.168, 'eval_samples_per_second': 2.713, 'eval_steps_per_second': 0.362, 'epoch': 83.0}
{'loss': 0.132, 'grad_norm': 0.8786668181419373, 'learning_rate': 3.3333333333333335e-05, 'epoch': 83.33}
{'loss': 0.0999, 'grad_norm': 0.8408744931221008, 'learning_rate': 3.266666666666667e-05, 'epoch': 83.67}
{'loss': 0.1398, 'grad_norm': 1746.0435791015625, 'learning_rate': 3.2000000000000005e-05, 'epoch': 84.0}
{'eval_loss': 0.446062296628952, 'eval_runtime': 52.2626, 'eval_samples_per_second': 1.722, 'eval_steps_per_second': 0.23, 'epoch': 84.0}
{'loss': 0.1293, 'grad_norm': 1.4195010662078857, 'learning_rate': 3.1333333333333334e-05, 'epoch': 84.33}
{'loss': 0.142, 'grad_norm': 0.9551326036453247, 'learning_rate': 3.066666666666667e-05, 'epoch': 84.67}
{'loss': 0.0969, 'grad_norm': 12.324258804321289, 'learning_rate': 3e-05, 'epoch': 85.0}
{'eval_loss': 0.4496799111366272, 'eval_runtime': 33.1319, 'eval_samples_per_second': 2.716, 'eval_steps_per_second': 0.362, 'epoch': 85.0}
{'loss': 0.1381, 'grad_norm': 1.0671379566192627, 'learning_rate': 2.9333333333333336e-05, 'epoch': 85.33}
{'loss': 0.1148, 'grad_norm': 1.0421829223632812, 'learning_rate': 2.8666666666666668e-05, 'epoch': 85.67}
{'loss': 0.0881, 'grad_norm': 1.0142706632614136, 'learning_rate': 2.8000000000000003e-05, 'epoch': 86.0}
{'eval_loss': 0.4309689700603485, 'eval_runtime': 33.0389, 'eval_samples_per_second': 2.724, 'eval_steps_per_second': 0.363, 'epoch': 86.0}
{'loss': 0.1274, 'grad_norm': 1.078590989112854, 'learning_rate': 2.733333333333333e-05, 'epoch': 86.33}
{'loss': 0.1127, 'grad_norm': 1.1607680320739746, 'learning_rate': 2.6666666666666667e-05, 'epoch': 86.67}
{'loss': 0.1009, 'grad_norm': 0.7194535732269287, 'learning_rate': 2.6000000000000002e-05, 'epoch': 87.0}
{'eval_loss': 0.4465084969997406, 'eval_runtime': 32.9866, 'eval_samples_per_second': 2.728, 'eval_steps_per_second': 0.364, 'epoch': 87.0}
{'loss': 0.1296, 'grad_norm': 0.8692588210105896, 'learning_rate': 2.5333333333333337e-05, 'epoch': 87.33}
{'loss': 0.0958, 'grad_norm': 0.8195713758468628, 'learning_rate': 2.466666666666667e-05, 'epoch': 87.67}
{'loss': 0.098, 'grad_norm': 0.6782001256942749, 'learning_rate': 2.4e-05, 'epoch': 88.0}
{'eval_loss': 0.4397243857383728, 'eval_runtime': 41.7523, 'eval_samples_per_second': 2.156, 'eval_steps_per_second': 0.287, 'epoch': 88.0}
{'loss': 0.096, 'grad_norm': 0.6714922189712524, 'learning_rate': 2.3333333333333336e-05, 'epoch': 88.33}
{'loss': 0.1224, 'grad_norm': 0.7656777501106262, 'learning_rate': 2.2666666666666668e-05, 'epoch': 88.67}
{'loss': 0.0924, 'grad_norm': 0.7819477915763855, 'learning_rate': 2.2000000000000003e-05, 'epoch': 89.0}
{'eval_loss': 0.4490935504436493, 'eval_runtime': 32.8829, 'eval_samples_per_second': 2.737, 'eval_steps_per_second': 0.365, 'epoch': 89.0}
{'loss': 0.0613, 'grad_norm': 0.3335721790790558, 'learning_rate': 2.1333333333333335e-05, 'epoch': 89.33}
{'loss': 0.127, 'grad_norm': 0.7605283260345459, 'learning_rate': 2.0666666666666666e-05, 'epoch': 89.67}
{'loss': 0.0989, 'grad_norm': 0.6824905872344971, 'learning_rate': 2e-05, 'epoch': 90.0}
{'eval_loss': 0.45449912548065186, 'eval_runtime': 32.5681, 'eval_samples_per_second': 2.763, 'eval_steps_per_second': 0.368, 'epoch': 90.0}
{'loss': 0.107, 'grad_norm': 0.4760892391204834, 'learning_rate': 1.9333333333333333e-05, 'epoch': 90.33}
{'loss': 0.0976, 'grad_norm': 4.890916347503662, 'learning_rate': 1.866666666666667e-05, 'epoch': 90.67}
{'loss': 0.0793, 'grad_norm': 0.6378079652786255, 'learning_rate': 1.8e-05, 'epoch': 91.0}
{'eval_loss': 0.451865553855896, 'eval_runtime': 32.5174, 'eval_samples_per_second': 2.768, 'eval_steps_per_second': 0.369, 'epoch': 91.0}
{'loss': 0.0836, 'grad_norm': 0.49689632654190063, 'learning_rate': 1.7333333333333336e-05, 'epoch': 91.33}
{'loss': 0.0804, 'grad_norm': 0.517463207244873, 'learning_rate': 1.6666666666666667e-05, 'epoch': 91.67}
{'loss': 0.1168, 'grad_norm': 0.520090639591217, 'learning_rate': 1.6000000000000003e-05, 'epoch': 92.0}
{'eval_loss': 0.4556053876876831, 'eval_runtime': 32.3386, 'eval_samples_per_second': 2.783, 'eval_steps_per_second': 0.371, 'epoch': 92.0}
{'loss': 0.1089, 'grad_norm': 0.5118058323860168, 'learning_rate': 1.5333333333333334e-05, 'epoch': 92.33}
{'loss': 0.0729, 'grad_norm': 0.4265426993370056, 'learning_rate': 1.4666666666666668e-05, 'epoch': 92.67}
{'loss': 0.0856, 'grad_norm': 0.5515624284744263, 'learning_rate': 1.4000000000000001e-05, 'epoch': 93.0}
{'eval_loss': 0.4596633017063141, 'eval_runtime': 32.3481, 'eval_samples_per_second': 2.782, 'eval_steps_per_second': 0.371, 'epoch': 93.0}
{'loss': 0.0995, 'grad_norm': 0.40363311767578125, 'learning_rate': 1.3333333333333333e-05, 'epoch': 93.33}
{'loss': 0.0926, 'grad_norm': 0.4906638562679291, 'learning_rate': 1.2666666666666668e-05, 'epoch': 93.67}
{'loss': 0.0699, 'grad_norm': 88.23387145996094, 'learning_rate': 1.2e-05, 'epoch': 94.0}
{'eval_loss': 0.4582177400588989, 'eval_runtime': 32.3451, 'eval_samples_per_second': 2.782, 'eval_steps_per_second': 0.371, 'epoch': 94.0}
{'loss': 0.0955, 'grad_norm': 0.37457969784736633, 'learning_rate': 1.1333333333333334e-05, 'epoch': 94.33}
{'loss': 0.0841, 'grad_norm': 0.49486345052719116, 'learning_rate': 1.0666666666666667e-05, 'epoch': 94.67}
{'loss': 0.0751, 'grad_norm': 0.4275543689727783, 'learning_rate': 1e-05, 'epoch': 95.0}
{'eval_loss': 0.4602420926094055, 'eval_runtime': 32.3372, 'eval_samples_per_second': 2.783, 'eval_steps_per_second': 0.371, 'epoch': 95.0}
{'loss': 0.0735, 'grad_norm': 0.33021464943885803, 'learning_rate': 9.333333333333334e-06, 'epoch': 95.33}
{'loss': 0.0712, 'grad_norm': 0.30228906869888306, 'learning_rate': 8.666666666666668e-06, 'epoch': 95.67}
{'loss': 0.1138, 'grad_norm': 0.43347033858299255, 'learning_rate': 8.000000000000001e-06, 'epoch': 96.0}
{'eval_loss': 0.4636923372745514, 'eval_runtime': 32.3253, 'eval_samples_per_second': 2.784, 'eval_steps_per_second': 0.371, 'epoch': 96.0}
{'loss': 0.0786, 'grad_norm': 11.863571166992188, 'learning_rate': 7.333333333333334e-06, 'epoch': 96.33}
{'loss': 0.0887, 'grad_norm': 0.32131674885749817, 'learning_rate': 6.666666666666667e-06, 'epoch': 96.67}
{'loss': 0.0789, 'grad_norm': 0.4342692792415619, 'learning_rate': 6e-06, 'epoch': 97.0}
{'eval_loss': 0.46426093578338623, 'eval_runtime': 40.5325, 'eval_samples_per_second': 2.22, 'eval_steps_per_second': 0.296, 'epoch': 97.0}
{'loss': 0.0967, 'grad_norm': 0.3253389000892639, 'learning_rate': 5.333333333333334e-06, 'epoch': 97.33}
{'loss': 0.08, 'grad_norm': 0.2793431282043457, 'learning_rate': 4.666666666666667e-06, 'epoch': 97.67}
{'loss': 0.0653, 'grad_norm': 0.31219545006752014, 'learning_rate': 4.000000000000001e-06, 'epoch': 98.0}
{'eval_loss': 0.46299007534980774, 'eval_runtime': 32.65, 'eval_samples_per_second': 2.757, 'eval_steps_per_second': 0.368, 'epoch': 98.0}
{'loss': 0.0817, 'grad_norm': 40.97433853149414, 'learning_rate': 3.3333333333333333e-06, 'epoch': 98.33}
{'loss': 0.0862, 'grad_norm': 0.2746117413043976, 'learning_rate': 2.666666666666667e-06, 'epoch': 98.67}
{'loss': 0.0735, 'grad_norm': 0.356365442276001, 'learning_rate': 2.0000000000000003e-06, 'epoch': 99.0}
{'eval_loss': 0.4640451967716217, 'eval_runtime': 32.7278, 'eval_samples_per_second': 2.75, 'eval_steps_per_second': 0.367, 'epoch': 99.0}
{'loss': 0.0795, 'grad_norm': 0.35577040910720825, 'learning_rate': 1.3333333333333334e-06, 'epoch': 99.33}
{'loss': 0.0921, 'grad_norm': 0.2830866277217865, 'learning_rate': 6.666666666666667e-07, 'epoch': 99.67}
{'loss': 0.065, 'grad_norm': 0.2908239960670471, 'learning_rate': 0.0, 'epoch': 100.0}
{'eval_loss': 0.46426835656166077, 'eval_runtime': 32.4182, 'eval_samples_per_second': 2.776, 'eval_steps_per_second': 0.37, 'epoch': 100.0}
{'train_runtime': 21229.5086, 'train_samples_per_second': 0.424, 'train_steps_per_second': 0.014, 'train_loss': 0.6157261642813683, 'epoch': 100.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [5:53:49<00:00, 70.77s/it]
Unsloth: Merging 4bit and LoRA weights to 16bit...
Unsloth: Will use up to 26.3 out of 63.91 RAM for saving.
Unsloth: Saving model... This might take 5 minutes ...
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:00<00:00, 58.69it/s]
Unsloth: Saving tokenizer... Done.
Done.