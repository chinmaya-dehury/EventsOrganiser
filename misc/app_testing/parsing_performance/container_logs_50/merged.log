INFO 05/03/2025 02:13:53 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 02:13:53 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 02:13:53 PM UTC Closing channel (200): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be22c339c10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 02:13:53 PM UTC Closing channel (200): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be22c339c10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 02:13:53 PM UTC Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be22c339c10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 02:13:53 PM UTC Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be22c339c10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 02:13:53 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 02:13:53 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 02:13:53 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 47438), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:53 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 47438), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:53 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 47438), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:53 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 47438), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:53 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 47438), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:53 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 47438), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:53 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 02:13:53 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 02:13:53 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 02:13:53 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 02:13:53 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 47438), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:53 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 47438), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:53 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
INFO 05/03/2025 02:13:53 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
Exception in thread Thread-1:
Exception in thread Thread-1:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 806, in _write_bytes
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 806, in _write_bytes
    self._sock.sendall(data)
    self._sock.sendall(data)
BrokenPipeError: [Errno 32] Broken pipe
BrokenPipeError: [Errno 32] Broken pipe


During handling of the above exception, another exception occurred:
During handling of the above exception, another exception occurred:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
    self.dialect.do_execute(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
    cursor.execute(statement, parameters)
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 562, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 562, in query
    self._execute_command(COMMAND.COM_QUERY, sql)
    self._execute_command(COMMAND.COM_QUERY, sql)
INFO 05/03/2025 02:13:53 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 02:13:53 PM UTC Closing connection (200): Normal shutdown
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 864, in _execute_command
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 864, in _execute_command
INFO 05/03/2025 02:13:53 PM UTC Closing channel (200): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d199610> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 02:13:53 PM UTC Closing channel (200): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d199610> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
    self._write_bytes(packet)
    self._write_bytes(packet)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 809, in _write_bytes
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 809, in _write_bytes
    raise err.OperationalError(
    raise err.OperationalError(
pymysql.err.OperationalError: (2006, "MySQL server has gone away (BrokenPipeError(32, 'Broken pipe'))")
pymysql.err.OperationalError: (2006, "MySQL server has gone away (BrokenPipeError(32, 'Broken pipe'))")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
INFO 05/03/2025 02:13:53 PM UTC Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d199610> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 02:13:53 PM UTC Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d199610> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 02:13:53 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 02:13:53 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 02:13:53 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 34496), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:53 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 34496), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:53 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 34496), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:53 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 34496), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:53 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 34496), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:53 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 34496), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:53 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 02:13:53 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 02:13:53 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 02:13:53 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 02:13:53 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 34496), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:53 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 34496), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:53 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
INFO 05/03/2025 02:13:53 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
Exception in thread Thread-1:
Exception in thread Thread-1:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 806, in _write_bytes
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 806, in _write_bytes
    self._sock.sendall(data)
    self._sock.sendall(data)
BrokenPipeError: [Errno 32] Broken pipe
BrokenPipeError: [Errno 32] Broken pipe


During handling of the above exception, another exception occurred:
During handling of the above exception, another exception occurred:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
    self.dialect.do_execute(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
    cursor.execute(statement, parameters)
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    self.run()
    self.run()
  File "/app/modules/parser.py", line 145, in run
  File "/app/modules/parser.py", line 145, in run
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
    self.mq_channel.start_consuming()
    self.mq_channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 562, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 562, in query
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._execute_command(COMMAND.COM_QUERY, sql)
    self._execute_command(COMMAND.COM_QUERY, sql)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 864, in _execute_command
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 864, in _execute_command
    self._write_bytes(packet)
    self._write_bytes(packet)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 809, in _write_bytes
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 809, in _write_bytes
    raise err.OperationalError(
    raise err.OperationalError(
pymysql.err.OperationalError: (2006, "MySQL server has gone away (BrokenPipeError(32, 'Broken pipe'))")
pymysql.err.OperationalError: (2006, "MySQL server has gone away (BrokenPipeError(32, 'Broken pipe'))")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/app/modules/parser.py", line 145, in run
  File "/app/modules/parser.py", line 145, in run
    self.mq_channel.start_consuming()
    self.mq_channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2044, in _process_data_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2044, in _process_data_events
    self._process_data_events(time_limit=None)
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2044, in _process_data_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2044, in _process_data_events
    self.connection.process_data_events(time_limit=time_limit)
    self.connection.process_data_events(time_limit=time_limit)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 851, in process_data_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 851, in process_data_events
    self._dispatch_channel_events()
    self._dispatch_channel_events()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 567, in _dispatch_channel_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 567, in _dispatch_channel_events
    impl_channel._get_cookie()._dispatch_events()
    impl_channel._get_cookie()._dispatch_events()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1510, in _dispatch_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1510, in _dispatch_events
    self.connection.process_data_events(time_limit=time_limit)
    self.connection.process_data_events(time_limit=time_limit)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 851, in process_data_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 851, in process_data_events
    consumer_info.on_message_callback(self, evt.method,
    consumer_info.on_message_callback(self, evt.method,
  File "/app/modules/parser.py", line 79, in _on_new_email
  File "/app/modules/parser.py", line 79, in _on_new_email
    settings_row = db_session.execute(query).unique().scalar_one_or_none()
    settings_row = db_session.execute(query).unique().scalar_one_or_none()
    self._dispatch_channel_events()
    self._dispatch_channel_events()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 567, in _dispatch_channel_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 567, in _dispatch_channel_events
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2362, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2362, in execute
    impl_channel._get_cookie()._dispatch_events()
    impl_channel._get_cookie()._dispatch_events()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1510, in _dispatch_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1510, in _dispatch_events
    return self._execute_internal(
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2247, in _execute_internal
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2247, in _execute_internal
    consumer_info.on_message_callback(self, evt.method,
    consumer_info.on_message_callback(self, evt.method,
    result: Result[Any] = compile_state_cls.orm_execute_statement(
    result: Result[Any] = compile_state_cls.orm_execute_statement(
  File "/app/modules/parser.py", line 79, in _on_new_email
  File "/app/modules/parser.py", line 79, in _on_new_email
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 305, in orm_execute_statement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 305, in orm_execute_statement
    result = conn.execute(
    result = conn.execute(
             ^^^^^^^^^^^^^
             ^^^^^^^^^^^^^
    settings_row = db_session.execute(query).unique().scalar_one_or_none()
    settings_row = db_session.execute(query).unique().scalar_one_or_none()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2362, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2362, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._execute_internal(
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2247, in _execute_internal
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2247, in _execute_internal
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
    result: Result[Any] = compile_state_cls.orm_execute_statement(
    result: Result[Any] = compile_state_cls.orm_execute_statement(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 305, in orm_execute_statement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 305, in orm_execute_statement
    result = conn.execute(
    result = conn.execute(
             ^^^^^^^^^^^^^
             ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    self.dialect.do_execute(
    self.dialect.do_execute(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    cursor.execute(statement, parameters)
    cursor.execute(statement, parameters)
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 562, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 562, in query
    self._execute_command(COMMAND.COM_QUERY, sql)
    self._execute_command(COMMAND.COM_QUERY, sql)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 864, in _execute_command
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 864, in _execute_command
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    self._write_bytes(packet)
    self._write_bytes(packet)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 809, in _write_bytes
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 809, in _write_bytes
    raise err.OperationalError(
    raise err.OperationalError(
sqlalchemy.exc.OperationalError: (pymysql.err.OperationalError) (2006, "MySQL server has gone away (BrokenPipeError(32, 'Broken pipe'))")
sqlalchemy.exc.OperationalError: (pymysql.err.OperationalError) (2006, "MySQL server has gone away (BrokenPipeError(32, 'Broken pipe'))")
[SQL: SELECT event_settings.user_id, event_settings.user_acc_type, tags_1.id, tags_1.name 
[SQL: SELECT event_settings.user_id, event_settings.user_acc_type, tags_1.id, tags_1.name 
FROM event_settings LEFT OUTER JOIN (user_settings_selected_categories AS user_settings_selected_categories_1 INNER JOIN tags AS tags_1 ON tags_1.id = user_settings_selected_categories_1.tag_id) ON event_settings.user_id = user_settings_selected_categories_1.user_id AND event_settings.user_acc_type = user_settings_selected_categories_1.acc_type 
FROM event_settings LEFT OUTER JOIN (user_settings_selected_categories AS user_settings_selected_categories_1 INNER JOIN tags AS tags_1 ON tags_1.id = user_settings_selected_categories_1.tag_id) ON event_settings.user_id = user_settings_selected_categories_1.user_id AND event_settings.user_acc_type = user_settings_selected_categories_1.acc_type 
WHERE event_settings.user_id = %(user_id_1)s AND event_settings.user_acc_type = %(user_acc_type_1)s]
WHERE event_settings.user_id = %(user_id_1)s AND event_settings.user_acc_type = %(user_acc_type_1)s]
[parameters: {'user_id_1': '00000000-0000-0000-82a0-946cac1dbac9', 'user_acc_type_1': 'OUTLOOK'}]
[parameters: {'user_id_1': '00000000-0000-0000-82a0-946cac1dbac9', 'user_acc_type_1': 'OUTLOOK'}]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
(Background on this error at: https://sqlalche.me/e/20/e3q8)
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
    self.dialect.do_execute(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
    cursor.execute(statement, parameters)
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 562, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 562, in query
    self._execute_command(COMMAND.COM_QUERY, sql)
    self._execute_command(COMMAND.COM_QUERY, sql)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 864, in _execute_command
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 864, in _execute_command
    self._write_bytes(packet)
    self._write_bytes(packet)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 809, in _write_bytes
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 809, in _write_bytes
    raise err.OperationalError(
    raise err.OperationalError(
sqlalchemy.exc.OperationalError: (pymysql.err.OperationalError) (2006, "MySQL server has gone away (BrokenPipeError(32, 'Broken pipe'))")
sqlalchemy.exc.OperationalError: (pymysql.err.OperationalError) (2006, "MySQL server has gone away (BrokenPipeError(32, 'Broken pipe'))")
[SQL: SELECT event_settings.user_id, event_settings.user_acc_type, tags_1.id, tags_1.name 
[SQL: SELECT event_settings.user_id, event_settings.user_acc_type, tags_1.id, tags_1.name 
FROM event_settings LEFT OUTER JOIN (user_settings_selected_categories AS user_settings_selected_categories_1 INNER JOIN tags AS tags_1 ON tags_1.id = user_settings_selected_categories_1.tag_id) ON event_settings.user_id = user_settings_selected_categories_1.user_id AND event_settings.user_acc_type = user_settings_selected_categories_1.acc_type 
FROM event_settings LEFT OUTER JOIN (user_settings_selected_categories AS user_settings_selected_categories_1 INNER JOIN tags AS tags_1 ON tags_1.id = user_settings_selected_categories_1.tag_id) ON event_settings.user_id = user_settings_selected_categories_1.user_id AND event_settings.user_acc_type = user_settings_selected_categories_1.acc_type 
WHERE event_settings.user_id = %(user_id_1)s AND event_settings.user_acc_type = %(user_acc_type_1)s]
WHERE event_settings.user_id = %(user_id_1)s AND event_settings.user_acc_type = %(user_acc_type_1)s]
[parameters: {'user_id_1': '00000000-0000-0000-82a0-946cac1dbac9', 'user_acc_type_1': 'OUTLOOK'}]
[parameters: {'user_id_1': '00000000-0000-0000-82a0-946cac1dbac9', 'user_acc_type_1': 'OUTLOOK'}]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
(Background on this error at: https://sqlalche.me/e/20/e3q8)
WARNING 05/03/2025 02:13:55 PM UTC ParserThread unexpectedly crashed, restarted it
WARNING 05/03/2025 02:13:55 PM UTC ParserThread unexpectedly crashed, restarted it
INFO 05/03/2025 02:13:55 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 02:13:55 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 02:13:55 PM UTC Socket connected: <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51266), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:55 PM UTC Socket connected: <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51266), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:55 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c7980>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c7980> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 02:13:55 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c7980>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c7980> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 02:13:55 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c7980> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 02:13:55 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c7980> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 02:13:55 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c7980> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 02:13:55 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c7980> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 02:13:55 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c7980> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 02:13:55 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c7980> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 02:13:55 PM UTC Created channel=1
INFO 05/03/2025 02:13:55 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
WARNING 05/03/2025 02:13:55 PM UTC ParserThread unexpectedly crashed, restarted it
WARNING 05/03/2025 02:13:55 PM UTC ParserThread unexpectedly crashed, restarted it
INFO 05/03/2025 02:13:55 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 02:13:55 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 02:13:55 PM UTC Socket connected: <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 43322), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:55 PM UTC Socket connected: <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 43322), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 02:13:55 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b40b0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b40b0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 02:13:55 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b40b0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b40b0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 02:13:55 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b40b0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 02:13:55 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b40b0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 02:13:55 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b40b0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 02:13:55 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b40b0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 02:13:55 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b40b0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 02:13:55 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b40b0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 02:13:55 PM UTC Created channel=1
INFO 05/03/2025 02:13:55 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Available chat formats from metadata: chat_template.default
Available chat formats from metadata: chat_template.default
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Available chat formats from metadata: chat_template.default
Available chat formats from metadata: chat_template.default
INFO 05/03/2025 02:13:59 PM UTC New e-mail: 5b3d7074-66d5-40af-ae14-ea55bae3f4cc
INFO 05/03/2025 02:13:59 PM UTC New e-mail: 5b3d7074-66d5-40af-ae14-ea55bae3f4cc
INFO 05/03/2025 02:15:19 PM UTC New e-mail: 9f98ae3f-ff82-4847-b87e-614e3e9e5b76
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print: prompt eval time =   76313.19 ms /   946 tokens (   80.67 ms per token,    12.40 tokens per second)
llama_perf_context_print: prompt eval time =   76313.19 ms /   946 tokens (   80.67 ms per token,    12.40 tokens per second)
llama_perf_context_print:        eval time =   24229.12 ms /   111 runs   (  218.28 ms per token,     4.58 tokens per second)
llama_perf_context_print:        eval time =   24229.12 ms /   111 runs   (  218.28 ms per token,     4.58 tokens per second)
llama_perf_context_print:       total time =  103234.83 ms /  1057 tokens
llama_perf_context_print:       total time =  103234.83 ms /  1057 tokens
INFO 05/03/2025 02:15:42 PM UTC E-mail parsing finished: 5b3d7074-66d5-40af-ae14-ea55bae3f4cc
INFO 05/03/2025 02:15:42 PM UTC E-mail parsing finished: 5b3d7074-66d5-40af-ae14-ea55bae3f4cc
INFO 05/03/2025 02:16:46 PM UTC New e-mail: 8d6a58ee-e35f-4676-ba76-cdfea0bd8c8d
INFO 05/03/2025 02:16:46 PM UTC New e-mail: 8d6a58ee-e35f-4676-ba76-cdfea0bd8c8d
Llama.generate: 489 prefix-match hit, remaining 476 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 476 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   87094.39 ms /   749 tokens (  116.28 ms per token,     8.60 tokens per second)
llama_perf_context_print: prompt eval time =   87094.39 ms /   749 tokens (  116.28 ms per token,     8.60 tokens per second)
llama_perf_context_print:        eval time =   25088.85 ms /   110 runs   (  228.08 ms per token,     4.38 tokens per second)
llama_perf_context_print:        eval time =   25088.85 ms /   110 runs   (  228.08 ms per token,     4.38 tokens per second)
llama_perf_context_print:       total time =  114553.07 ms /   859 tokens
llama_perf_context_print:       total time =  114553.07 ms /   859 tokens
INFO 05/03/2025 02:17:14 PM UTC E-mail parsing finished: 9f98ae3f-ff82-4847-b87e-614e3e9e5b76
INFO 05/03/2025 02:17:14 PM UTC E-mail parsing finished: 9f98ae3f-ff82-4847-b87e-614e3e9e5b76
WARNING 05/03/2025 02:17:14 PM UTC Events from an email rejected due to data validation errors
WARNING 05/03/2025 02:17:14 PM UTC Events from an email rejected due to data validation errors
Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 151, in _on_new_events
  File "/app/modules/validator.py", line 151, in _on_new_events
    data: NewEvents = NewEvents.model_validate_json(body)
    data: NewEvents = NewEvents.model_validate_json(body)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 2 validation errors for NewEvents
pydantic_core._pydantic_core.ValidationError: 2 validation errors for NewEvents
events.0.start_date
events.0.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
events.1.start_date
events.1.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print: prompt eval time =   55841.81 ms /   476 tokens (  117.31 ms per token,     8.52 tokens per second)
llama_perf_context_print: prompt eval time =   55841.81 ms /   476 tokens (  117.31 ms per token,     8.52 tokens per second)
llama_perf_context_print:        eval time =    7070.15 ms /    50 runs   (  141.40 ms per token,     7.07 tokens per second)
llama_perf_context_print:        eval time =    7070.15 ms /    50 runs   (  141.40 ms per token,     7.07 tokens per second)
llama_perf_context_print:       total time =   63882.97 ms /   526 tokens
llama_perf_context_print:       total time =   63882.97 ms /   526 tokens
INFO 05/03/2025 02:17:49 PM UTC E-mail parsing finished: 8d6a58ee-e35f-4676-ba76-cdfea0bd8c8d
INFO 05/03/2025 02:17:49 PM UTC E-mail parsing finished: 8d6a58ee-e35f-4676-ba76-cdfea0bd8c8d
WARNING 05/03/2025 02:17:49 PM UTC Events from an email rejected due to data validation errors
WARNING 05/03/2025 02:17:49 PM UTC Events from an email rejected due to data validation errors
Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 151, in _on_new_events
  File "/app/modules/validator.py", line 151, in _on_new_events
    data: NewEvents = NewEvents.model_validate_json(body)
    data: NewEvents = NewEvents.model_validate_json(body)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
events.0.start_date
events.0.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
INFO 05/03/2025 02:18:12 PM UTC New e-mail: 082a34cd-81c9-4e75-b9fe-1089a5b49a7b
INFO 05/03/2025 02:18:12 PM UTC New e-mail: 082a34cd-81c9-4e75-b9fe-1089a5b49a7b
Llama.generate: 489 prefix-match hit, remaining 13344 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 13344 prompt tokens to eval
INFO 05/03/2025 02:19:38 PM UTC New e-mail: 4ea2d5d5-2435-4186-977a-fd71e7318ae6
INFO 05/03/2025 02:19:38 PM UTC New e-mail: 4ea2d5d5-2435-4186-977a-fd71e7318ae6
Llama.generate: 489 prefix-match hit, remaining 586 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 586 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =  106306.25 ms /   586 tokens (  181.41 ms per token,     5.51 tokens per second)
llama_perf_context_print: prompt eval time =  106306.25 ms /   586 tokens (  181.41 ms per token,     5.51 tokens per second)
llama_perf_context_print:        eval time =   25410.16 ms /   112 runs   (  226.88 ms per token,     4.41 tokens per second)
llama_perf_context_print:        eval time =   25410.16 ms /   112 runs   (  226.88 ms per token,     4.41 tokens per second)
llama_perf_context_print:       total time =  134445.39 ms /   698 tokens
llama_perf_context_print:       total time =  134445.39 ms /   698 tokens
INFO 05/03/2025 02:21:53 PM UTC E-mail parsing finished: 4ea2d5d5-2435-4186-977a-fd71e7318ae6
INFO 05/03/2025 02:21:53 PM UTC E-mail parsing finished: 4ea2d5d5-2435-4186-977a-fd71e7318ae6
INFO 05/03/2025 02:21:53 PM UTC New e-mail: 389b5d50-eacf-424a-be65-15ce4d8a2dc7
INFO 05/03/2025 02:21:53 PM UTC New e-mail: 389b5d50-eacf-424a-be65-15ce4d8a2dc7
Llama.generate: 543 prefix-match hit, remaining 436 prompt tokens to eval
Llama.generate: 543 prefix-match hit, remaining 436 prompt tokens to eval
ERROR 05/03/2025 02:21:53 PM UTC Unknown exception occurred
ERROR 05/03/2025 02:21:53 PM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '1860-6' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '1860-6' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1860-6' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1860-6' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 1860, 'tag_id': 5}, {'event_id': 1860, 'tag_id': 6}, {'event_id': 1860, 'tag_id': 6}, {'event_id': 1860, 'tag_id': 5}]]
[parameters: [{'event_id': 1860, 'tag_id': 5}, {'event_id': 1860, 'tag_id': 6}, {'event_id': 1860, 'tag_id': 6}, {'event_id': 1860, 'tag_id': 5}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   52742.28 ms /   436 tokens (  120.97 ms per token,     8.27 tokens per second)
llama_perf_context_print: prompt eval time =   52742.28 ms /   436 tokens (  120.97 ms per token,     8.27 tokens per second)
llama_perf_context_print:        eval time =   30118.81 ms /   125 runs   (  240.95 ms per token,     4.15 tokens per second)
llama_perf_context_print:        eval time =   30118.81 ms /   125 runs   (  240.95 ms per token,     4.15 tokens per second)
llama_perf_context_print:       total time =   85959.68 ms /   561 tokens
llama_perf_context_print:       total time =   85959.68 ms /   561 tokens
INFO 05/03/2025 02:23:19 PM UTC E-mail parsing finished: 389b5d50-eacf-424a-be65-15ce4d8a2dc7
INFO 05/03/2025 02:23:19 PM UTC E-mail parsing finished: 389b5d50-eacf-424a-be65-15ce4d8a2dc7
INFO 05/03/2025 02:23:19 PM UTC New e-mail: 823966f6-db59-4fd2-88cb-f327540af9b6
INFO 05/03/2025 02:23:19 PM UTC New e-mail: 823966f6-db59-4fd2-88cb-f327540af9b6
Llama.generate: 489 prefix-match hit, remaining 461 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 461 prompt tokens to eval
ERROR 05/03/2025 02:23:19 PM UTC Unknown exception occurred
ERROR 05/03/2025 02:23:19 PM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '1861-6' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '1861-6' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1861-6' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1861-6' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 1861, 'tag_id': 5}, {'event_id': 1861, 'tag_id': 6}, {'event_id': 1861, 'tag_id': 6}, {'event_id': 1861, 'tag_id': 4}, {'event_id': 1861, 'tag_id': 2}]]
[parameters: [{'event_id': 1861, 'tag_id': 5}, {'event_id': 1861, 'tag_id': 6}, {'event_id': 1861, 'tag_id': 6}, {'event_id': 1861, 'tag_id': 4}, {'event_id': 1861, 'tag_id': 2}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   52869.23 ms /   461 tokens (  114.68 ms per token,     8.72 tokens per second)
llama_perf_context_print: prompt eval time =   52869.23 ms /   461 tokens (  114.68 ms per token,     8.72 tokens per second)
llama_perf_context_print:        eval time =     277.80 ms /     1 runs   (  277.80 ms per token,     3.60 tokens per second)
llama_perf_context_print:        eval time =     277.80 ms /     1 runs   (  277.80 ms per token,     3.60 tokens per second)
llama_perf_context_print:       total time =   53187.81 ms /   462 tokens
llama_perf_context_print:       total time =   53187.81 ms /   462 tokens
INFO 05/03/2025 02:24:12 PM UTC E-mail parsing finished: 823966f6-db59-4fd2-88cb-f327540af9b6
INFO 05/03/2025 02:24:12 PM UTC E-mail parsing finished: 823966f6-db59-4fd2-88cb-f327540af9b6
INFO 05/03/2025 02:24:12 PM UTC New e-mail: a0248012-d958-4426-bd15-99de28889cf1
INFO 05/03/2025 02:24:12 PM UTC New e-mail: a0248012-d958-4426-bd15-99de28889cf1
Llama.generate: 536 prefix-match hit, remaining 270 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 270 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   51862.58 ms /   270 tokens (  192.08 ms per token,     5.21 tokens per second)
llama_perf_context_print: prompt eval time =   51862.58 ms /   270 tokens (  192.08 ms per token,     5.21 tokens per second)
llama_perf_context_print:        eval time =   16046.05 ms /    69 runs   (  232.55 ms per token,     4.30 tokens per second)
llama_perf_context_print:        eval time =   16046.05 ms /    69 runs   (  232.55 ms per token,     4.30 tokens per second)
llama_perf_context_print:       total time =   69596.13 ms /   339 tokens
llama_perf_context_print:       total time =   69596.13 ms /   339 tokens
INFO 05/03/2025 02:25:22 PM UTC E-mail parsing finished: a0248012-d958-4426-bd15-99de28889cf1
INFO 05/03/2025 02:25:22 PM UTC E-mail parsing finished: a0248012-d958-4426-bd15-99de28889cf1
INFO 05/03/2025 02:25:24 PM UTC New e-mail: 7b83a7fe-a91e-486e-a096-ed111cc65935
INFO 05/03/2025 02:25:24 PM UTC New e-mail: 7b83a7fe-a91e-486e-a096-ed111cc65935
Llama.generate: 489 prefix-match hit, remaining 129 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 129 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   47293.37 ms /   129 tokens (  366.62 ms per token,     2.73 tokens per second)
llama_perf_context_print: prompt eval time =   47293.37 ms /   129 tokens (  366.62 ms per token,     2.73 tokens per second)
llama_perf_context_print:        eval time =   14494.55 ms /    65 runs   (  222.99 ms per token,     4.48 tokens per second)
llama_perf_context_print:        eval time =   14494.55 ms /    65 runs   (  222.99 ms per token,     4.48 tokens per second)
llama_perf_context_print:       total time =   63242.24 ms /   194 tokens
llama_perf_context_print:       total time =   63242.24 ms /   194 tokens
INFO 05/03/2025 02:26:27 PM UTC E-mail parsing finished: 7b83a7fe-a91e-486e-a096-ed111cc65935
INFO 05/03/2025 02:26:27 PM UTC E-mail parsing finished: 7b83a7fe-a91e-486e-a096-ed111cc65935
INFO 05/03/2025 02:26:50 PM UTC New e-mail: 6561dd7e-2176-47f8-962c-c6151232d2c0
INFO 05/03/2025 02:26:50 PM UTC New e-mail: 6561dd7e-2176-47f8-962c-c6151232d2c0
Llama.generate: 489 prefix-match hit, remaining 915 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 915 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =  107988.51 ms /   915 tokens (  118.02 ms per token,     8.47 tokens per second)
llama_perf_context_print: prompt eval time =  107988.51 ms /   915 tokens (  118.02 ms per token,     8.47 tokens per second)
llama_perf_context_print:        eval time =   29058.53 ms /   114 runs   (  254.90 ms per token,     3.92 tokens per second)
llama_perf_context_print:        eval time =   29058.53 ms /   114 runs   (  254.90 ms per token,     3.92 tokens per second)
llama_perf_context_print:       total time =  139409.64 ms /  1029 tokens
llama_perf_context_print:       total time =  139409.64 ms /  1029 tokens
INFO 05/03/2025 02:29:10 PM UTC E-mail parsing finished: 6561dd7e-2176-47f8-962c-c6151232d2c0
INFO 05/03/2025 02:29:10 PM UTC E-mail parsing finished: 6561dd7e-2176-47f8-962c-c6151232d2c0
INFO 05/03/2025 02:29:10 PM UTC New e-mail: 2b0e3361-fe58-4ff7-a09d-18864626116f
INFO 05/03/2025 02:29:10 PM UTC New e-mail: 2b0e3361-fe58-4ff7-a09d-18864626116f
Llama.generate: 541 prefix-match hit, remaining 755 prompt tokens to eval
Llama.generate: 541 prefix-match hit, remaining 755 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   99861.44 ms /   755 tokens (  132.27 ms per token,     7.56 tokens per second)
llama_perf_context_print: prompt eval time =   99861.44 ms /   755 tokens (  132.27 ms per token,     7.56 tokens per second)
llama_perf_context_print:        eval time =   22081.46 ms /    85 runs   (  259.78 ms per token,     3.85 tokens per second)
llama_perf_context_print:        eval time =   22081.46 ms /    85 runs   (  259.78 ms per token,     3.85 tokens per second)
llama_perf_context_print:       total time =  123708.49 ms /   840 tokens
llama_perf_context_print:       total time =  123708.49 ms /   840 tokens
INFO 05/03/2025 02:31:14 PM UTC E-mail parsing finished: 2b0e3361-fe58-4ff7-a09d-18864626116f
INFO 05/03/2025 02:31:14 PM UTC E-mail parsing finished: 2b0e3361-fe58-4ff7-a09d-18864626116f
INFO 05/03/2025 02:31:14 PM UTC New e-mail: 64274253-f984-4c36-9b27-bed1c52bea97
INFO 05/03/2025 02:31:14 PM UTC New e-mail: 64274253-f984-4c36-9b27-bed1c52bea97
Llama.generate: 489 prefix-match hit, remaining 236 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 236 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   50466.27 ms /   236 tokens (  213.84 ms per token,     4.68 tokens per second)
llama_perf_context_print: prompt eval time =   50466.27 ms /   236 tokens (  213.84 ms per token,     4.68 tokens per second)
llama_perf_context_print:        eval time =   19092.42 ms /    83 runs   (  230.03 ms per token,     4.35 tokens per second)
llama_perf_context_print:        eval time =   19092.42 ms /    83 runs   (  230.03 ms per token,     4.35 tokens per second)
llama_perf_context_print:       total time =   71456.48 ms /   319 tokens
llama_perf_context_print:       total time =   71456.48 ms /   319 tokens
INFO 05/03/2025 02:32:25 PM UTC E-mail parsing finished: 64274253-f984-4c36-9b27-bed1c52bea97
INFO 05/03/2025 02:32:25 PM UTC E-mail parsing finished: 64274253-f984-4c36-9b27-bed1c52bea97
INFO 05/03/2025 02:32:25 PM UTC New e-mail: 1f38000e-c077-4ae6-a952-a937916a96a2
INFO 05/03/2025 02:32:25 PM UTC New e-mail: 1f38000e-c077-4ae6-a952-a937916a96a2
Llama.generate: 489 prefix-match hit, remaining 119 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 119 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   47479.34 ms /   119 tokens (  398.99 ms per token,     2.51 tokens per second)
llama_perf_context_print: prompt eval time =   47479.34 ms /   119 tokens (  398.99 ms per token,     2.51 tokens per second)
llama_perf_context_print:        eval time =     231.75 ms /     1 runs   (  231.75 ms per token,     4.31 tokens per second)
llama_perf_context_print:        eval time =     231.75 ms /     1 runs   (  231.75 ms per token,     4.31 tokens per second)
llama_perf_context_print:       total time =   47754.87 ms /   120 tokens
llama_perf_context_print:       total time =   47754.87 ms /   120 tokens
INFO 05/03/2025 02:33:13 PM UTC E-mail parsing finished: 1f38000e-c077-4ae6-a952-a937916a96a2
INFO 05/03/2025 02:33:13 PM UTC E-mail parsing finished: 1f38000e-c077-4ae6-a952-a937916a96a2
INFO 05/03/2025 02:33:13 PM UTC New e-mail: f37534cf-6d99-4c37-9ca1-a3aac41514ca
INFO 05/03/2025 02:33:13 PM UTC New e-mail: f37534cf-6d99-4c37-9ca1-a3aac41514ca
Llama.generate: 489 prefix-match hit, remaining 531 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 531 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   56323.73 ms /   531 tokens (  106.07 ms per token,     9.43 tokens per second)
llama_perf_context_print: prompt eval time =   56323.73 ms /   531 tokens (  106.07 ms per token,     9.43 tokens per second)
llama_perf_context_print:        eval time =   51338.91 ms /   206 runs   (  249.22 ms per token,     4.01 tokens per second)
llama_perf_context_print:        eval time =   51338.91 ms /   206 runs   (  249.22 ms per token,     4.01 tokens per second)
llama_perf_context_print:       total time =  112339.08 ms /   737 tokens
llama_perf_context_print:       total time =  112339.08 ms /   737 tokens
INFO 05/03/2025 02:35:05 PM UTC E-mail parsing finished: f37534cf-6d99-4c37-9ca1-a3aac41514ca
INFO 05/03/2025 02:35:05 PM UTC E-mail parsing finished: f37534cf-6d99-4c37-9ca1-a3aac41514ca
INFO 05/03/2025 02:35:05 PM UTC New e-mail: af7c19a1-6543-4f0b-983f-606e163ea4e7
INFO 05/03/2025 02:35:05 PM UTC New e-mail: af7c19a1-6543-4f0b-983f-606e163ea4e7
Llama.generate: 489 prefix-match hit, remaining 823 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 823 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =  105140.54 ms /   823 tokens (  127.75 ms per token,     7.83 tokens per second)
llama_perf_context_print: prompt eval time =  105140.54 ms /   823 tokens (  127.75 ms per token,     7.83 tokens per second)
llama_perf_context_print:        eval time =   37769.92 ms /   149 runs   (  253.49 ms per token,     3.94 tokens per second)
llama_perf_context_print:        eval time =   37769.92 ms /   149 runs   (  253.49 ms per token,     3.94 tokens per second)
llama_perf_context_print:       total time =  145993.15 ms /   972 tokens
llama_perf_context_print:       total time =  145993.15 ms /   972 tokens
INFO 05/03/2025 02:37:31 PM UTC E-mail parsing finished: af7c19a1-6543-4f0b-983f-606e163ea4e7
INFO 05/03/2025 02:37:31 PM UTC E-mail parsing finished: af7c19a1-6543-4f0b-983f-606e163ea4e7
INFO 05/03/2025 02:37:31 PM UTC New e-mail: eaee6d6e-f778-44b8-85a2-60943e6f19ae
INFO 05/03/2025 02:37:31 PM UTC New e-mail: eaee6d6e-f778-44b8-85a2-60943e6f19ae
Llama.generate: 489 prefix-match hit, remaining 10810 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 10810 prompt tokens to eval
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print: prompt eval time = 1633731.56 ms / 13344 tokens (  122.43 ms per token,     8.17 tokens per second)
llama_perf_context_print: prompt eval time = 1633731.56 ms / 13344 tokens (  122.43 ms per token,     8.17 tokens per second)
llama_perf_context_print:        eval time =     331.50 ms /     1 runs   (  331.50 ms per token,     3.02 tokens per second)
llama_perf_context_print:        eval time =     331.50 ms /     1 runs   (  331.50 ms per token,     3.02 tokens per second)
llama_perf_context_print:       total time = 1634113.43 ms / 13345 tokens
llama_perf_context_print:       total time = 1634113.43 ms / 13345 tokens
INFO 05/03/2025 02:45:26 PM UTC E-mail parsing finished: 082a34cd-81c9-4e75-b9fe-1089a5b49a7b
INFO 05/03/2025 02:45:26 PM UTC E-mail parsing finished: 082a34cd-81c9-4e75-b9fe-1089a5b49a7b
INFO 05/03/2025 02:45:26 PM UTC New e-mail: a458698e-fe0e-44ce-9628-7c669884d39e
INFO 05/03/2025 02:45:26 PM UTC New e-mail: a458698e-fe0e-44ce-9628-7c669884d39e
Llama.generate: 489 prefix-match hit, remaining 1247 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1247 prompt tokens to eval
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print: prompt eval time =  146190.16 ms /  1247 tokens (  117.23 ms per token,     8.53 tokens per second)
llama_perf_context_print: prompt eval time =  146190.16 ms /  1247 tokens (  117.23 ms per token,     8.53 tokens per second)
llama_perf_context_print:        eval time =     214.78 ms /     1 runs   (  214.78 ms per token,     4.66 tokens per second)
llama_perf_context_print:        eval time =     214.78 ms /     1 runs   (  214.78 ms per token,     4.66 tokens per second)
llama_perf_context_print:       total time =  146438.70 ms /  1248 tokens
llama_perf_context_print:       total time =  146438.70 ms /  1248 tokens
INFO 05/03/2025 02:47:53 PM UTC E-mail parsing finished: a458698e-fe0e-44ce-9628-7c669884d39e
INFO 05/03/2025 02:47:53 PM UTC E-mail parsing finished: a458698e-fe0e-44ce-9628-7c669884d39e
INFO 05/03/2025 02:47:53 PM UTC New e-mail: a32ecc83-1484-4915-8e72-1ac08a00e614
INFO 05/03/2025 02:47:53 PM UTC New e-mail: a32ecc83-1484-4915-8e72-1ac08a00e614
Llama.generate: 489 prefix-match hit, remaining 376 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 376 prompt tokens to eval
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print: prompt eval time =   46640.35 ms /   376 tokens (  124.04 ms per token,     8.06 tokens per second)
llama_perf_context_print: prompt eval time =   46640.35 ms /   376 tokens (  124.04 ms per token,     8.06 tokens per second)
llama_perf_context_print:        eval time =   20789.24 ms /    94 runs   (  221.16 ms per token,     4.52 tokens per second)
llama_perf_context_print:        eval time =   20789.24 ms /    94 runs   (  221.16 ms per token,     4.52 tokens per second)
llama_perf_context_print:       total time =   69751.16 ms /   470 tokens
llama_perf_context_print:       total time =   69751.16 ms /   470 tokens
INFO 05/03/2025 02:49:02 PM UTC E-mail parsing finished: a32ecc83-1484-4915-8e72-1ac08a00e614
INFO 05/03/2025 02:49:02 PM UTC E-mail parsing finished: a32ecc83-1484-4915-8e72-1ac08a00e614
INFO 05/03/2025 02:49:02 PM UTC New e-mail: 85eca9ab-fb29-4a89-89e4-a0fb1aaded65
INFO 05/03/2025 02:49:02 PM UTC New e-mail: 85eca9ab-fb29-4a89-89e4-a0fb1aaded65
Llama.generate: 489 prefix-match hit, remaining 526 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 526 prompt tokens to eval
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print: prompt eval time =   49171.18 ms /   526 tokens (   93.48 ms per token,    10.70 tokens per second)
llama_perf_context_print: prompt eval time =   49171.18 ms /   526 tokens (   93.48 ms per token,    10.70 tokens per second)
llama_perf_context_print:        eval time =   18903.75 ms /    81 runs   (  233.38 ms per token,     4.28 tokens per second)
llama_perf_context_print:        eval time =   18903.75 ms /    81 runs   (  233.38 ms per token,     4.28 tokens per second)
llama_perf_context_print:       total time =   69869.61 ms /   607 tokens
llama_perf_context_print:       total time =   69869.61 ms /   607 tokens
INFO 05/03/2025 02:50:12 PM UTC E-mail parsing finished: 85eca9ab-fb29-4a89-89e4-a0fb1aaded65
INFO 05/03/2025 02:50:12 PM UTC E-mail parsing finished: 85eca9ab-fb29-4a89-89e4-a0fb1aaded65
INFO 05/03/2025 02:50:12 PM UTC New e-mail: ecf5ddd9-3a70-49e6-83b0-1a9ae5e07fa2
INFO 05/03/2025 02:50:12 PM UTC New e-mail: ecf5ddd9-3a70-49e6-83b0-1a9ae5e07fa2
Llama.generate: 489 prefix-match hit, remaining 266 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 266 prompt tokens to eval
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print: prompt eval time =   49308.43 ms /   266 tokens (  185.37 ms per token,     5.39 tokens per second)
llama_perf_context_print: prompt eval time =   49308.43 ms /   266 tokens (  185.37 ms per token,     5.39 tokens per second)
llama_perf_context_print:        eval time =     170.81 ms /     1 runs   (  170.81 ms per token,     5.85 tokens per second)
llama_perf_context_print:        eval time =     170.81 ms /     1 runs   (  170.81 ms per token,     5.85 tokens per second)
llama_perf_context_print:       total time =   49589.31 ms /   267 tokens
llama_perf_context_print:       total time =   49589.31 ms /   267 tokens
INFO 05/03/2025 02:51:02 PM UTC E-mail parsing finished: ecf5ddd9-3a70-49e6-83b0-1a9ae5e07fa2
INFO 05/03/2025 02:51:02 PM UTC E-mail parsing finished: ecf5ddd9-3a70-49e6-83b0-1a9ae5e07fa2
INFO 05/03/2025 02:51:02 PM UTC New e-mail: 3f7475bb-405d-42f7-acca-987d898c9ce3
INFO 05/03/2025 02:51:02 PM UTC New e-mail: 3f7475bb-405d-42f7-acca-987d898c9ce3
Llama.generate: 489 prefix-match hit, remaining 115 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 115 prompt tokens to eval
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print: prompt eval time =   43609.79 ms /   115 tokens (  379.22 ms per token,     2.64 tokens per second)
llama_perf_context_print: prompt eval time =   43609.79 ms /   115 tokens (  379.22 ms per token,     2.64 tokens per second)
llama_perf_context_print:        eval time =     168.77 ms /     1 runs   (  168.77 ms per token,     5.93 tokens per second)
llama_perf_context_print:        eval time =     168.77 ms /     1 runs   (  168.77 ms per token,     5.93 tokens per second)
llama_perf_context_print:       total time =   43903.19 ms /   116 tokens
llama_perf_context_print:       total time =   43903.19 ms /   116 tokens
INFO 05/03/2025 02:51:46 PM UTC E-mail parsing finished: 3f7475bb-405d-42f7-acca-987d898c9ce3
INFO 05/03/2025 02:51:46 PM UTC E-mail parsing finished: 3f7475bb-405d-42f7-acca-987d898c9ce3
INFO 05/03/2025 02:51:46 PM UTC New e-mail: db997c67-7e10-4614-b5d8-5349da7597bc
INFO 05/03/2025 02:51:46 PM UTC New e-mail: db997c67-7e10-4614-b5d8-5349da7597bc
Llama.generate: 532 prefix-match hit, remaining 72 prompt tokens to eval
Llama.generate: 532 prefix-match hit, remaining 72 prompt tokens to eval
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print: prompt eval time =   43077.31 ms /    72 tokens (  598.30 ms per token,     1.67 tokens per second)
llama_perf_context_print: prompt eval time =   43077.31 ms /    72 tokens (  598.30 ms per token,     1.67 tokens per second)
llama_perf_context_print:        eval time =     214.93 ms /     1 runs   (  214.93 ms per token,     4.65 tokens per second)
llama_perf_context_print:        eval time =     214.93 ms /     1 runs   (  214.93 ms per token,     4.65 tokens per second)
llama_perf_context_print:       total time =   43330.99 ms /    73 tokens
llama_perf_context_print:       total time =   43330.99 ms /    73 tokens
INFO 05/03/2025 02:52:29 PM UTC E-mail parsing finished: db997c67-7e10-4614-b5d8-5349da7597bc
INFO 05/03/2025 02:52:29 PM UTC E-mail parsing finished: db997c67-7e10-4614-b5d8-5349da7597bc
INFO 05/03/2025 02:52:29 PM UTC New e-mail: 652ea419-89a7-45f0-89f5-77a72db22e50
INFO 05/03/2025 02:52:29 PM UTC New e-mail: 652ea419-89a7-45f0-89f5-77a72db22e50
Llama.generate: 489 prefix-match hit, remaining 14895 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 14895 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time = 1325322.30 ms / 10810 tokens (  122.60 ms per token,     8.16 tokens per second)
llama_perf_context_print: prompt eval time = 1325322.30 ms / 10810 tokens (  122.60 ms per token,     8.16 tokens per second)
llama_perf_context_print:        eval time =     394.94 ms /     1 runs   (  394.94 ms per token,     2.53 tokens per second)
llama_perf_context_print:        eval time =     394.94 ms /     1 runs   (  394.94 ms per token,     2.53 tokens per second)
llama_perf_context_print:       total time = 1325752.81 ms / 10811 tokens
llama_perf_context_print:       total time = 1325752.81 ms / 10811 tokens
INFO 05/03/2025 02:59:37 PM UTC E-mail parsing finished: eaee6d6e-f778-44b8-85a2-60943e6f19ae
INFO 05/03/2025 02:59:37 PM UTC E-mail parsing finished: eaee6d6e-f778-44b8-85a2-60943e6f19ae
INFO 05/03/2025 02:59:37 PM UTC New e-mail: 13f418ed-fa08-49a8-a8cf-84873c4ecbc2
INFO 05/03/2025 02:59:37 PM UTC New e-mail: 13f418ed-fa08-49a8-a8cf-84873c4ecbc2
Llama.generate: 489 prefix-match hit, remaining 684 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 684 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   99176.05 ms /   684 tokens (  144.99 ms per token,     6.90 tokens per second)
llama_perf_context_print: prompt eval time =   99176.05 ms /   684 tokens (  144.99 ms per token,     6.90 tokens per second)
llama_perf_context_print:        eval time =   17338.00 ms /    71 runs   (  244.20 ms per token,     4.10 tokens per second)
llama_perf_context_print:        eval time =   17338.00 ms /    71 runs   (  244.20 ms per token,     4.10 tokens per second)
llama_perf_context_print:       total time =  118078.06 ms /   755 tokens
llama_perf_context_print:       total time =  118078.06 ms /   755 tokens
INFO 05/03/2025 03:01:35 PM UTC E-mail parsing finished: 13f418ed-fa08-49a8-a8cf-84873c4ecbc2
INFO 05/03/2025 03:01:35 PM UTC E-mail parsing finished: 13f418ed-fa08-49a8-a8cf-84873c4ecbc2
INFO 05/03/2025 03:01:35 PM UTC New e-mail: 02240e93-3a6c-4ae5-9bcd-aeca89e36903
Llama.generate: 489 prefix-match hit, remaining 4420 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 4420 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =  499850.82 ms /  4420 tokens (  113.09 ms per token,     8.84 tokens per second)
llama_perf_context_print: prompt eval time =  499850.82 ms /  4420 tokens (  113.09 ms per token,     8.84 tokens per second)
llama_perf_context_print:        eval time =     299.08 ms /     1 runs   (  299.08 ms per token,     3.34 tokens per second)
llama_perf_context_print:        eval time =     299.08 ms /     1 runs   (  299.08 ms per token,     3.34 tokens per second)
llama_perf_context_print:       total time =  500192.04 ms /  4421 tokens
llama_perf_context_print:       total time =  500192.04 ms /  4421 tokens
INFO 05/03/2025 03:09:55 PM UTC E-mail parsing finished: 02240e93-3a6c-4ae5-9bcd-aeca89e36903
INFO 05/03/2025 03:09:55 PM UTC E-mail parsing finished: 02240e93-3a6c-4ae5-9bcd-aeca89e36903
INFO 05/03/2025 03:09:55 PM UTC New e-mail: b87ce228-3aa2-4f3b-a86b-683389686960
INFO 05/03/2025 03:09:55 PM UTC New e-mail: b87ce228-3aa2-4f3b-a86b-683389686960
Llama.generate: 489 prefix-match hit, remaining 770 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 770 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =  102742.71 ms /   770 tokens (  133.43 ms per token,     7.49 tokens per second)
llama_perf_context_print: prompt eval time =  102742.71 ms /   770 tokens (  133.43 ms per token,     7.49 tokens per second)
llama_perf_context_print:        eval time =   64088.05 ms /   264 runs   (  242.76 ms per token,     4.12 tokens per second)
llama_perf_context_print:        eval time =   64088.05 ms /   264 runs   (  242.76 ms per token,     4.12 tokens per second)
llama_perf_context_print:       total time =  172543.25 ms /  1034 tokens
llama_perf_context_print:       total time =  172543.25 ms /  1034 tokens
INFO 05/03/2025 03:12:48 PM UTC E-mail parsing finished: b87ce228-3aa2-4f3b-a86b-683389686960
INFO 05/03/2025 03:12:48 PM UTC E-mail parsing finished: b87ce228-3aa2-4f3b-a86b-683389686960
INFO 05/03/2025 03:12:48 PM UTC New e-mail: a17b8760-f895-46d8-98b9-d8457f110f7e
INFO 05/03/2025 03:12:48 PM UTC New e-mail: a17b8760-f895-46d8-98b9-d8457f110f7e
Llama.generate: 489 prefix-match hit, remaining 266 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 266 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   51200.57 ms /   266 tokens (  192.48 ms per token,     5.20 tokens per second)
llama_perf_context_print: prompt eval time =   51200.57 ms /   266 tokens (  192.48 ms per token,     5.20 tokens per second)
llama_perf_context_print:        eval time =     213.15 ms /     1 runs   (  213.15 ms per token,     4.69 tokens per second)
llama_perf_context_print:        eval time =     213.15 ms /     1 runs   (  213.15 ms per token,     4.69 tokens per second)
llama_perf_context_print:       total time =   51511.10 ms /   267 tokens
llama_perf_context_print:       total time =   51511.10 ms /   267 tokens
INFO 05/03/2025 03:13:39 PM UTC E-mail parsing finished: a17b8760-f895-46d8-98b9-d8457f110f7e
INFO 05/03/2025 03:13:39 PM UTC E-mail parsing finished: a17b8760-f895-46d8-98b9-d8457f110f7e
INFO 05/03/2025 03:13:39 PM UTC New e-mail: 9c627659-d206-4fff-8df6-e6a7786144c8
INFO 05/03/2025 03:13:39 PM UTC New e-mail: 9c627659-d206-4fff-8df6-e6a7786144c8
Llama.generate: 489 prefix-match hit, remaining 208 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 208 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   53257.59 ms /   208 tokens (  256.05 ms per token,     3.91 tokens per second)
llama_perf_context_print: prompt eval time =   53257.59 ms /   208 tokens (  256.05 ms per token,     3.91 tokens per second)
llama_perf_context_print:        eval time =     234.78 ms /     1 runs   (  234.78 ms per token,     4.26 tokens per second)
llama_perf_context_print:        eval time =     234.78 ms /     1 runs   (  234.78 ms per token,     4.26 tokens per second)
llama_perf_context_print:       total time =   53529.96 ms /   209 tokens
llama_perf_context_print:       total time =   53529.96 ms /   209 tokens
INFO 05/03/2025 03:14:33 PM UTC E-mail parsing finished: 9c627659-d206-4fff-8df6-e6a7786144c8
INFO 05/03/2025 03:14:33 PM UTC E-mail parsing finished: 9c627659-d206-4fff-8df6-e6a7786144c8
INFO 05/03/2025 03:14:33 PM UTC New e-mail: 4926249a-496f-40e3-95c8-ea7f09b44d54
INFO 05/03/2025 03:14:33 PM UTC New e-mail: 4926249a-496f-40e3-95c8-ea7f09b44d54
Llama.generate: 489 prefix-match hit, remaining 587 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 587 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =  107132.37 ms /   587 tokens (  182.51 ms per token,     5.48 tokens per second)
llama_perf_context_print: prompt eval time =  107132.37 ms /   587 tokens (  182.51 ms per token,     5.48 tokens per second)
llama_perf_context_print:        eval time =   36023.33 ms /   154 runs   (  233.92 ms per token,     4.28 tokens per second)
llama_perf_context_print:        eval time =   36023.33 ms /   154 runs   (  233.92 ms per token,     4.28 tokens per second)
llama_perf_context_print:       total time =  146940.18 ms /   741 tokens
llama_perf_context_print:       total time =  146940.18 ms /   741 tokens
INFO 05/03/2025 03:17:00 PM UTC E-mail parsing finished: 4926249a-496f-40e3-95c8-ea7f09b44d54
INFO 05/03/2025 03:17:00 PM UTC E-mail parsing finished: 4926249a-496f-40e3-95c8-ea7f09b44d54
INFO 05/03/2025 03:17:00 PM UTC New e-mail: 51111d4e-7b25-4bb7-abad-fd337154fb7f
INFO 05/03/2025 03:17:00 PM UTC New e-mail: 51111d4e-7b25-4bb7-abad-fd337154fb7f
Llama.generate: 489 prefix-match hit, remaining 1013 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1013 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =  116163.32 ms /  1013 tokens (  114.67 ms per token,     8.72 tokens per second)
llama_perf_context_print: prompt eval time =  116163.32 ms /  1013 tokens (  114.67 ms per token,     8.72 tokens per second)
llama_perf_context_print:        eval time =  116026.13 ms /   462 runs   (  251.14 ms per token,     3.98 tokens per second)
llama_perf_context_print:        eval time =  116026.13 ms /   462 runs   (  251.14 ms per token,     3.98 tokens per second)
llama_perf_context_print:       total time =  242564.09 ms /  1475 tokens
llama_perf_context_print:       total time =  242564.09 ms /  1475 tokens
INFO 05/03/2025 03:21:02 PM UTC E-mail parsing finished: 51111d4e-7b25-4bb7-abad-fd337154fb7f
INFO 05/03/2025 03:21:02 PM UTC E-mail parsing finished: 51111d4e-7b25-4bb7-abad-fd337154fb7f
INFO 05/03/2025 03:21:02 PM UTC New e-mail: 52a13e9d-628a-4847-ae2f-27ef3c86f525
INFO 05/03/2025 03:21:02 PM UTC New e-mail: 52a13e9d-628a-4847-ae2f-27ef3c86f525
Llama.generate: 489 prefix-match hit, remaining 11994 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 11994 prompt tokens to eval
WARNING 05/03/2025 03:23:12 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c7980> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
WARNING 05/03/2025 03:23:12 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c7980> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 03:23:12 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 03:23:12 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 03:23:12 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 03:23:12 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 03:23:12 PM UTC Aborting transport connection: state=1; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51266), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:23:12 PM UTC Aborting transport connection: state=1; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51266), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:23:12 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51266), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:23:12 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51266), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:23:12 PM UTC Deactivating transport: state=1; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51266), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:23:12 PM UTC Deactivating transport: state=1; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51266), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:23:12 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 03:23:12 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 03:23:12 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 03:23:12 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 03:23:12 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51266), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:23:12 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51266), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:23:12 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
INFO 05/03/2025 03:23:12 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
Exception in thread Thread-9:
Exception in thread Thread-9:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/app/modules/parser.py", line 145, in run
  File "/app/modules/parser.py", line 145, in run
    self.mq_channel.start_consuming()
    self.mq_channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
    raise self._closing_reason  # pylint: disable=E0702
    raise self._closing_reason  # pylint: disable=E0702
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
WARNING 05/03/2025 03:23:15 PM UTC ParserThread unexpectedly crashed, restarted it
WARNING 05/03/2025 03:23:15 PM UTC ParserThread unexpectedly crashed, restarted it
INFO 05/03/2025 03:23:15 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 03:23:15 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 03:23:15 PM UTC Socket connected: <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51686), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:23:15 PM UTC Socket connected: <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51686), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:23:15 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c6660>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c6660> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 03:23:15 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c6660>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c6660> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 03:23:15 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c6660> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:23:15 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c6660> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:23:15 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c6660> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:23:15 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c6660> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:23:15 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c6660> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:23:15 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c6660> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:23:15 PM UTC Created channel=1
INFO 05/03/2025 03:23:15 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Available chat formats from metadata: chat_template.default
Available chat formats from metadata: chat_template.default
INFO 05/03/2025 03:23:24 PM UTC New e-mail: 652ea419-89a7-45f0-89f5-77a72db22e50
INFO 05/03/2025 03:23:24 PM UTC New e-mail: 652ea419-89a7-45f0-89f5-77a72db22e50
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print:        load time =   76314.57 ms
llama_perf_context_print: prompt eval time = 1860106.21 ms / 14895 tokens (  124.88 ms per token,     8.01 tokens per second)
llama_perf_context_print: prompt eval time = 1860106.21 ms / 14895 tokens (  124.88 ms per token,     8.01 tokens per second)
llama_perf_context_print:        eval time =    2510.49 ms /     1 runs   ( 2510.49 ms per token,     0.40 tokens per second)
llama_perf_context_print:        eval time =    2510.49 ms /     1 runs   ( 2510.49 ms per token,     0.40 tokens per second)
llama_perf_context_print:       total time = 1862803.90 ms / 14896 tokens
llama_perf_context_print:       total time = 1862803.90 ms / 14896 tokens
Exception in thread Thread-20 (_start_parsing):
Exception in thread Thread-20 (_start_parsing):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/usr/local/lib/python3.12/threading.py", line 1012, in run
  File "/usr/local/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
    self._target(*self._args, **self._kwargs)
  File "/app/modules/parser.py", line 110, in _start_parsing
  File "/app/modules/parser.py", line 110, in _start_parsing
    channel.connection.add_callback_threadsafe(cb)
    channel.connection.add_callback_threadsafe(cb)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 742, in add_callback_threadsafe
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 742, in add_callback_threadsafe
    raise exceptions.ConnectionWrongStateError(
    raise exceptions.ConnectionWrongStateError(
pika.exceptions.ConnectionWrongStateError: BlockingConnection.add_callback_threadsafe() called on closed or closing connection.
pika.exceptions.ConnectionWrongStateError: BlockingConnection.add_callback_threadsafe() called on closed or closing connection.
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time = 1454244.25 ms / 11994 tokens (  121.25 ms per token,     8.25 tokens per second)
llama_perf_context_print: prompt eval time = 1454244.25 ms / 11994 tokens (  121.25 ms per token,     8.25 tokens per second)
llama_perf_context_print:        eval time =     386.13 ms /     1 runs   (  386.13 ms per token,     2.59 tokens per second)
llama_perf_context_print:        eval time =     386.13 ms /     1 runs   (  386.13 ms per token,     2.59 tokens per second)
llama_perf_context_print:       total time = 1454663.15 ms / 11995 tokens
llama_perf_context_print:       total time = 1454663.15 ms / 11995 tokens
INFO 05/03/2025 03:45:17 PM UTC E-mail parsing finished: 52a13e9d-628a-4847-ae2f-27ef3c86f525
INFO 05/03/2025 03:45:17 PM UTC E-mail parsing finished: 52a13e9d-628a-4847-ae2f-27ef3c86f525
INFO 05/03/2025 03:45:17 PM UTC New e-mail: f470f004-0fc2-45a7-b67c-ab729ca252a3
INFO 05/03/2025 03:45:17 PM UTC New e-mail: f470f004-0fc2-45a7-b67c-ab729ca252a3
Llama.generate: 489 prefix-match hit, remaining 776 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 776 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =  103861.59 ms /   776 tokens (  133.84 ms per token,     7.47 tokens per second)
llama_perf_context_print: prompt eval time =  103861.59 ms /   776 tokens (  133.84 ms per token,     7.47 tokens per second)
llama_perf_context_print:        eval time =   24896.53 ms /    99 runs   (  251.48 ms per token,     3.98 tokens per second)
llama_perf_context_print:        eval time =   24896.53 ms /    99 runs   (  251.48 ms per token,     3.98 tokens per second)
llama_perf_context_print:       total time =  130886.86 ms /   875 tokens
llama_perf_context_print:       total time =  130886.86 ms /   875 tokens
INFO 05/03/2025 03:47:28 PM UTC E-mail parsing finished: f470f004-0fc2-45a7-b67c-ab729ca252a3
INFO 05/03/2025 03:47:28 PM UTC E-mail parsing finished: f470f004-0fc2-45a7-b67c-ab729ca252a3
INFO 05/03/2025 03:47:28 PM UTC New e-mail: fe5cc83c-4178-48a9-b1bb-abc0bdd6a78e
INFO 05/03/2025 03:47:28 PM UTC New e-mail: fe5cc83c-4178-48a9-b1bb-abc0bdd6a78e
Llama.generate: 512 prefix-match hit, remaining 1514 prompt tokens to eval
Llama.generate: 512 prefix-match hit, remaining 1514 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =  180959.91 ms /  1514 tokens (  119.52 ms per token,     8.37 tokens per second)
llama_perf_context_print: prompt eval time =  180959.91 ms /  1514 tokens (  119.52 ms per token,     8.37 tokens per second)
llama_perf_context_print:        eval time =   30915.04 ms /   115 runs   (  268.83 ms per token,     3.72 tokens per second)
llama_perf_context_print:        eval time =   30915.04 ms /   115 runs   (  268.83 ms per token,     3.72 tokens per second)
llama_perf_context_print:       total time =  214418.39 ms /  1629 tokens
llama_perf_context_print:       total time =  214418.39 ms /  1629 tokens
INFO 05/03/2025 03:51:02 PM UTC E-mail parsing finished: fe5cc83c-4178-48a9-b1bb-abc0bdd6a78e
INFO 05/03/2025 03:51:02 PM UTC E-mail parsing finished: fe5cc83c-4178-48a9-b1bb-abc0bdd6a78e
INFO 05/03/2025 03:51:02 PM UTC New e-mail: 91879dca-2c9c-4d4d-be62-1ec14b16defa
INFO 05/03/2025 03:51:02 PM UTC New e-mail: 91879dca-2c9c-4d4d-be62-1ec14b16defa
Llama.generate: 489 prefix-match hit, remaining 414 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 414 prompt tokens to eval
ERROR 05/03/2025 03:51:02 PM UTC Unknown exception occurred
ERROR 05/03/2025 03:51:02 PM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '1882-6' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '1882-6' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1882-6' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1882-6' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 1882, 'tag_id': 2}, {'event_id': 1882, 'tag_id': 5}, {'event_id': 1882, 'tag_id': 6}, {'event_id': 1882, 'tag_id': 6}]]
[parameters: [{'event_id': 1882, 'tag_id': 2}, {'event_id': 1882, 'tag_id': 5}, {'event_id': 1882, 'tag_id': 6}, {'event_id': 1882, 'tag_id': 6}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
WARNING 05/03/2025 03:53:24 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c6660> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
WARNING 05/03/2025 03:53:24 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1c6660> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 03:53:24 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 03:53:24 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 03:53:24 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 03:53:24 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 03:53:24 PM UTC Aborting transport connection: state=1; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51686), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:53:24 PM UTC Aborting transport connection: state=1; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51686), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:53:24 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51686), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:53:24 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51686), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:53:24 PM UTC Deactivating transport: state=1; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51686), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:53:24 PM UTC Deactivating transport: state=1; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51686), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:53:24 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 03:53:24 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 03:53:24 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 03:53:24 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 03:53:24 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51686), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:53:24 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 51686), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:53:24 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
INFO 05/03/2025 03:53:24 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
Exception in thread Thread-21:
Exception in thread Thread-21:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/app/modules/parser.py", line 145, in run
  File "/app/modules/parser.py", line 145, in run
    self.mq_channel.start_consuming()
    self.mq_channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
    raise self._closing_reason  # pylint: disable=E0702
    raise self._closing_reason  # pylint: disable=E0702
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
WARNING 05/03/2025 03:53:24 PM UTC ParserThread unexpectedly crashed, restarted it
WARNING 05/03/2025 03:53:24 PM UTC ParserThread unexpectedly crashed, restarted it
INFO 05/03/2025 03:53:24 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 03:53:24 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 03:53:24 PM UTC Socket connected: <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 58740), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:53:24 PM UTC Socket connected: <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.190', 58740), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:53:24 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1caea0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1caea0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 03:53:24 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1caea0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1caea0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 03:53:24 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1caea0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:24 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1caea0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:24 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1caea0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:24 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1caea0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:24 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1caea0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:24 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x72744d1caea0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:24 PM UTC Created channel=1
INFO 05/03/2025 03:53:24 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
INFO 05/03/2025 03:53:46 PM UTC Creating default categories in database
INFO 05/03/2025 03:53:46 PM UTC Creating default categories in database
INFO 05/03/2025 03:53:46 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 03:53:46 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 03:53:46 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 37194), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:53:46 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 37194), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:53:46 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318d8e0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318d8e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 03:53:46 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318d8e0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318d8e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 03:53:46 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318d8e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:46 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318d8e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:46 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318d8e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:46 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318d8e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:46 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318d8e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:46 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318d8e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:46 PM UTC Created channel=1
INFO 05/03/2025 03:53:46 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Available chat formats from metadata: chat_template.default
Available chat formats from metadata: chat_template.default
INFO 05/03/2025 03:53:49 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 03:53:49 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 03:53:49 PM UTC Socket connected: <socket.socket fd=13, family=2, type=1, proto=6, laddr=('10.0.1.190', 37210), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:53:49 PM UTC Socket connected: <socket.socket fd=13, family=2, type=1, proto=6, laddr=('10.0.1.190', 37210), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:53:49 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318f020>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318f020> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 03:53:49 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318f020>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318f020> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 03:53:49 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318f020> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:49 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318f020> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:49 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318f020> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:49 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318f020> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:49 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318f020> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:49 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318f020> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:49 PM UTC Created channel=1
INFO 05/03/2025 03:53:49 PM UTC Created channel=1
INFO 05/03/2025 03:53:49 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 03:53:49 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 03:53:49 PM UTC Socket connected: <socket.socket fd=17, family=2, type=1, proto=6, laddr=('10.0.1.190', 37220), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:53:49 PM UTC Socket connected: <socket.socket fd=17, family=2, type=1, proto=6, laddr=('10.0.1.190', 37220), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 03:53:49 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b75c0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b75c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 03:53:49 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b75c0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b75c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 03:53:49 PM UTC New e-mail: 652ea419-89a7-45f0-89f5-77a72db22e50
INFO 05/03/2025 03:53:49 PM UTC New e-mail: 652ea419-89a7-45f0-89f5-77a72db22e50
INFO 05/03/2025 03:53:49 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b75c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:49 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b75c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:49 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b75c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:49 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b75c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:49 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b75c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:49 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b75c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 03:53:49 PM UTC Created channel=1
INFO 05/03/2025 03:53:49 PM UTC Created channel=1
INFO 05/03/2025 03:53:49 PM UTC Server started
INFO 05/03/2025 03:53:49 PM UTC Server started
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   55542.22 ms /   414 tokens (  134.16 ms per token,     7.45 tokens per second)
llama_perf_context_print: prompt eval time =   55542.22 ms /   414 tokens (  134.16 ms per token,     7.45 tokens per second)
llama_perf_context_print:        eval time =  343876.48 ms /  1484 runs   (  231.72 ms per token,     4.32 tokens per second)
llama_perf_context_print:        eval time =  343876.48 ms /  1484 runs   (  231.72 ms per token,     4.32 tokens per second)
llama_perf_context_print:       total time =  436908.83 ms /  1898 tokens
llama_perf_context_print:       total time =  436908.83 ms /  1898 tokens
INFO 05/03/2025 03:58:19 PM UTC E-mail parsing finished: 91879dca-2c9c-4d4d-be62-1ec14b16defa
INFO 05/03/2025 03:58:19 PM UTC E-mail parsing finished: 91879dca-2c9c-4d4d-be62-1ec14b16defa
INFO 05/03/2025 03:58:19 PM UTC New e-mail: 2365ef5f-b882-4ce9-bd1e-d44fc87b1257
INFO 05/03/2025 03:58:19 PM UTC New e-mail: 2365ef5f-b882-4ce9-bd1e-d44fc87b1257
Llama.generate: 489 prefix-match hit, remaining 221 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 221 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   49611.76 ms /   221 tokens (  224.49 ms per token,     4.45 tokens per second)
llama_perf_context_print: prompt eval time =   49611.76 ms /   221 tokens (  224.49 ms per token,     4.45 tokens per second)
llama_perf_context_print:        eval time =     220.13 ms /     1 runs   (  220.13 ms per token,     4.54 tokens per second)
llama_perf_context_print:        eval time =     220.13 ms /     1 runs   (  220.13 ms per token,     4.54 tokens per second)
llama_perf_context_print:       total time =   49883.45 ms /   222 tokens
llama_perf_context_print:       total time =   49883.45 ms /   222 tokens
INFO 05/03/2025 03:59:09 PM UTC E-mail parsing finished: 2365ef5f-b882-4ce9-bd1e-d44fc87b1257
INFO 05/03/2025 03:59:09 PM UTC E-mail parsing finished: 2365ef5f-b882-4ce9-bd1e-d44fc87b1257
INFO 05/03/2025 03:59:09 PM UTC New e-mail: b399e01f-7f05-4176-8063-bafd06f7bd94
INFO 05/03/2025 03:59:09 PM UTC New e-mail: b399e01f-7f05-4176-8063-bafd06f7bd94
Llama.generate: 489 prefix-match hit, remaining 107 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 107 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   48238.70 ms /   107 tokens (  450.83 ms per token,     2.22 tokens per second)
llama_perf_context_print: prompt eval time =   48238.70 ms /   107 tokens (  450.83 ms per token,     2.22 tokens per second)
llama_perf_context_print:        eval time =     259.71 ms /     1 runs   (  259.71 ms per token,     3.85 tokens per second)
llama_perf_context_print:        eval time =     259.71 ms /     1 runs   (  259.71 ms per token,     3.85 tokens per second)
llama_perf_context_print:       total time =   48579.19 ms /   108 tokens
llama_perf_context_print:       total time =   48579.19 ms /   108 tokens
INFO 05/03/2025 03:59:58 PM UTC E-mail parsing finished: b399e01f-7f05-4176-8063-bafd06f7bd94
INFO 05/03/2025 03:59:58 PM UTC E-mail parsing finished: b399e01f-7f05-4176-8063-bafd06f7bd94
INFO 05/03/2025 03:59:58 PM UTC New e-mail: 868abe16-262a-487f-bdf8-33fafd2865d8
INFO 05/03/2025 03:59:58 PM UTC New e-mail: 868abe16-262a-487f-bdf8-33fafd2865d8
Llama.generate: 536 prefix-match hit, remaining 66 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 66 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   42010.75 ms /    66 tokens (  636.53 ms per token,     1.57 tokens per second)
llama_perf_context_print: prompt eval time =   42010.75 ms /    66 tokens (  636.53 ms per token,     1.57 tokens per second)
llama_perf_context_print:        eval time =     241.61 ms /     1 runs   (  241.61 ms per token,     4.14 tokens per second)
llama_perf_context_print:        eval time =     241.61 ms /     1 runs   (  241.61 ms per token,     4.14 tokens per second)
llama_perf_context_print:       total time =   42316.32 ms /    67 tokens
llama_perf_context_print:       total time =   42316.32 ms /    67 tokens
INFO 05/03/2025 04:00:40 PM UTC E-mail parsing finished: 868abe16-262a-487f-bdf8-33fafd2865d8
INFO 05/03/2025 04:00:40 PM UTC E-mail parsing finished: 868abe16-262a-487f-bdf8-33fafd2865d8
INFO 05/03/2025 04:00:40 PM UTC New e-mail: 0c7f178f-e19f-4eb5-b814-472613539a2a
INFO 05/03/2025 04:00:40 PM UTC New e-mail: 0c7f178f-e19f-4eb5-b814-472613539a2a
Llama.generate: 534 prefix-match hit, remaining 62 prompt tokens to eval
Llama.generate: 534 prefix-match hit, remaining 62 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   41509.09 ms /    62 tokens (  669.50 ms per token,     1.49 tokens per second)
llama_perf_context_print: prompt eval time =   41509.09 ms /    62 tokens (  669.50 ms per token,     1.49 tokens per second)
llama_perf_context_print:        eval time =     203.97 ms /     1 runs   (  203.97 ms per token,     4.90 tokens per second)
llama_perf_context_print:        eval time =     203.97 ms /     1 runs   (  203.97 ms per token,     4.90 tokens per second)
llama_perf_context_print:       total time =   41800.22 ms /    63 tokens
llama_perf_context_print:       total time =   41800.22 ms /    63 tokens
INFO 05/03/2025 04:01:22 PM UTC E-mail parsing finished: 0c7f178f-e19f-4eb5-b814-472613539a2a
INFO 05/03/2025 04:01:22 PM UTC E-mail parsing finished: 0c7f178f-e19f-4eb5-b814-472613539a2a
INFO 05/03/2025 04:01:22 PM UTC New e-mail: 105afaeb-863e-4182-9591-a2aa81480936
INFO 05/03/2025 04:01:22 PM UTC New e-mail: 105afaeb-863e-4182-9591-a2aa81480936
Llama.generate: 536 prefix-match hit, remaining 146 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 146 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   43871.35 ms /   146 tokens (  300.49 ms per token,     3.33 tokens per second)
llama_perf_context_print: prompt eval time =   43871.35 ms /   146 tokens (  300.49 ms per token,     3.33 tokens per second)
llama_perf_context_print:        eval time =     223.11 ms /     1 runs   (  223.11 ms per token,     4.48 tokens per second)
llama_perf_context_print:        eval time =     223.11 ms /     1 runs   (  223.11 ms per token,     4.48 tokens per second)
llama_perf_context_print:       total time =   44150.28 ms /   147 tokens
llama_perf_context_print:       total time =   44150.28 ms /   147 tokens
INFO 05/03/2025 04:02:06 PM UTC E-mail parsing finished: 105afaeb-863e-4182-9591-a2aa81480936
INFO 05/03/2025 04:02:06 PM UTC E-mail parsing finished: 105afaeb-863e-4182-9591-a2aa81480936
INFO 05/03/2025 04:02:06 PM UTC New e-mail: b2a362b1-0577-4d94-8d80-62075a02bcd1
INFO 05/03/2025 04:02:06 PM UTC New e-mail: b2a362b1-0577-4d94-8d80-62075a02bcd1
Llama.generate: 489 prefix-match hit, remaining 483 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 483 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   54226.01 ms /   483 tokens (  112.27 ms per token,     8.91 tokens per second)
llama_perf_context_print: prompt eval time =   54226.01 ms /   483 tokens (  112.27 ms per token,     8.91 tokens per second)
llama_perf_context_print:        eval time =     312.05 ms /     1 runs   (  312.05 ms per token,     3.20 tokens per second)
llama_perf_context_print:        eval time =     312.05 ms /     1 runs   (  312.05 ms per token,     3.20 tokens per second)
llama_perf_context_print:       total time =   54577.32 ms /   484 tokens
llama_perf_context_print:       total time =   54577.32 ms /   484 tokens
INFO 05/03/2025 04:03:01 PM UTC E-mail parsing finished: b2a362b1-0577-4d94-8d80-62075a02bcd1
INFO 05/03/2025 04:03:01 PM UTC E-mail parsing finished: b2a362b1-0577-4d94-8d80-62075a02bcd1
INFO 05/03/2025 04:03:01 PM UTC New e-mail: 95b801cc-1028-458b-90fa-4a1c20460482
INFO 05/03/2025 04:03:01 PM UTC New e-mail: 95b801cc-1028-458b-90fa-4a1c20460482
Llama.generate: 489 prefix-match hit, remaining 14393 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 14393 prompt tokens to eval
WARNING 05/03/2025 04:23:49 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318d8e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
WARNING 05/03/2025 04:23:49 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559318d8e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 04:23:49 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 04:23:49 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 04:23:49 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 04:23:49 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 04:23:49 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 37194), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:23:49 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 37194), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:23:49 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 37194), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:23:49 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 37194), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:23:49 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 37194), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:23:49 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 37194), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:23:49 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 04:23:49 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 04:23:49 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 04:23:49 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 04:23:49 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 37194), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:23:49 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 37194), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:23:49 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
INFO 05/03/2025 04:23:49 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
Exception in thread Thread-1:
Exception in thread Thread-1:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/app/modules/parser.py", line 145, in run
  File "/app/modules/parser.py", line 145, in run
    self.mq_channel.start_consuming()
    self.mq_channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
    raise self._closing_reason  # pylint: disable=E0702
    raise self._closing_reason  # pylint: disable=E0702
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
WARNING 05/03/2025 04:23:50 PM UTC ParserThread unexpectedly crashed, restarted it
WARNING 05/03/2025 04:23:50 PM UTC ParserThread unexpectedly crashed, restarted it
INFO 05/03/2025 04:23:50 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 04:23:50 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 04:23:50 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 58736), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:23:50 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 58736), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:23:50 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b65d0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b65d0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 04:23:50 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b65d0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b65d0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 04:23:50 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b65d0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:23:50 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b65d0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:23:50 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b65d0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:23:50 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b65d0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:23:50 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b65d0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:23:50 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b65d0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:23:50 PM UTC Created channel=1
INFO 05/03/2025 04:23:50 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Available chat formats from metadata: chat_template.default
Available chat formats from metadata: chat_template.default
INFO 05/03/2025 04:24:01 PM UTC New e-mail: 652ea419-89a7-45f0-89f5-77a72db22e50
INFO 05/03/2025 04:24:01 PM UTC New e-mail: 652ea419-89a7-45f0-89f5-77a72db22e50
llama_perf_context_print:        load time = 1999303.01 ms
llama_perf_context_print:        load time = 1999303.01 ms
llama_perf_context_print: prompt eval time = 1999301.62 ms / 15384 tokens (  129.96 ms per token,     7.69 tokens per second)
llama_perf_context_print: prompt eval time = 1999301.62 ms / 15384 tokens (  129.96 ms per token,     7.69 tokens per second)
llama_perf_context_print:        eval time =    2131.88 ms /     1 runs   ( 2131.88 ms per token,     0.47 tokens per second)
llama_perf_context_print:        eval time =    2131.88 ms /     1 runs   ( 2131.88 ms per token,     0.47 tokens per second)
llama_perf_context_print:       total time = 2001554.78 ms / 15385 tokens
llama_perf_context_print:       total time = 2001554.78 ms / 15385 tokens
Exception in thread Thread-7 (_start_parsing):
Exception in thread Thread-7 (_start_parsing):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/usr/local/lib/python3.12/threading.py", line 1012, in run
  File "/usr/local/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
    self._target(*self._args, **self._kwargs)
  File "/app/modules/parser.py", line 110, in _start_parsing
  File "/app/modules/parser.py", line 110, in _start_parsing
    channel.connection.add_callback_threadsafe(cb)
    channel.connection.add_callback_threadsafe(cb)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 742, in add_callback_threadsafe
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 742, in add_callback_threadsafe
    raise exceptions.ConnectionWrongStateError(
    raise exceptions.ConnectionWrongStateError(
pika.exceptions.ConnectionWrongStateError: BlockingConnection.add_callback_threadsafe() called on closed or closing connection.
pika.exceptions.ConnectionWrongStateError: BlockingConnection.add_callback_threadsafe() called on closed or closing connection.
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time = 1817498.71 ms / 14393 tokens (  126.28 ms per token,     7.92 tokens per second)
llama_perf_context_print: prompt eval time = 1817498.71 ms / 14393 tokens (  126.28 ms per token,     7.92 tokens per second)
llama_perf_context_print:        eval time =     417.35 ms /     1 runs   (  417.35 ms per token,     2.40 tokens per second)
llama_perf_context_print:        eval time =     417.35 ms /     1 runs   (  417.35 ms per token,     2.40 tokens per second)
llama_perf_context_print:       total time = 1817966.84 ms / 14394 tokens
llama_perf_context_print:       total time = 1817966.84 ms / 14394 tokens
INFO 05/03/2025 04:33:19 PM UTC E-mail parsing finished: 95b801cc-1028-458b-90fa-4a1c20460482
INFO 05/03/2025 04:33:19 PM UTC E-mail parsing finished: 95b801cc-1028-458b-90fa-4a1c20460482
INFO 05/03/2025 04:33:19 PM UTC New e-mail: 4bb217d1-463a-466f-a374-fd3be04d6bd7
INFO 05/03/2025 04:33:19 PM UTC New e-mail: 4bb217d1-463a-466f-a374-fd3be04d6bd7
Llama.generate: 489 prefix-match hit, remaining 696 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 696 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   99328.75 ms /   696 tokens (  142.71 ms per token,     7.01 tokens per second)
llama_perf_context_print: prompt eval time =   99328.75 ms /   696 tokens (  142.71 ms per token,     7.01 tokens per second)
llama_perf_context_print:        eval time =   38009.17 ms /   154 runs   (  246.81 ms per token,     4.05 tokens per second)
llama_perf_context_print:        eval time =   38009.17 ms /   154 runs   (  246.81 ms per token,     4.05 tokens per second)
llama_perf_context_print:       total time =  140998.44 ms /   850 tokens
llama_perf_context_print:       total time =  140998.44 ms /   850 tokens
INFO 05/03/2025 04:35:40 PM UTC E-mail parsing finished: 4bb217d1-463a-466f-a374-fd3be04d6bd7
INFO 05/03/2025 04:35:40 PM UTC E-mail parsing finished: 4bb217d1-463a-466f-a374-fd3be04d6bd7
INFO 05/03/2025 04:35:40 PM UTC New e-mail: c0aec692-a60e-43bc-9821-eafd4618dddc
INFO 05/03/2025 04:35:40 PM UTC New e-mail: c0aec692-a60e-43bc-9821-eafd4618dddc
Llama.generate: 489 prefix-match hit, remaining 317 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 317 prompt tokens to eval
ERROR 05/03/2025 04:35:40 PM UTC Unknown exception occurred
ERROR 05/03/2025 04:35:40 PM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '1900-1' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '1900-1' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1900-1' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1900-1' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 1900, 'tag_id': 5}, {'event_id': 1900, 'tag_id': 4}, {'event_id': 1900, 'tag_id': 1}, {'event_id': 1900, 'tag_id': 2}, {'event_id': 1900, 'tag_id': 1}, {'event_id': 1900, 'tag_id': 5}]]
[parameters: [{'event_id': 1900, 'tag_id': 5}, {'event_id': 1900, 'tag_id': 4}, {'event_id': 1900, 'tag_id': 1}, {'event_id': 1900, 'tag_id': 2}, {'event_id': 1900, 'tag_id': 1}, {'event_id': 1900, 'tag_id': 5}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   50282.64 ms /   317 tokens (  158.62 ms per token,     6.30 tokens per second)
llama_perf_context_print: prompt eval time =   50282.64 ms /   317 tokens (  158.62 ms per token,     6.30 tokens per second)
llama_perf_context_print:        eval time =   14903.60 ms /    63 runs   (  236.57 ms per token,     4.23 tokens per second)
llama_perf_context_print:        eval time =   14903.60 ms /    63 runs   (  236.57 ms per token,     4.23 tokens per second)
llama_perf_context_print:       total time =   66664.86 ms /   380 tokens
llama_perf_context_print:       total time =   66664.86 ms /   380 tokens
INFO 05/03/2025 04:36:46 PM UTC E-mail parsing finished: c0aec692-a60e-43bc-9821-eafd4618dddc
INFO 05/03/2025 04:36:46 PM UTC E-mail parsing finished: c0aec692-a60e-43bc-9821-eafd4618dddc
INFO 05/03/2025 04:36:46 PM UTC New e-mail: a8cd272c-ea2f-473e-936b-14aaadd80723
INFO 05/03/2025 04:36:46 PM UTC New e-mail: a8cd272c-ea2f-473e-936b-14aaadd80723
Llama.generate: 538 prefix-match hit, remaining 480 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 480 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   55638.72 ms /   480 tokens (  115.91 ms per token,     8.63 tokens per second)
llama_perf_context_print: prompt eval time =   55638.72 ms /   480 tokens (  115.91 ms per token,     8.63 tokens per second)
llama_perf_context_print:        eval time =   15135.67 ms /    64 runs   (  236.49 ms per token,     4.23 tokens per second)
llama_perf_context_print:        eval time =   15135.67 ms /    64 runs   (  236.49 ms per token,     4.23 tokens per second)
llama_perf_context_print:       total time =   72268.28 ms /   544 tokens
llama_perf_context_print:       total time =   72268.28 ms /   544 tokens
INFO 05/03/2025 04:37:59 PM UTC E-mail parsing finished: a8cd272c-ea2f-473e-936b-14aaadd80723
INFO 05/03/2025 04:37:59 PM UTC E-mail parsing finished: a8cd272c-ea2f-473e-936b-14aaadd80723
INFO 05/03/2025 04:37:59 PM UTC New e-mail: ecd3a042-e139-421f-acf6-ddda1383d308
INFO 05/03/2025 04:37:59 PM UTC New e-mail: ecd3a042-e139-421f-acf6-ddda1383d308
Llama.generate: 489 prefix-match hit, remaining 306 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 306 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   49802.75 ms /   306 tokens (  162.75 ms per token,     6.14 tokens per second)
llama_perf_context_print: prompt eval time =   49802.75 ms /   306 tokens (  162.75 ms per token,     6.14 tokens per second)
llama_perf_context_print:        eval time =     227.39 ms /     1 runs   (  227.39 ms per token,     4.40 tokens per second)
llama_perf_context_print:        eval time =     227.39 ms /     1 runs   (  227.39 ms per token,     4.40 tokens per second)
llama_perf_context_print:       total time =   50078.45 ms /   307 tokens
llama_perf_context_print:       total time =   50078.45 ms /   307 tokens
INFO 05/03/2025 04:38:49 PM UTC E-mail parsing finished: ecd3a042-e139-421f-acf6-ddda1383d308
INFO 05/03/2025 04:38:49 PM UTC E-mail parsing finished: ecd3a042-e139-421f-acf6-ddda1383d308
INFO 05/03/2025 04:38:49 PM UTC New e-mail: 9d0563ad-22ff-4c16-b777-f51b2ec6f166
INFO 05/03/2025 04:38:49 PM UTC New e-mail: 9d0563ad-22ff-4c16-b777-f51b2ec6f166
Llama.generate: 489 prefix-match hit, remaining 513 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 513 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   52171.22 ms /   513 tokens (  101.70 ms per token,     9.83 tokens per second)
llama_perf_context_print: prompt eval time =   52171.22 ms /   513 tokens (  101.70 ms per token,     9.83 tokens per second)
llama_perf_context_print:        eval time =     232.26 ms /     1 runs   (  232.26 ms per token,     4.31 tokens per second)
llama_perf_context_print:        eval time =     232.26 ms /     1 runs   (  232.26 ms per token,     4.31 tokens per second)
llama_perf_context_print:       total time =   52453.66 ms /   514 tokens
llama_perf_context_print:       total time =   52453.66 ms /   514 tokens
INFO 05/03/2025 04:39:41 PM UTC E-mail parsing finished: 9d0563ad-22ff-4c16-b777-f51b2ec6f166
INFO 05/03/2025 04:39:41 PM UTC E-mail parsing finished: 9d0563ad-22ff-4c16-b777-f51b2ec6f166
INFO 05/03/2025 04:39:41 PM UTC New e-mail: 5a552fff-c5dd-4225-9f6a-2289ecc4ec3b
INFO 05/03/2025 04:39:41 PM UTC New e-mail: 5a552fff-c5dd-4225-9f6a-2289ecc4ec3b
Llama.generate: 489 prefix-match hit, remaining 432 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 432 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   51448.91 ms /   432 tokens (  119.09 ms per token,     8.40 tokens per second)
llama_perf_context_print: prompt eval time =   51448.91 ms /   432 tokens (  119.09 ms per token,     8.40 tokens per second)
llama_perf_context_print:        eval time =   31602.58 ms /   137 runs   (  230.68 ms per token,     4.34 tokens per second)
llama_perf_context_print:        eval time =   31602.58 ms /   137 runs   (  230.68 ms per token,     4.34 tokens per second)
llama_perf_context_print:       total time =   86374.14 ms /   569 tokens
llama_perf_context_print:       total time =   86374.14 ms /   569 tokens
INFO 05/03/2025 04:41:08 PM UTC E-mail parsing finished: 5a552fff-c5dd-4225-9f6a-2289ecc4ec3b
INFO 05/03/2025 04:41:08 PM UTC E-mail parsing finished: 5a552fff-c5dd-4225-9f6a-2289ecc4ec3b
INFO 05/03/2025 04:41:08 PM UTC New e-mail: 111d8afe-c784-4af1-bdad-5352132b988a
INFO 05/03/2025 04:41:08 PM UTC New e-mail: 111d8afe-c784-4af1-bdad-5352132b988a
Llama.generate: 489 prefix-match hit, remaining 1422 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1422 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =  159965.77 ms /  1422 tokens (  112.49 ms per token,     8.89 tokens per second)
llama_perf_context_print: prompt eval time =  159965.77 ms /  1422 tokens (  112.49 ms per token,     8.89 tokens per second)
llama_perf_context_print:        eval time =   28118.22 ms /   110 runs   (  255.62 ms per token,     3.91 tokens per second)
llama_perf_context_print:        eval time =   28118.22 ms /   110 runs   (  255.62 ms per token,     3.91 tokens per second)
llama_perf_context_print:       total time =  190524.80 ms /  1532 tokens
llama_perf_context_print:       total time =  190524.80 ms /  1532 tokens
INFO 05/03/2025 04:44:18 PM UTC E-mail parsing finished: 111d8afe-c784-4af1-bdad-5352132b988a
INFO 05/03/2025 04:44:18 PM UTC E-mail parsing finished: 111d8afe-c784-4af1-bdad-5352132b988a
INFO 05/03/2025 04:44:18 PM UTC New e-mail: ccf0f9bf-7f7e-463a-ab4a-5475f6c9cd74
INFO 05/03/2025 04:44:18 PM UTC New e-mail: ccf0f9bf-7f7e-463a-ab4a-5475f6c9cd74
Llama.generate: 531 prefix-match hit, remaining 439 prompt tokens to eval
Llama.generate: 531 prefix-match hit, remaining 439 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   52529.81 ms /   439 tokens (  119.66 ms per token,     8.36 tokens per second)
llama_perf_context_print: prompt eval time =   52529.81 ms /   439 tokens (  119.66 ms per token,     8.36 tokens per second)
llama_perf_context_print:        eval time =   28578.41 ms /   125 runs   (  228.63 ms per token,     4.37 tokens per second)
llama_perf_context_print:        eval time =   28578.41 ms /   125 runs   (  228.63 ms per token,     4.37 tokens per second)
llama_perf_context_print:       total time =   84234.20 ms /   564 tokens
llama_perf_context_print:       total time =   84234.20 ms /   564 tokens
INFO 05/03/2025 04:45:43 PM UTC E-mail parsing finished: ccf0f9bf-7f7e-463a-ab4a-5475f6c9cd74
INFO 05/03/2025 04:45:43 PM UTC E-mail parsing finished: ccf0f9bf-7f7e-463a-ab4a-5475f6c9cd74
INFO 05/03/2025 04:45:43 PM UTC New e-mail: f715878a-cc35-43da-b1cd-2f24a7b223cf
INFO 05/03/2025 04:45:43 PM UTC New e-mail: f715878a-cc35-43da-b1cd-2f24a7b223cf
Llama.generate: 489 prefix-match hit, remaining 229 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 229 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   48870.18 ms /   229 tokens (  213.41 ms per token,     4.69 tokens per second)
llama_perf_context_print: prompt eval time =   48870.18 ms /   229 tokens (  213.41 ms per token,     4.69 tokens per second)
llama_perf_context_print:        eval time =     225.89 ms /     1 runs   (  225.89 ms per token,     4.43 tokens per second)
llama_perf_context_print:        eval time =     225.89 ms /     1 runs   (  225.89 ms per token,     4.43 tokens per second)
llama_perf_context_print:       total time =   49138.71 ms /   230 tokens
llama_perf_context_print:       total time =   49138.71 ms /   230 tokens
INFO 05/03/2025 04:46:32 PM UTC E-mail parsing finished: f715878a-cc35-43da-b1cd-2f24a7b223cf
INFO 05/03/2025 04:46:32 PM UTC E-mail parsing finished: f715878a-cc35-43da-b1cd-2f24a7b223cf
INFO 05/03/2025 04:46:32 PM UTC New e-mail: 6875c4ed-d79a-4e33-a312-782b5168188d
INFO 05/03/2025 04:46:32 PM UTC New e-mail: 6875c4ed-d79a-4e33-a312-782b5168188d
Llama.generate: 489 prefix-match hit, remaining 119 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 119 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   44031.14 ms /   119 tokens (  370.01 ms per token,     2.70 tokens per second)
llama_perf_context_print: prompt eval time =   44031.14 ms /   119 tokens (  370.01 ms per token,     2.70 tokens per second)
llama_perf_context_print:        eval time =     248.64 ms /     1 runs   (  248.64 ms per token,     4.02 tokens per second)
llama_perf_context_print:        eval time =     248.64 ms /     1 runs   (  248.64 ms per token,     4.02 tokens per second)
llama_perf_context_print:       total time =   44337.84 ms /   120 tokens
llama_perf_context_print:       total time =   44337.84 ms /   120 tokens
INFO 05/03/2025 04:47:16 PM UTC E-mail parsing finished: 6875c4ed-d79a-4e33-a312-782b5168188d
INFO 05/03/2025 04:47:16 PM UTC E-mail parsing finished: 6875c4ed-d79a-4e33-a312-782b5168188d
INFO 05/03/2025 04:47:16 PM UTC New e-mail: 0094d19c-8101-4446-b245-277dfb5bea50
INFO 05/03/2025 04:47:16 PM UTC New e-mail: 0094d19c-8101-4446-b245-277dfb5bea50
Llama.generate: 489 prefix-match hit, remaining 828 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 828 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =  104350.66 ms /   828 tokens (  126.03 ms per token,     7.93 tokens per second)
llama_perf_context_print: prompt eval time =  104350.66 ms /   828 tokens (  126.03 ms per token,     7.93 tokens per second)
llama_perf_context_print:        eval time =   20112.96 ms /    84 runs   (  239.44 ms per token,     4.18 tokens per second)
llama_perf_context_print:        eval time =   20112.96 ms /    84 runs   (  239.44 ms per token,     4.18 tokens per second)
llama_perf_context_print:       total time =  126335.61 ms /   912 tokens
llama_perf_context_print:       total time =  126335.61 ms /   912 tokens
INFO 05/03/2025 04:49:22 PM UTC E-mail parsing finished: 0094d19c-8101-4446-b245-277dfb5bea50
INFO 05/03/2025 04:49:22 PM UTC E-mail parsing finished: 0094d19c-8101-4446-b245-277dfb5bea50
INFO 05/03/2025 04:49:22 PM UTC New e-mail: 493cbc43-240a-4e60-b804-4cf155490c5f
INFO 05/03/2025 04:49:22 PM UTC New e-mail: 493cbc43-240a-4e60-b804-4cf155490c5f
Llama.generate: 554 prefix-match hit, remaining 444 prompt tokens to eval
Llama.generate: 554 prefix-match hit, remaining 444 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   53822.45 ms /   444 tokens (  121.22 ms per token,     8.25 tokens per second)
llama_perf_context_print: prompt eval time =   53822.45 ms /   444 tokens (  121.22 ms per token,     8.25 tokens per second)
llama_perf_context_print:        eval time =     242.65 ms /     1 runs   (  242.65 ms per token,     4.12 tokens per second)
llama_perf_context_print:        eval time =     242.65 ms /     1 runs   (  242.65 ms per token,     4.12 tokens per second)
llama_perf_context_print:       total time =   54119.53 ms /   445 tokens
llama_perf_context_print:       total time =   54119.53 ms /   445 tokens
INFO 05/03/2025 04:50:17 PM UTC E-mail parsing finished: 493cbc43-240a-4e60-b804-4cf155490c5f
INFO 05/03/2025 04:50:17 PM UTC E-mail parsing finished: 493cbc43-240a-4e60-b804-4cf155490c5f
INFO 05/03/2025 04:50:17 PM UTC New e-mail: d6e9ea9f-de5f-48db-879a-967b83866669
INFO 05/03/2025 04:50:17 PM UTC New e-mail: d6e9ea9f-de5f-48db-879a-967b83866669
Llama.generate: 540 prefix-match hit, remaining 473 prompt tokens to eval
Llama.generate: 540 prefix-match hit, remaining 473 prompt tokens to eval
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =   55276.15 ms /   473 tokens (  116.86 ms per token,     8.56 tokens per second)
llama_perf_context_print: prompt eval time =   55276.15 ms /   473 tokens (  116.86 ms per token,     8.56 tokens per second)
llama_perf_context_print:        eval time =   22200.56 ms /    95 runs   (  233.69 ms per token,     4.28 tokens per second)
llama_perf_context_print:        eval time =   22200.56 ms /    95 runs   (  233.69 ms per token,     4.28 tokens per second)
llama_perf_context_print:       total time =   79738.35 ms /   568 tokens
llama_perf_context_print:       total time =   79738.35 ms /   568 tokens
INFO 05/03/2025 04:51:36 PM UTC E-mail parsing finished: d6e9ea9f-de5f-48db-879a-967b83866669
INFO 05/03/2025 04:51:36 PM UTC E-mail parsing finished: d6e9ea9f-de5f-48db-879a-967b83866669
INFO 05/03/2025 04:51:36 PM UTC New e-mail: a798697a-dab3-4a68-bdee-f3266b0465da
INFO 05/03/2025 04:51:36 PM UTC New e-mail: a798697a-dab3-4a68-bdee-f3266b0465da
Llama.generate: 489 prefix-match hit, remaining 762 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 762 prompt tokens to eval
WARNING 05/03/2025 04:54:01 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b65d0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
WARNING 05/03/2025 04:54:01 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931b65d0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 04:54:01 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 04:54:01 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 04:54:01 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 04:54:01 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 04:54:01 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 58736), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:54:01 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 58736), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:54:01 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 58736), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:54:01 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 58736), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:54:01 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 58736), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:54:01 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 58736), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:54:01 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 04:54:01 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 04:54:01 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 04:54:01 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 04:54:01 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 58736), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:54:01 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 58736), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:54:01 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
INFO 05/03/2025 04:54:01 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
Exception in thread Thread-8:
Exception in thread Thread-8:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/app/modules/parser.py", line 145, in run
  File "/app/modules/parser.py", line 145, in run
    self.mq_channel.start_consuming()
    self.mq_channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
    raise self._closing_reason  # pylint: disable=E0702
    raise self._closing_reason  # pylint: disable=E0702
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
WARNING 05/03/2025 04:54:02 PM UTC ParserThread unexpectedly crashed, restarted it
WARNING 05/03/2025 04:54:02 PM UTC ParserThread unexpectedly crashed, restarted it
INFO 05/03/2025 04:54:02 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 04:54:02 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 04:54:02 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 49770), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:54:02 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 49770), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:54:02 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931c17c0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931c17c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 04:54:02 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931c17c0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931c17c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 04:54:02 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931c17c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:02 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931c17c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:02 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931c17c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:02 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931c17c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:02 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931c17c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:02 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55931c17c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:02 PM UTC Created channel=1
INFO 05/03/2025 04:54:02 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time =  100155.68 ms /   762 tokens (  131.44 ms per token,     7.61 tokens per second)
llama_perf_context_print: prompt eval time =  100155.68 ms /   762 tokens (  131.44 ms per token,     7.61 tokens per second)
llama_perf_context_print:        eval time =   46543.45 ms /   211 runs   (  220.59 ms per token,     4.53 tokens per second)
llama_perf_context_print:        eval time =   46543.45 ms /   211 runs   (  220.59 ms per token,     4.53 tokens per second)
llama_perf_context_print:       total time =  152159.32 ms /   973 tokens
llama_perf_context_print:       total time =  152159.32 ms /   973 tokens
INFO 05/03/2025 04:54:08 PM UTC E-mail parsing finished: a798697a-dab3-4a68-bdee-f3266b0465da
INFO 05/03/2025 04:54:08 PM UTC E-mail parsing finished: a798697a-dab3-4a68-bdee-f3266b0465da
INFO 05/03/2025 04:54:08 PM UTC New e-mail: 652ea419-89a7-45f0-89f5-77a72db22e50
INFO 05/03/2025 04:54:08 PM UTC New e-mail: 652ea419-89a7-45f0-89f5-77a72db22e50
Llama.generate: 489 prefix-match hit, remaining 14895 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 14895 prompt tokens to eval
INFO 05/03/2025 04:54:10 PM UTC Creating default categories in database
INFO 05/03/2025 04:54:10 PM UTC Creating default categories in database
INFO 05/03/2025 04:54:11 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 04:54:11 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 04:54:11 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 49776), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:54:11 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 49776), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:54:11 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7769139500e0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7769139500e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 04:54:11 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7769139500e0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7769139500e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 04:54:11 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7769139500e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:11 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7769139500e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:11 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7769139500e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:11 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7769139500e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:11 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7769139500e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:11 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7769139500e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:11 PM UTC Created channel=1
INFO 05/03/2025 04:54:11 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Available chat formats from metadata: chat_template.default
Available chat formats from metadata: chat_template.default
INFO 05/03/2025 04:54:14 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 04:54:14 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 04:54:14 PM UTC Socket connected: <socket.socket fd=13, family=2, type=1, proto=6, laddr=('10.0.1.190', 32866), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:54:14 PM UTC Socket connected: <socket.socket fd=13, family=2, type=1, proto=6, laddr=('10.0.1.190', 32866), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:54:14 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdba24e0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdba24e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 04:54:14 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdba24e0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdba24e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 04:54:14 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdba24e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:14 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdba24e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:14 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdba24e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:14 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdba24e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:14 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdba24e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:14 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdba24e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:14 PM UTC Created channel=1
INFO 05/03/2025 04:54:14 PM UTC Created channel=1
INFO 05/03/2025 04:54:14 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 04:54:14 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 04:54:14 PM UTC Socket connected: <socket.socket fd=17, family=2, type=1, proto=6, laddr=('10.0.1.190', 32876), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:54:14 PM UTC Socket connected: <socket.socket fd=17, family=2, type=1, proto=6, laddr=('10.0.1.190', 32876), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 04:54:14 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbc9460>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbc9460> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 04:54:14 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbc9460>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbc9460> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 04:54:14 PM UTC New e-mail: fa74e9b7-3ea1-4acc-893c-54c2138e76a6
INFO 05/03/2025 04:54:14 PM UTC New e-mail: fa74e9b7-3ea1-4acc-893c-54c2138e76a6
INFO 05/03/2025 04:54:14 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbc9460> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:14 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbc9460> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:14 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbc9460> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:14 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbc9460> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:14 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbc9460> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:14 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbc9460> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 04:54:14 PM UTC Created channel=1
INFO 05/03/2025 04:54:14 PM UTC Created channel=1
INFO 05/03/2025 04:54:14 PM UTC Server started
INFO 05/03/2025 04:54:14 PM UTC Server started
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time = 1428398.98 ms / 12420 tokens (  115.01 ms per token,     8.70 tokens per second)
llama_perf_context_print: prompt eval time = 1428398.98 ms / 12420 tokens (  115.01 ms per token,     8.70 tokens per second)
llama_perf_context_print:        eval time =     361.58 ms /     1 runs   (  361.58 ms per token,     2.77 tokens per second)
llama_perf_context_print:        eval time =     361.58 ms /     1 runs   (  361.58 ms per token,     2.77 tokens per second)
llama_perf_context_print:       total time = 1428835.67 ms / 12421 tokens
llama_perf_context_print:       total time = 1428835.67 ms / 12421 tokens
INFO 05/03/2025 05:18:03 PM UTC E-mail parsing finished: fa74e9b7-3ea1-4acc-893c-54c2138e76a6
INFO 05/03/2025 05:18:03 PM UTC E-mail parsing finished: fa74e9b7-3ea1-4acc-893c-54c2138e76a6
INFO 05/03/2025 05:18:03 PM UTC New e-mail: a9c88dc0-6fcc-4c1b-bf6f-554499b91074
INFO 05/03/2025 05:18:03 PM UTC New e-mail: a9c88dc0-6fcc-4c1b-bf6f-554499b91074
Llama.generate: 489 prefix-match hit, remaining 1155 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1155 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =  149655.35 ms /  1155 tokens (  129.57 ms per token,     7.72 tokens per second)
llama_perf_context_print: prompt eval time =  149655.35 ms /  1155 tokens (  129.57 ms per token,     7.72 tokens per second)
llama_perf_context_print:        eval time =   28798.51 ms /   115 runs   (  250.42 ms per token,     3.99 tokens per second)
llama_perf_context_print:        eval time =   28798.51 ms /   115 runs   (  250.42 ms per token,     3.99 tokens per second)
llama_perf_context_print:       total time =  181008.26 ms /  1270 tokens
llama_perf_context_print:       total time =  181008.26 ms /  1270 tokens
INFO 05/03/2025 05:21:04 PM UTC E-mail parsing finished: a9c88dc0-6fcc-4c1b-bf6f-554499b91074
INFO 05/03/2025 05:21:04 PM UTC E-mail parsing finished: a9c88dc0-6fcc-4c1b-bf6f-554499b91074
INFO 05/03/2025 05:21:04 PM UTC New e-mail: 7d900e99-dbac-4ed7-af9c-57aff8b1c1a2
INFO 05/03/2025 05:21:04 PM UTC New e-mail: 7d900e99-dbac-4ed7-af9c-57aff8b1c1a2
Llama.generate: 489 prefix-match hit, remaining 1739 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1739 prompt tokens to eval
WARNING 05/03/2025 05:24:51 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b40b0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
WARNING 05/03/2025 05:24:51 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b40b0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 05:24:51 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 05:24:51 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 05:24:51 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 05:24:51 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 05:24:51 PM UTC Aborting transport connection: state=1; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 43322), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:24:51 PM UTC Aborting transport connection: state=1; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 43322), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:24:51 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 43322), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:24:51 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 43322), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:24:51 PM UTC Deactivating transport: state=1; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 43322), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:24:51 PM UTC Deactivating transport: state=1; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 43322), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:24:51 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 05:24:51 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 05:24:51 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 05:24:51 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 05:24:51 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 43322), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:24:51 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 43322), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:24:51 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
INFO 05/03/2025 05:24:51 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
Exception in thread Thread-7:
Exception in thread Thread-7:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/app/modules/parser.py", line 145, in run
  File "/app/modules/parser.py", line 145, in run
    self.mq_channel.start_consuming()
    self.mq_channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
    raise self._closing_reason  # pylint: disable=E0702
    raise self._closing_reason  # pylint: disable=E0702
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
WARNING 05/03/2025 05:24:52 PM UTC ParserThread unexpectedly crashed, restarted it
WARNING 05/03/2025 05:24:52 PM UTC ParserThread unexpectedly crashed, restarted it
INFO 05/03/2025 05:24:52 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 05:24:52 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 05:24:52 PM UTC Socket connected: <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 50738), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:24:52 PM UTC Socket connected: <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 50738), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:24:52 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b9b80>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b9b80> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 05:24:52 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b9b80>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b9b80> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 05:24:52 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b9b80> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:24:52 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b9b80> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:24:52 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b9b80> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:24:52 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b9b80> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:24:52 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b9b80> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:24:52 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b9b80> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:24:52 PM UTC Created channel=1
INFO 05/03/2025 05:24:52 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Available chat formats from metadata: chat_template.default
Available chat formats from metadata: chat_template.default
INFO 05/03/2025 05:25:02 PM UTC New e-mail: 652ea419-89a7-45f0-89f5-77a72db22e50
INFO 05/03/2025 05:25:02 PM UTC New e-mail: 652ea419-89a7-45f0-89f5-77a72db22e50
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print:        load time =   87095.53 ms
llama_perf_context_print: prompt eval time = 1853041.20 ms / 14895 tokens (  124.41 ms per token,     8.04 tokens per second)
llama_perf_context_print: prompt eval time = 1853041.20 ms / 14895 tokens (  124.41 ms per token,     8.04 tokens per second)
llama_perf_context_print:        eval time =    2152.74 ms /     1 runs   ( 2152.74 ms per token,     0.46 tokens per second)
llama_perf_context_print:        eval time =    2152.74 ms /     1 runs   ( 2152.74 ms per token,     0.46 tokens per second)
llama_perf_context_print:       total time = 1855315.44 ms / 14896 tokens
llama_perf_context_print:       total time = 1855315.44 ms / 14896 tokens
Exception in thread Thread-54 (_start_parsing):
Exception in thread Thread-54 (_start_parsing):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/usr/local/lib/python3.12/threading.py", line 1012, in run
  File "/usr/local/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
    self._target(*self._args, **self._kwargs)
  File "/app/modules/parser.py", line 110, in _start_parsing
  File "/app/modules/parser.py", line 110, in _start_parsing
    channel.connection.add_callback_threadsafe(cb)
    channel.connection.add_callback_threadsafe(cb)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 742, in add_callback_threadsafe
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 742, in add_callback_threadsafe
    raise exceptions.ConnectionWrongStateError(
    raise exceptions.ConnectionWrongStateError(
pika.exceptions.ConnectionWrongStateError: BlockingConnection.add_callback_threadsafe() called on closed or closing connection.
pika.exceptions.ConnectionWrongStateError: BlockingConnection.add_callback_threadsafe() called on closed or closing connection.
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =  202713.45 ms /  1739 tokens (  116.57 ms per token,     8.58 tokens per second)
llama_perf_context_print: prompt eval time =  202713.45 ms /  1739 tokens (  116.57 ms per token,     8.58 tokens per second)
llama_perf_context_print:        eval time =  110644.85 ms /   431 runs   (  256.72 ms per token,     3.90 tokens per second)
llama_perf_context_print:        eval time =  110644.85 ms /   431 runs   (  256.72 ms per token,     3.90 tokens per second)
llama_perf_context_print:       total time =  323061.86 ms /  2170 tokens
llama_perf_context_print:       total time =  323061.86 ms /  2170 tokens
INFO 05/03/2025 05:26:27 PM UTC E-mail parsing finished: 7d900e99-dbac-4ed7-af9c-57aff8b1c1a2
INFO 05/03/2025 05:26:27 PM UTC E-mail parsing finished: 7d900e99-dbac-4ed7-af9c-57aff8b1c1a2
INFO 05/03/2025 05:26:27 PM UTC New e-mail: 6a33d919-5b9e-4338-91cd-37d230c49431
INFO 05/03/2025 05:26:27 PM UTC New e-mail: 6a33d919-5b9e-4338-91cd-37d230c49431
Llama.generate: 489 prefix-match hit, remaining 251 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 251 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   40847.46 ms /   251 tokens (  162.74 ms per token,     6.14 tokens per second)
llama_perf_context_print: prompt eval time =   40847.46 ms /   251 tokens (  162.74 ms per token,     6.14 tokens per second)
llama_perf_context_print:        eval time =     214.70 ms /     1 runs   (  214.70 ms per token,     4.66 tokens per second)
llama_perf_context_print:        eval time =     214.70 ms /     1 runs   (  214.70 ms per token,     4.66 tokens per second)
llama_perf_context_print:       total time =   41094.51 ms /   252 tokens
llama_perf_context_print:       total time =   41094.51 ms /   252 tokens
INFO 05/03/2025 05:27:08 PM UTC E-mail parsing finished: 6a33d919-5b9e-4338-91cd-37d230c49431
INFO 05/03/2025 05:27:08 PM UTC E-mail parsing finished: 6a33d919-5b9e-4338-91cd-37d230c49431
INFO 05/03/2025 05:27:08 PM UTC New e-mail: e0b835c7-6ed8-407d-8d02-d3eaecb9818c
INFO 05/03/2025 05:27:08 PM UTC New e-mail: e0b835c7-6ed8-407d-8d02-d3eaecb9818c
Llama.generate: 489 prefix-match hit, remaining 637 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 637 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   89623.04 ms /   637 tokens (  140.70 ms per token,     7.11 tokens per second)
llama_perf_context_print: prompt eval time =   89623.04 ms /   637 tokens (  140.70 ms per token,     7.11 tokens per second)
llama_perf_context_print:        eval time =     230.02 ms /     1 runs   (  230.02 ms per token,     4.35 tokens per second)
llama_perf_context_print:        eval time =     230.02 ms /     1 runs   (  230.02 ms per token,     4.35 tokens per second)
llama_perf_context_print:       total time =   89895.02 ms /   638 tokens
llama_perf_context_print:       total time =   89895.02 ms /   638 tokens
INFO 05/03/2025 05:28:38 PM UTC E-mail parsing finished: e0b835c7-6ed8-407d-8d02-d3eaecb9818c
INFO 05/03/2025 05:28:38 PM UTC E-mail parsing finished: e0b835c7-6ed8-407d-8d02-d3eaecb9818c
INFO 05/03/2025 05:28:38 PM UTC New e-mail: 3fa25ca3-3edf-43cf-a879-fae776c71d07
INFO 05/03/2025 05:28:38 PM UTC New e-mail: 3fa25ca3-3edf-43cf-a879-fae776c71d07
Llama.generate: 538 prefix-match hit, remaining 558 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 558 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   89602.06 ms /   558 tokens (  160.58 ms per token,     6.23 tokens per second)
llama_perf_context_print: prompt eval time =   89602.06 ms /   558 tokens (  160.58 ms per token,     6.23 tokens per second)
llama_perf_context_print:        eval time =   40775.89 ms /   173 runs   (  235.70 ms per token,     4.24 tokens per second)
llama_perf_context_print:        eval time =   40775.89 ms /   173 runs   (  235.70 ms per token,     4.24 tokens per second)
llama_perf_context_print:       total time =  134304.33 ms /   731 tokens
llama_perf_context_print:       total time =  134304.33 ms /   731 tokens
INFO 05/03/2025 05:30:52 PM UTC E-mail parsing finished: 3fa25ca3-3edf-43cf-a879-fae776c71d07
INFO 05/03/2025 05:30:52 PM UTC E-mail parsing finished: 3fa25ca3-3edf-43cf-a879-fae776c71d07
INFO 05/03/2025 05:30:52 PM UTC New e-mail: 77aebdda-c75f-4fb8-8a6f-f052f7d754d2
INFO 05/03/2025 05:30:52 PM UTC New e-mail: 77aebdda-c75f-4fb8-8a6f-f052f7d754d2
Llama.generate: 536 prefix-match hit, remaining 586 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 586 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   92489.37 ms /   586 tokens (  157.83 ms per token,     6.34 tokens per second)
llama_perf_context_print: prompt eval time =   92489.37 ms /   586 tokens (  157.83 ms per token,     6.34 tokens per second)
llama_perf_context_print:        eval time =     195.84 ms /     1 runs   (  195.84 ms per token,     5.11 tokens per second)
llama_perf_context_print:        eval time =     195.84 ms /     1 runs   (  195.84 ms per token,     5.11 tokens per second)
llama_perf_context_print:       total time =   92722.66 ms /   587 tokens
llama_perf_context_print:       total time =   92722.66 ms /   587 tokens
INFO 05/03/2025 05:32:25 PM UTC E-mail parsing finished: 77aebdda-c75f-4fb8-8a6f-f052f7d754d2
INFO 05/03/2025 05:32:25 PM UTC E-mail parsing finished: 77aebdda-c75f-4fb8-8a6f-f052f7d754d2
INFO 05/03/2025 05:32:25 PM UTC New e-mail: 52a61e50-497f-4c0a-94b1-5dfd3c52cc0e
INFO 05/03/2025 05:32:25 PM UTC New e-mail: 52a61e50-497f-4c0a-94b1-5dfd3c52cc0e
Llama.generate: 538 prefix-match hit, remaining 690 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 690 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   95271.89 ms /   690 tokens (  138.08 ms per token,     7.24 tokens per second)
llama_perf_context_print: prompt eval time =   95271.89 ms /   690 tokens (  138.08 ms per token,     7.24 tokens per second)
llama_perf_context_print:        eval time =   27887.15 ms /   119 runs   (  234.35 ms per token,     4.27 tokens per second)
llama_perf_context_print:        eval time =   27887.15 ms /   119 runs   (  234.35 ms per token,     4.27 tokens per second)
llama_perf_context_print:       total time =  125991.57 ms /   809 tokens
llama_perf_context_print:       total time =  125991.57 ms /   809 tokens
INFO 05/03/2025 05:34:31 PM UTC E-mail parsing finished: 52a61e50-497f-4c0a-94b1-5dfd3c52cc0e
INFO 05/03/2025 05:34:31 PM UTC E-mail parsing finished: 52a61e50-497f-4c0a-94b1-5dfd3c52cc0e
INFO 05/03/2025 05:34:31 PM UTC New e-mail: 8e8f805f-597a-4cf4-86c5-b4e77e80fdaa
INFO 05/03/2025 05:34:31 PM UTC New e-mail: 8e8f805f-597a-4cf4-86c5-b4e77e80fdaa
Llama.generate: 540 prefix-match hit, remaining 1626 prompt tokens to eval
Llama.generate: 540 prefix-match hit, remaining 1626 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =  189648.68 ms /  1626 tokens (  116.64 ms per token,     8.57 tokens per second)
llama_perf_context_print: prompt eval time =  189648.68 ms /  1626 tokens (  116.64 ms per token,     8.57 tokens per second)
llama_perf_context_print:        eval time =   46478.60 ms /   182 runs   (  255.38 ms per token,     3.92 tokens per second)
llama_perf_context_print:        eval time =   46478.60 ms /   182 runs   (  255.38 ms per token,     3.92 tokens per second)
llama_perf_context_print:       total time =  239887.26 ms /  1808 tokens
llama_perf_context_print:       total time =  239887.26 ms /  1808 tokens
INFO 05/03/2025 05:38:31 PM UTC E-mail parsing finished: 8e8f805f-597a-4cf4-86c5-b4e77e80fdaa
INFO 05/03/2025 05:38:31 PM UTC E-mail parsing finished: 8e8f805f-597a-4cf4-86c5-b4e77e80fdaa
INFO 05/03/2025 05:38:31 PM UTC New e-mail: c710b1cd-7822-4207-b492-c2dcd5da0a6e
INFO 05/03/2025 05:38:31 PM UTC New e-mail: c710b1cd-7822-4207-b492-c2dcd5da0a6e
Llama.generate: 540 prefix-match hit, remaining 725 prompt tokens to eval
Llama.generate: 540 prefix-match hit, remaining 725 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   99730.32 ms /   725 tokens (  137.56 ms per token,     7.27 tokens per second)
llama_perf_context_print: prompt eval time =   99730.32 ms /   725 tokens (  137.56 ms per token,     7.27 tokens per second)
llama_perf_context_print:        eval time =   20337.47 ms /    87 runs   (  233.76 ms per token,     4.28 tokens per second)
llama_perf_context_print:        eval time =   20337.47 ms /    87 runs   (  233.76 ms per token,     4.28 tokens per second)
llama_perf_context_print:       total time =  121998.20 ms /   812 tokens
llama_perf_context_print:       total time =  121998.20 ms /   812 tokens
INFO 05/03/2025 05:40:33 PM UTC E-mail parsing finished: c710b1cd-7822-4207-b492-c2dcd5da0a6e
INFO 05/03/2025 05:40:33 PM UTC E-mail parsing finished: c710b1cd-7822-4207-b492-c2dcd5da0a6e
INFO 05/03/2025 05:40:33 PM UTC New e-mail: f33a83e1-acbf-443d-a3fe-9fabcf200306
INFO 05/03/2025 05:40:33 PM UTC New e-mail: f33a83e1-acbf-443d-a3fe-9fabcf200306
Llama.generate: 540 prefix-match hit, remaining 557 prompt tokens to eval
Llama.generate: 540 prefix-match hit, remaining 557 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   94009.94 ms /   557 tokens (  168.78 ms per token,     5.92 tokens per second)
llama_perf_context_print: prompt eval time =   94009.94 ms /   557 tokens (  168.78 ms per token,     5.92 tokens per second)
llama_perf_context_print:        eval time =   22696.28 ms /   100 runs   (  226.96 ms per token,     4.41 tokens per second)
llama_perf_context_print:        eval time =   22696.28 ms /   100 runs   (  226.96 ms per token,     4.41 tokens per second)
llama_perf_context_print:       total time =  119131.64 ms /   657 tokens
llama_perf_context_print:       total time =  119131.64 ms /   657 tokens
INFO 05/03/2025 05:42:32 PM UTC E-mail parsing finished: f33a83e1-acbf-443d-a3fe-9fabcf200306
INFO 05/03/2025 05:42:32 PM UTC E-mail parsing finished: f33a83e1-acbf-443d-a3fe-9fabcf200306
INFO 05/03/2025 05:42:32 PM UTC New e-mail: 13169737-1eae-4612-bce4-7820a2d537df
INFO 05/03/2025 05:42:32 PM UTC New e-mail: 13169737-1eae-4612-bce4-7820a2d537df
Llama.generate: 538 prefix-match hit, remaining 504 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 504 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   50278.07 ms /   504 tokens (   99.76 ms per token,    10.02 tokens per second)
llama_perf_context_print: prompt eval time =   50278.07 ms /   504 tokens (   99.76 ms per token,    10.02 tokens per second)
llama_perf_context_print:        eval time =     219.42 ms /     1 runs   (  219.42 ms per token,     4.56 tokens per second)
llama_perf_context_print:        eval time =     219.42 ms /     1 runs   (  219.42 ms per token,     4.56 tokens per second)
llama_perf_context_print:       total time =   50529.57 ms /   505 tokens
llama_perf_context_print:       total time =   50529.57 ms /   505 tokens
INFO 05/03/2025 05:43:23 PM UTC E-mail parsing finished: 13169737-1eae-4612-bce4-7820a2d537df
INFO 05/03/2025 05:43:23 PM UTC E-mail parsing finished: 13169737-1eae-4612-bce4-7820a2d537df
INFO 05/03/2025 05:43:23 PM UTC New e-mail: 54e02641-e329-493f-b1cc-ca73e887e725
INFO 05/03/2025 05:43:23 PM UTC New e-mail: 54e02641-e329-493f-b1cc-ca73e887e725
Llama.generate: 538 prefix-match hit, remaining 743 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 743 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   95358.57 ms /   743 tokens (  128.34 ms per token,     7.79 tokens per second)
llama_perf_context_print: prompt eval time =   95358.57 ms /   743 tokens (  128.34 ms per token,     7.79 tokens per second)
llama_perf_context_print:        eval time =   38698.16 ms /   166 runs   (  233.12 ms per token,     4.29 tokens per second)
llama_perf_context_print:        eval time =   38698.16 ms /   166 runs   (  233.12 ms per token,     4.29 tokens per second)
llama_perf_context_print:       total time =  137984.38 ms /   909 tokens
llama_perf_context_print:       total time =  137984.38 ms /   909 tokens
INFO 05/03/2025 05:45:41 PM UTC E-mail parsing finished: 54e02641-e329-493f-b1cc-ca73e887e725
INFO 05/03/2025 05:45:41 PM UTC E-mail parsing finished: 54e02641-e329-493f-b1cc-ca73e887e725
INFO 05/03/2025 05:45:41 PM UTC New e-mail: b48d1842-1d20-42db-aeba-7cb5a3f71c8c
INFO 05/03/2025 05:45:41 PM UTC New e-mail: b48d1842-1d20-42db-aeba-7cb5a3f71c8c
Llama.generate: 536 prefix-match hit, remaining 554 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 554 prompt tokens to eval
ERROR 05/03/2025 05:45:41 PM UTC Unknown exception occurred
ERROR 05/03/2025 05:45:41 PM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '1922-5' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '1922-5' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1922-5' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1922-5' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 1922, 'tag_id': 5}, {'event_id': 1922, 'tag_id': 6}, {'event_id': 1922, 'tag_id': 2}, {'event_id': 1922, 'tag_id': 5}]]
[parameters: [{'event_id': 1922, 'tag_id': 5}, {'event_id': 1922, 'tag_id': 6}, {'event_id': 1922, 'tag_id': 2}, {'event_id': 1922, 'tag_id': 5}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   88116.82 ms /   554 tokens (  159.06 ms per token,     6.29 tokens per second)
llama_perf_context_print: prompt eval time =   88116.82 ms /   554 tokens (  159.06 ms per token,     6.29 tokens per second)
llama_perf_context_print:        eval time =     196.60 ms /     1 runs   (  196.60 ms per token,     5.09 tokens per second)
llama_perf_context_print:        eval time =     196.60 ms /     1 runs   (  196.60 ms per token,     5.09 tokens per second)
llama_perf_context_print:       total time =   88353.59 ms /   555 tokens
llama_perf_context_print:       total time =   88353.59 ms /   555 tokens
INFO 05/03/2025 05:47:09 PM UTC E-mail parsing finished: b48d1842-1d20-42db-aeba-7cb5a3f71c8c
INFO 05/03/2025 05:47:09 PM UTC E-mail parsing finished: b48d1842-1d20-42db-aeba-7cb5a3f71c8c
INFO 05/03/2025 05:47:09 PM UTC New e-mail: 10be07a5-c1fa-41d0-927d-4ebe59e30855
INFO 05/03/2025 05:47:09 PM UTC New e-mail: 10be07a5-c1fa-41d0-927d-4ebe59e30855
Llama.generate: 538 prefix-match hit, remaining 507 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 507 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   53042.93 ms /   507 tokens (  104.62 ms per token,     9.56 tokens per second)
llama_perf_context_print: prompt eval time =   53042.93 ms /   507 tokens (  104.62 ms per token,     9.56 tokens per second)
llama_perf_context_print:        eval time =     208.41 ms /     1 runs   (  208.41 ms per token,     4.80 tokens per second)
llama_perf_context_print:        eval time =     208.41 ms /     1 runs   (  208.41 ms per token,     4.80 tokens per second)
llama_perf_context_print:       total time =   53297.89 ms /   508 tokens
llama_perf_context_print:       total time =   53297.89 ms /   508 tokens
INFO 05/03/2025 05:48:02 PM UTC E-mail parsing finished: 10be07a5-c1fa-41d0-927d-4ebe59e30855
INFO 05/03/2025 05:48:02 PM UTC E-mail parsing finished: 10be07a5-c1fa-41d0-927d-4ebe59e30855
INFO 05/03/2025 05:48:02 PM UTC New e-mail: a65b2d35-5c4d-4682-a23e-9488b3b020b9
INFO 05/03/2025 05:48:02 PM UTC New e-mail: a65b2d35-5c4d-4682-a23e-9488b3b020b9
Llama.generate: 489 prefix-match hit, remaining 1968 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1968 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =  205945.66 ms /  1968 tokens (  104.65 ms per token,     9.56 tokens per second)
llama_perf_context_print: prompt eval time =  205945.66 ms /  1968 tokens (  104.65 ms per token,     9.56 tokens per second)
llama_perf_context_print:        eval time =   16453.50 ms /    67 runs   (  245.57 ms per token,     4.07 tokens per second)
llama_perf_context_print:        eval time =   16453.50 ms /    67 runs   (  245.57 ms per token,     4.07 tokens per second)
llama_perf_context_print:       total time =  223801.70 ms /  2035 tokens
llama_perf_context_print:       total time =  223801.70 ms /  2035 tokens
INFO 05/03/2025 05:51:46 PM UTC E-mail parsing finished: a65b2d35-5c4d-4682-a23e-9488b3b020b9
INFO 05/03/2025 05:51:46 PM UTC E-mail parsing finished: a65b2d35-5c4d-4682-a23e-9488b3b020b9
INFO 05/03/2025 05:51:46 PM UTC New e-mail: 2cfb53b4-6a75-4294-b2ef-3750360d9c46
INFO 05/03/2025 05:51:46 PM UTC New e-mail: 2cfb53b4-6a75-4294-b2ef-3750360d9c46
Llama.generate: 489 prefix-match hit, remaining 182 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 182 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   44521.03 ms /   182 tokens (  244.62 ms per token,     4.09 tokens per second)
llama_perf_context_print: prompt eval time =   44521.03 ms /   182 tokens (  244.62 ms per token,     4.09 tokens per second)
llama_perf_context_print:        eval time =     201.27 ms /     1 runs   (  201.27 ms per token,     4.97 tokens per second)
llama_perf_context_print:        eval time =     201.27 ms /     1 runs   (  201.27 ms per token,     4.97 tokens per second)
llama_perf_context_print:       total time =   44753.62 ms /   183 tokens
llama_perf_context_print:       total time =   44753.62 ms /   183 tokens
INFO 05/03/2025 05:52:31 PM UTC E-mail parsing finished: 2cfb53b4-6a75-4294-b2ef-3750360d9c46
INFO 05/03/2025 05:52:31 PM UTC E-mail parsing finished: 2cfb53b4-6a75-4294-b2ef-3750360d9c46
INFO 05/03/2025 05:52:31 PM UTC New e-mail: 9c0061d4-0da9-4b51-a8c3-16362619e03c
INFO 05/03/2025 05:52:31 PM UTC New e-mail: 9c0061d4-0da9-4b51-a8c3-16362619e03c
Llama.generate: 489 prefix-match hit, remaining 369 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 369 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   49671.86 ms /   369 tokens (  134.61 ms per token,     7.43 tokens per second)
llama_perf_context_print: prompt eval time =   49671.86 ms /   369 tokens (  134.61 ms per token,     7.43 tokens per second)
llama_perf_context_print:        eval time =   34808.84 ms /   153 runs   (  227.51 ms per token,     4.40 tokens per second)
llama_perf_context_print:        eval time =   34808.84 ms /   153 runs   (  227.51 ms per token,     4.40 tokens per second)
llama_perf_context_print:       total time =   88375.74 ms /   522 tokens
llama_perf_context_print:       total time =   88375.74 ms /   522 tokens
INFO 05/03/2025 05:53:59 PM UTC E-mail parsing finished: 9c0061d4-0da9-4b51-a8c3-16362619e03c
INFO 05/03/2025 05:53:59 PM UTC E-mail parsing finished: 9c0061d4-0da9-4b51-a8c3-16362619e03c
INFO 05/03/2025 05:53:59 PM UTC New e-mail: 45c4c421-76a0-492e-916d-c6ed63b64860
INFO 05/03/2025 05:53:59 PM UTC New e-mail: 45c4c421-76a0-492e-916d-c6ed63b64860
Llama.generate: 489 prefix-match hit, remaining 137 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 137 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   43152.63 ms /   137 tokens (  314.98 ms per token,     3.17 tokens per second)
llama_perf_context_print: prompt eval time =   43152.63 ms /   137 tokens (  314.98 ms per token,     3.17 tokens per second)
llama_perf_context_print:        eval time =     216.55 ms /     1 runs   (  216.55 ms per token,     4.62 tokens per second)
llama_perf_context_print:        eval time =     216.55 ms /     1 runs   (  216.55 ms per token,     4.62 tokens per second)
llama_perf_context_print:       total time =   43412.15 ms /   138 tokens
llama_perf_context_print:       total time =   43412.15 ms /   138 tokens
INFO 05/03/2025 05:54:43 PM UTC E-mail parsing finished: 45c4c421-76a0-492e-916d-c6ed63b64860
INFO 05/03/2025 05:54:43 PM UTC E-mail parsing finished: 45c4c421-76a0-492e-916d-c6ed63b64860
INFO 05/03/2025 05:54:43 PM UTC New e-mail: 829f30c0-48cd-4579-9d0b-979c1f403325
INFO 05/03/2025 05:54:43 PM UTC New e-mail: 829f30c0-48cd-4579-9d0b-979c1f403325
Llama.generate: 489 prefix-match hit, remaining 488 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 488 prompt tokens to eval
WARNING 05/03/2025 05:55:02 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b9b80> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
WARNING 05/03/2025 05:55:02 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53b9b80> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 05:55:02 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 05:55:02 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 05:55:02 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 05:55:02 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 05:55:02 PM UTC Aborting transport connection: state=1; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 50738), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:55:02 PM UTC Aborting transport connection: state=1; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 50738), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:55:02 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 50738), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:55:02 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 50738), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:55:02 PM UTC Deactivating transport: state=1; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 50738), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:55:02 PM UTC Deactivating transport: state=1; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 50738), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:55:02 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 05:55:02 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 05:55:02 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 05:55:02 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 05:55:02 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 50738), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:55:02 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 50738), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:55:02 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
INFO 05/03/2025 05:55:02 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
Exception in thread Thread-55:
Exception in thread Thread-55:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/app/modules/parser.py", line 145, in run
  File "/app/modules/parser.py", line 145, in run
    self.mq_channel.start_consuming()
    self.mq_channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
    raise self._closing_reason  # pylint: disable=E0702
    raise self._closing_reason  # pylint: disable=E0702
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
WARNING 05/03/2025 05:55:02 PM UTC ParserThread unexpectedly crashed, restarted it
WARNING 05/03/2025 05:55:02 PM UTC ParserThread unexpectedly crashed, restarted it
INFO 05/03/2025 05:55:02 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 05:55:02 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 05:55:02 PM UTC Socket connected: <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 38886), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:55:02 PM UTC Socket connected: <socket.socket fd=8, family=2, type=1, proto=6, laddr=('10.0.1.27', 38886), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:55:02 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53fe780>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53fe780> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 05:55:02 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53fe780>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53fe780> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 05:55:02 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53fe780> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:02 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53fe780> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:02 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53fe780> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:02 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53fe780> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:02 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53fe780> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:02 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7be1f53fe780> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:02 PM UTC Created channel=1
INFO 05/03/2025 05:55:02 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
INFO 05/03/2025 05:55:11 PM UTC Creating default categories in database
INFO 05/03/2025 05:55:11 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 05:55:11 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 05:55:11 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 38902), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:55:11 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 38902), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:55:11 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f65310>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f65310> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 05:55:11 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f65310>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f65310> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 05:55:11 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f65310> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:11 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f65310> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:11 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f65310> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:11 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f65310> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:11 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f65310> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:11 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f65310> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:11 PM UTC Created channel=1
INFO 05/03/2025 05:55:11 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Available chat formats from metadata: chat_template.default
Available chat formats from metadata: chat_template.default
INFO 05/03/2025 05:55:15 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 05:55:15 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 05:55:15 PM UTC Socket connected: <socket.socket fd=13, family=2, type=1, proto=6, laddr=('10.0.1.27', 60232), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:55:15 PM UTC Socket connected: <socket.socket fd=13, family=2, type=1, proto=6, laddr=('10.0.1.27', 60232), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:55:15 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f672c0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f672c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 05:55:15 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f672c0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f672c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 05:55:15 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f672c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:15 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f672c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:15 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f672c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:15 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f672c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:15 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f672c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:15 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f672c0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:15 PM UTC Created channel=1
INFO 05/03/2025 05:55:15 PM UTC Created channel=1
INFO 05/03/2025 05:55:15 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 05:55:15 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 05:55:15 PM UTC New e-mail: 652ea419-89a7-45f0-89f5-77a72db22e50
INFO 05/03/2025 05:55:15 PM UTC New e-mail: 652ea419-89a7-45f0-89f5-77a72db22e50
INFO 05/03/2025 05:55:15 PM UTC Socket connected: <socket.socket fd=14, family=2, type=1, proto=6, laddr=('10.0.1.27', 60248), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:55:15 PM UTC Socket connected: <socket.socket fd=14, family=2, type=1, proto=6, laddr=('10.0.1.27', 60248), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 05:55:15 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f8f260>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f8f260> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 05:55:15 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f8f260>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f8f260> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 05:55:15 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f8f260> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:15 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f8f260> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:15 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f8f260> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:15 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f8f260> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:15 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f8f260> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:15 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f8f260> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 05:55:15 PM UTC Created channel=1
INFO 05/03/2025 05:55:15 PM UTC Created channel=1
INFO 05/03/2025 05:55:15 PM UTC Server started
INFO 05/03/2025 05:55:15 PM UTC Server started
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   58624.39 ms /   488 tokens (  120.13 ms per token,     8.32 tokens per second)
llama_perf_context_print: prompt eval time =   58624.39 ms /   488 tokens (  120.13 ms per token,     8.32 tokens per second)
llama_perf_context_print:        eval time =   17392.84 ms /    75 runs   (  231.90 ms per token,     4.31 tokens per second)
llama_perf_context_print:        eval time =   17392.84 ms /    75 runs   (  231.90 ms per token,     4.31 tokens per second)
llama_perf_context_print:       total time =   77503.83 ms /   563 tokens
llama_perf_context_print:       total time =   77503.83 ms /   563 tokens
INFO 05/03/2025 05:56:00 PM UTC E-mail parsing finished: 829f30c0-48cd-4579-9d0b-979c1f403325
INFO 05/03/2025 05:56:00 PM UTC E-mail parsing finished: 829f30c0-48cd-4579-9d0b-979c1f403325
INFO 05/03/2025 05:56:00 PM UTC New e-mail: 42bd23c7-2464-4715-8f4a-8e0976a9a18a
INFO 05/03/2025 05:56:00 PM UTC New e-mail: 42bd23c7-2464-4715-8f4a-8e0976a9a18a
Llama.generate: 489 prefix-match hit, remaining 454 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 454 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   54518.57 ms /   454 tokens (  120.08 ms per token,     8.33 tokens per second)
llama_perf_context_print: prompt eval time =   54518.57 ms /   454 tokens (  120.08 ms per token,     8.33 tokens per second)
llama_perf_context_print:        eval time =   20983.95 ms /    93 runs   (  225.63 ms per token,     4.43 tokens per second)
llama_perf_context_print:        eval time =   20983.95 ms /    93 runs   (  225.63 ms per token,     4.43 tokens per second)
llama_perf_context_print:       total time =   77731.15 ms /   547 tokens
llama_perf_context_print:       total time =   77731.15 ms /   547 tokens
INFO 05/03/2025 05:57:18 PM UTC E-mail parsing finished: 42bd23c7-2464-4715-8f4a-8e0976a9a18a
INFO 05/03/2025 05:57:18 PM UTC E-mail parsing finished: 42bd23c7-2464-4715-8f4a-8e0976a9a18a
INFO 05/03/2025 05:57:18 PM UTC New e-mail: 654d9c4d-c483-438c-ba69-97c3819d46c2
INFO 05/03/2025 05:57:18 PM UTC New e-mail: 654d9c4d-c483-438c-ba69-97c3819d46c2
Llama.generate: 489 prefix-match hit, remaining 172 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 172 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   47482.68 ms /   172 tokens (  276.06 ms per token,     3.62 tokens per second)
llama_perf_context_print: prompt eval time =   47482.68 ms /   172 tokens (  276.06 ms per token,     3.62 tokens per second)
llama_perf_context_print:        eval time =     217.54 ms /     1 runs   (  217.54 ms per token,     4.60 tokens per second)
llama_perf_context_print:        eval time =     217.54 ms /     1 runs   (  217.54 ms per token,     4.60 tokens per second)
llama_perf_context_print:       total time =   47788.08 ms /   173 tokens
llama_perf_context_print:       total time =   47788.08 ms /   173 tokens
INFO 05/03/2025 05:58:06 PM UTC E-mail parsing finished: 654d9c4d-c483-438c-ba69-97c3819d46c2
INFO 05/03/2025 05:58:06 PM UTC E-mail parsing finished: 654d9c4d-c483-438c-ba69-97c3819d46c2
INFO 05/03/2025 05:58:06 PM UTC New e-mail: 097e7dbf-4367-4ca0-9813-f894c312d93e
INFO 05/03/2025 05:58:06 PM UTC New e-mail: 097e7dbf-4367-4ca0-9813-f894c312d93e
Llama.generate: 489 prefix-match hit, remaining 137 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 137 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   48358.97 ms /   137 tokens (  352.99 ms per token,     2.83 tokens per second)
llama_perf_context_print: prompt eval time =   48358.97 ms /   137 tokens (  352.99 ms per token,     2.83 tokens per second)
llama_perf_context_print:        eval time =     271.97 ms /     1 runs   (  271.97 ms per token,     3.68 tokens per second)
llama_perf_context_print:        eval time =     271.97 ms /     1 runs   (  271.97 ms per token,     3.68 tokens per second)
llama_perf_context_print:       total time =   48661.65 ms /   138 tokens
llama_perf_context_print:       total time =   48661.65 ms /   138 tokens
INFO 05/03/2025 05:58:54 PM UTC E-mail parsing finished: 097e7dbf-4367-4ca0-9813-f894c312d93e
INFO 05/03/2025 05:58:54 PM UTC E-mail parsing finished: 097e7dbf-4367-4ca0-9813-f894c312d93e
INFO 05/03/2025 05:58:54 PM UTC New e-mail: 17c64a55-f77b-4fa7-815f-36b6f995169a
INFO 05/03/2025 05:58:54 PM UTC New e-mail: 17c64a55-f77b-4fa7-815f-36b6f995169a
Llama.generate: 532 prefix-match hit, remaining 94 prompt tokens to eval
Llama.generate: 532 prefix-match hit, remaining 94 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   48963.39 ms /    94 tokens (  520.89 ms per token,     1.92 tokens per second)
llama_perf_context_print: prompt eval time =   48963.39 ms /    94 tokens (  520.89 ms per token,     1.92 tokens per second)
llama_perf_context_print:        eval time =     219.39 ms /     1 runs   (  219.39 ms per token,     4.56 tokens per second)
llama_perf_context_print:        eval time =     219.39 ms /     1 runs   (  219.39 ms per token,     4.56 tokens per second)
llama_perf_context_print:       total time =   49239.63 ms /    95 tokens
llama_perf_context_print:       total time =   49239.63 ms /    95 tokens
INFO 05/03/2025 05:59:44 PM UTC E-mail parsing finished: 17c64a55-f77b-4fa7-815f-36b6f995169a
INFO 05/03/2025 05:59:44 PM UTC E-mail parsing finished: 17c64a55-f77b-4fa7-815f-36b6f995169a
INFO 05/03/2025 05:59:44 PM UTC New e-mail: 3acab8d4-131c-43e6-b1da-038d7d7cd653
INFO 05/03/2025 05:59:44 PM UTC New e-mail: 3acab8d4-131c-43e6-b1da-038d7d7cd653
Llama.generate: 538 prefix-match hit, remaining 432 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 432 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   53616.05 ms /   432 tokens (  124.11 ms per token,     8.06 tokens per second)
llama_perf_context_print: prompt eval time =   53616.05 ms /   432 tokens (  124.11 ms per token,     8.06 tokens per second)
llama_perf_context_print:        eval time =     216.98 ms /     1 runs   (  216.98 ms per token,     4.61 tokens per second)
llama_perf_context_print:        eval time =     216.98 ms /     1 runs   (  216.98 ms per token,     4.61 tokens per second)
llama_perf_context_print:       total time =   53883.38 ms /   433 tokens
llama_perf_context_print:       total time =   53883.38 ms /   433 tokens
INFO 05/03/2025 06:00:38 PM UTC E-mail parsing finished: 3acab8d4-131c-43e6-b1da-038d7d7cd653
INFO 05/03/2025 06:00:38 PM UTC E-mail parsing finished: 3acab8d4-131c-43e6-b1da-038d7d7cd653
INFO 05/03/2025 06:00:38 PM UTC New e-mail: 12de39bd-a897-4fa1-94e2-cf7be607c6af
INFO 05/03/2025 06:00:38 PM UTC New e-mail: 12de39bd-a897-4fa1-94e2-cf7be607c6af
Llama.generate: 489 prefix-match hit, remaining 427 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 427 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   55916.22 ms /   427 tokens (  130.95 ms per token,     7.64 tokens per second)
llama_perf_context_print: prompt eval time =   55916.22 ms /   427 tokens (  130.95 ms per token,     7.64 tokens per second)
llama_perf_context_print:        eval time =   25139.46 ms /   107 runs   (  234.95 ms per token,     4.26 tokens per second)
llama_perf_context_print:        eval time =   25139.46 ms /   107 runs   (  234.95 ms per token,     4.26 tokens per second)
llama_perf_context_print:       total time =   83606.06 ms /   534 tokens
llama_perf_context_print:       total time =   83606.06 ms /   534 tokens
INFO 05/03/2025 06:02:01 PM UTC E-mail parsing finished: 12de39bd-a897-4fa1-94e2-cf7be607c6af
INFO 05/03/2025 06:02:01 PM UTC E-mail parsing finished: 12de39bd-a897-4fa1-94e2-cf7be607c6af
INFO 05/03/2025 06:02:01 PM UTC New e-mail: dd88c3d9-2006-4d24-acd2-9f72ae5f2233
INFO 05/03/2025 06:02:01 PM UTC New e-mail: dd88c3d9-2006-4d24-acd2-9f72ae5f2233
Llama.generate: 489 prefix-match hit, remaining 152 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 152 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   48192.84 ms /   152 tokens (  317.06 ms per token,     3.15 tokens per second)
llama_perf_context_print: prompt eval time =   48192.84 ms /   152 tokens (  317.06 ms per token,     3.15 tokens per second)
llama_perf_context_print:        eval time =     226.80 ms /     1 runs   (  226.80 ms per token,     4.41 tokens per second)
llama_perf_context_print:        eval time =     226.80 ms /     1 runs   (  226.80 ms per token,     4.41 tokens per second)
llama_perf_context_print:       total time =   48468.02 ms /   153 tokens
llama_perf_context_print:       total time =   48468.02 ms /   153 tokens
INFO 05/03/2025 06:02:50 PM UTC E-mail parsing finished: dd88c3d9-2006-4d24-acd2-9f72ae5f2233
INFO 05/03/2025 06:02:50 PM UTC E-mail parsing finished: dd88c3d9-2006-4d24-acd2-9f72ae5f2233
INFO 05/03/2025 06:02:50 PM UTC New e-mail: 199853be-5b34-416d-b090-9b37ded7c594
INFO 05/03/2025 06:02:50 PM UTC New e-mail: 199853be-5b34-416d-b090-9b37ded7c594
Llama.generate: 489 prefix-match hit, remaining 238 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 238 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   48618.94 ms /   238 tokens (  204.28 ms per token,     4.90 tokens per second)
llama_perf_context_print: prompt eval time =   48618.94 ms /   238 tokens (  204.28 ms per token,     4.90 tokens per second)
llama_perf_context_print:        eval time =     233.23 ms /     1 runs   (  233.23 ms per token,     4.29 tokens per second)
llama_perf_context_print:        eval time =     233.23 ms /     1 runs   (  233.23 ms per token,     4.29 tokens per second)
llama_perf_context_print:       total time =   48901.69 ms /   239 tokens
llama_perf_context_print:       total time =   48901.69 ms /   239 tokens
INFO 05/03/2025 06:03:39 PM UTC E-mail parsing finished: 199853be-5b34-416d-b090-9b37ded7c594
INFO 05/03/2025 06:03:39 PM UTC E-mail parsing finished: 199853be-5b34-416d-b090-9b37ded7c594
INFO 05/03/2025 06:03:39 PM UTC New e-mail: e191cbac-19b0-4263-9d75-b278221f1bbc
INFO 05/03/2025 06:03:39 PM UTC New e-mail: e191cbac-19b0-4263-9d75-b278221f1bbc
Llama.generate: 489 prefix-match hit, remaining 184 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 184 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =   47821.02 ms /   184 tokens (  259.90 ms per token,     3.85 tokens per second)
llama_perf_context_print: prompt eval time =   47821.02 ms /   184 tokens (  259.90 ms per token,     3.85 tokens per second)
llama_perf_context_print:        eval time =     221.42 ms /     1 runs   (  221.42 ms per token,     4.52 tokens per second)
llama_perf_context_print:        eval time =     221.42 ms /     1 runs   (  221.42 ms per token,     4.52 tokens per second)
llama_perf_context_print:       total time =   48072.55 ms /   185 tokens
llama_perf_context_print:       total time =   48072.55 ms /   185 tokens
INFO 05/03/2025 06:04:27 PM UTC E-mail parsing finished: e191cbac-19b0-4263-9d75-b278221f1bbc
INFO 05/03/2025 06:04:27 PM UTC E-mail parsing finished: e191cbac-19b0-4263-9d75-b278221f1bbc
INFO 05/03/2025 06:04:27 PM UTC New e-mail: 2daff839-66b4-490a-b474-6dbf9cb3f660
INFO 05/03/2025 06:04:27 PM UTC New e-mail: 2daff839-66b4-490a-b474-6dbf9cb3f660
Llama.generate: 489 prefix-match hit, remaining 921 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 921 prompt tokens to eval
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time =  101748.54 ms /   921 tokens (  110.48 ms per token,     9.05 tokens per second)
llama_perf_context_print: prompt eval time =  101748.54 ms /   921 tokens (  110.48 ms per token,     9.05 tokens per second)
llama_perf_context_print:        eval time =   40442.43 ms /   169 runs   (  239.30 ms per token,     4.18 tokens per second)
llama_perf_context_print:        eval time =   40442.43 ms /   169 runs   (  239.30 ms per token,     4.18 tokens per second)
llama_perf_context_print:       total time =  145877.19 ms /  1090 tokens
llama_perf_context_print:       total time =  145877.19 ms /  1090 tokens
INFO 05/03/2025 06:06:53 PM UTC E-mail parsing finished: 2daff839-66b4-490a-b474-6dbf9cb3f660
INFO 05/03/2025 06:06:53 PM UTC E-mail parsing finished: 2daff839-66b4-490a-b474-6dbf9cb3f660
INFO 05/03/2025 06:06:53 PM UTC New e-mail: e3244885-6f23-4b3f-8c4a-37d2309b9540
INFO 05/03/2025 06:06:53 PM UTC New e-mail: e3244885-6f23-4b3f-8c4a-37d2309b9540
Llama.generate: 489 prefix-match hit, remaining 14532 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 14532 prompt tokens to eval
WARNING 05/03/2025 06:25:15 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f65310> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
WARNING 05/03/2025 06:25:15 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f65310> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 06:25:15 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 06:25:15 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 06:25:15 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 06:25:15 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 06:25:15 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 38902), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:25:15 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 38902), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:25:15 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 38902), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:25:15 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 38902), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:25:15 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 38902), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:25:15 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 38902), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:25:15 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 06:25:15 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 06:25:15 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 06:25:15 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 06:25:15 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 38902), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:25:15 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 38902), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:25:15 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
INFO 05/03/2025 06:25:15 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
Exception in thread Thread-1:
Exception in thread Thread-1:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/app/modules/parser.py", line 145, in run
  File "/app/modules/parser.py", line 145, in run
    self.mq_channel.start_consuming()
    self.mq_channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
    raise self._closing_reason  # pylint: disable=E0702
    raise self._closing_reason  # pylint: disable=E0702
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
WARNING 05/03/2025 06:25:15 PM UTC ParserThread unexpectedly crashed, restarted it
WARNING 05/03/2025 06:25:15 PM UTC ParserThread unexpectedly crashed, restarted it
INFO 05/03/2025 06:25:15 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 06:25:15 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 06:25:15 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 34346), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:25:15 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 34346), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:25:15 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f94cb0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f94cb0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 06:25:15 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f94cb0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f94cb0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 06:25:15 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f94cb0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 06:25:15 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f94cb0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 06:25:15 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f94cb0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 06:25:15 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f94cb0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 06:25:15 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f94cb0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 06:25:15 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f94cb0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 06:25:15 PM UTC Created channel=1
INFO 05/03/2025 06:25:15 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Available chat formats from metadata: chat_template.default
Available chat formats from metadata: chat_template.default
INFO 05/03/2025 06:25:26 PM UTC New e-mail: 652ea419-89a7-45f0-89f5-77a72db22e50
INFO 05/03/2025 06:25:26 PM UTC New e-mail: 652ea419-89a7-45f0-89f5-77a72db22e50
llama_perf_context_print:        load time = 1874373.65 ms
llama_perf_context_print:        load time = 1874373.65 ms
llama_perf_context_print: prompt eval time = 1874372.36 ms / 15384 tokens (  121.84 ms per token,     8.21 tokens per second)
llama_perf_context_print: prompt eval time = 1874372.36 ms / 15384 tokens (  121.84 ms per token,     8.21 tokens per second)
llama_perf_context_print:        eval time =  236200.66 ms /   110 runs   ( 2147.28 ms per token,     0.47 tokens per second)
llama_perf_context_print:        eval time =  236200.66 ms /   110 runs   ( 2147.28 ms per token,     0.47 tokens per second)
llama_perf_context_print:       total time = 2117622.97 ms / 15494 tokens
llama_perf_context_print:       total time = 2117622.97 ms / 15494 tokens
Exception in thread Thread-5 (_start_parsing):
Exception in thread Thread-5 (_start_parsing):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/usr/local/lib/python3.12/threading.py", line 1012, in run
  File "/usr/local/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
    self._target(*self._args, **self._kwargs)
  File "/app/modules/parser.py", line 110, in _start_parsing
  File "/app/modules/parser.py", line 110, in _start_parsing
    channel.connection.add_callback_threadsafe(cb)
    channel.connection.add_callback_threadsafe(cb)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 742, in add_callback_threadsafe
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 742, in add_callback_threadsafe
    raise exceptions.ConnectionWrongStateError(
    raise exceptions.ConnectionWrongStateError(
pika.exceptions.ConnectionWrongStateError: BlockingConnection.add_callback_threadsafe() called on closed or closing connection.
pika.exceptions.ConnectionWrongStateError: BlockingConnection.add_callback_threadsafe() called on closed or closing connection.
WARNING 05/03/2025 06:37:14 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7769139500e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
WARNING 05/03/2025 06:37:14 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7769139500e0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 06:37:14 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 06:37:14 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 06:37:14 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 06:37:14 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 06:37:14 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 49776), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:37:14 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 49776), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:37:14 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 49776), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:37:14 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 49776), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:37:14 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 49776), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:37:14 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 49776), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:37:14 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 06:37:14 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 06:37:14 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 06:37:14 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 06:37:14 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 49776), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:37:14 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 49776), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:37:14 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
INFO 05/03/2025 06:37:14 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
Exception in thread Thread-1:
Exception in thread Thread-1:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/app/modules/parser.py", line 145, in run
  File "/app/modules/parser.py", line 145, in run
    self.mq_channel.start_consuming()
    self.mq_channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
    raise self._closing_reason  # pylint: disable=E0702
    raise self._closing_reason  # pylint: disable=E0702
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
WARNING 05/03/2025 06:37:15 PM UTC ParserThread unexpectedly crashed, restarted it
WARNING 05/03/2025 06:37:15 PM UTC ParserThread unexpectedly crashed, restarted it
INFO 05/03/2025 06:37:15 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 06:37:15 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 06:37:15 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 47244), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:37:15 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 47244), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 06:37:15 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x776906f70740>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x776906f70740> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 06:37:15 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x776906f70740>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x776906f70740> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 06:37:15 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x776906f70740> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 06:37:15 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x776906f70740> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 06:37:15 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x776906f70740> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 06:37:15 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x776906f70740> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 06:37:15 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x776906f70740> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 06:37:15 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x776906f70740> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 06:37:15 PM UTC Created channel=1
INFO 05/03/2025 06:37:15 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Available chat formats from metadata: chat_template.default
Available chat formats from metadata: chat_template.default
INFO 05/03/2025 06:37:22 PM UTC New e-mail: e3244885-6f23-4b3f-8c4a-37d2309b9540
INFO 05/03/2025 06:37:22 PM UTC New e-mail: e3244885-6f23-4b3f-8c4a-37d2309b9540
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print:        load time = 1428400.39 ms
llama_perf_context_print: prompt eval time = 1820798.15 ms / 14532 tokens (  125.30 ms per token,     7.98 tokens per second)
llama_perf_context_print: prompt eval time = 1820798.15 ms / 14532 tokens (  125.30 ms per token,     7.98 tokens per second)
llama_perf_context_print:        eval time =  197351.79 ms /   102 runs   ( 1934.82 ms per token,     0.52 tokens per second)
llama_perf_context_print:        eval time =  197351.79 ms /   102 runs   ( 1934.82 ms per token,     0.52 tokens per second)
llama_perf_context_print:       total time = 2025008.61 ms / 14634 tokens
llama_perf_context_print:       total time = 2025008.61 ms / 14634 tokens
Exception in thread Thread-37 (_start_parsing):
Exception in thread Thread-37 (_start_parsing):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/usr/local/lib/python3.12/threading.py", line 1012, in run
  File "/usr/local/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
    self._target(*self._args, **self._kwargs)
  File "/app/modules/parser.py", line 110, in _start_parsing
  File "/app/modules/parser.py", line 110, in _start_parsing
    channel.connection.add_callback_threadsafe(cb)
    channel.connection.add_callback_threadsafe(cb)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 742, in add_callback_threadsafe
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 742, in add_callback_threadsafe
    raise exceptions.ConnectionWrongStateError(
    raise exceptions.ConnectionWrongStateError(
pika.exceptions.ConnectionWrongStateError: BlockingConnection.add_callback_threadsafe() called on closed or closing connection.
pika.exceptions.ConnectionWrongStateError: BlockingConnection.add_callback_threadsafe() called on closed or closing connection.
llama_perf_context_print:        load time = 1727680.63 ms
llama_perf_context_print:        load time = 1727680.63 ms
llama_perf_context_print: prompt eval time = 1727613.93 ms / 15384 tokens (  112.30 ms per token,     8.90 tokens per second)
llama_perf_context_print: prompt eval time = 1727613.93 ms / 15384 tokens (  112.30 ms per token,     8.90 tokens per second)
llama_perf_context_print:        eval time =    6282.68 ms /     1 runs   ( 6282.68 ms per token,     0.16 tokens per second)
llama_perf_context_print:        eval time =    6282.68 ms /     1 runs   ( 6282.68 ms per token,     0.16 tokens per second)
llama_perf_context_print:       total time = 1734003.58 ms / 15385 tokens
llama_perf_context_print:       total time = 1734003.58 ms / 15385 tokens
INFO 05/03/2025 06:54:20 PM UTC E-mail parsing finished: 652ea419-89a7-45f0-89f5-77a72db22e50
INFO 05/03/2025 06:54:20 PM UTC E-mail parsing finished: 652ea419-89a7-45f0-89f5-77a72db22e50
INFO 05/03/2025 06:54:20 PM UTC New e-mail: 9e216b5c-2daf-44f4-b939-9a4a83cdd235
INFO 05/03/2025 06:54:20 PM UTC New e-mail: 9e216b5c-2daf-44f4-b939-9a4a83cdd235
Llama.generate: 489 prefix-match hit, remaining 476 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 476 prompt tokens to eval
WARNING 05/03/2025 07:07:22 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x776906f70740> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
WARNING 05/03/2025 07:07:22 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x776906f70740> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 07:07:22 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 07:07:22 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 07:07:22 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 07:07:22 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 07:07:22 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 47244), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:07:22 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 47244), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:07:22 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 47244), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:07:22 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 47244), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:07:22 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 47244), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:07:22 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 47244), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:07:22 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 07:07:22 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 07:07:22 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 07:07:22 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 07:07:22 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 47244), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:07:22 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 47244), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:07:22 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
INFO 05/03/2025 07:07:22 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
Exception in thread Thread-38:
Exception in thread Thread-38:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/app/modules/parser.py", line 145, in run
  File "/app/modules/parser.py", line 145, in run
    self.mq_channel.start_consuming()
    self.mq_channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
    raise self._closing_reason  # pylint: disable=E0702
    raise self._closing_reason  # pylint: disable=E0702
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
WARNING 05/03/2025 07:07:27 PM UTC ParserThread unexpectedly crashed, restarted it
WARNING 05/03/2025 07:07:27 PM UTC ParserThread unexpectedly crashed, restarted it
INFO 05/03/2025 07:07:27 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:07:27 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:07:27 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 57282), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:07:27 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 57282), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:07:27 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbd3d40>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbd3d40> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:07:27 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbd3d40>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbd3d40> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:07:27 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbd3d40> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:07:27 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbd3d40> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:07:27 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbd3d40> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:07:27 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbd3d40> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:07:27 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbd3d40> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:07:27 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7768fdbd3d40> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:07:27 PM UTC Created channel=1
INFO 05/03/2025 07:07:27 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
INFO 05/03/2025 07:08:00 PM UTC Creating default categories in database
INFO 05/03/2025 07:08:00 PM UTC Creating default categories in database
INFO 05/03/2025 07:08:00 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:08:00 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:08:00 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 35160), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:08:00 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 35160), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:08:00 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337917f0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337917f0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:08:00 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337917f0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337917f0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:08:00 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337917f0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:00 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337917f0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:00 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337917f0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:00 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337917f0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:00 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337917f0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:00 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337917f0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:00 PM UTC Created channel=1
INFO 05/03/2025 07:08:00 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Available chat formats from metadata: chat_template.default
Available chat formats from metadata: chat_template.default
INFO 05/03/2025 07:08:22 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:08:22 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:08:22 PM UTC Socket connected: <socket.socket fd=13, family=2, type=1, proto=6, laddr=('10.0.1.190', 35626), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:08:22 PM UTC Socket connected: <socket.socket fd=13, family=2, type=1, proto=6, laddr=('10.0.1.190', 35626), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:08:22 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337934a0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337934a0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:08:22 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337934a0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337934a0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:08:22 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337934a0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:22 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337934a0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:22 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337934a0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:22 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337934a0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:22 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337934a0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:22 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337934a0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:22 PM UTC Created channel=1
INFO 05/03/2025 07:08:22 PM UTC Created channel=1
INFO 05/03/2025 07:08:22 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:08:22 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:08:22 PM UTC Socket connected: <socket.socket fd=17, family=2, type=1, proto=6, laddr=('10.0.1.190', 35638), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:08:22 PM UTC Socket connected: <socket.socket fd=17, family=2, type=1, proto=6, laddr=('10.0.1.190', 35638), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:08:22 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337bba40>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337bba40> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:08:22 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337bba40>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337bba40> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:08:22 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337bba40> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:22 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337bba40> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:22 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337bba40> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:22 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337bba40> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:22 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337bba40> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:22 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337bba40> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:08:22 PM UTC Created channel=1
INFO 05/03/2025 07:08:22 PM UTC Created channel=1
INFO 05/03/2025 07:08:22 PM UTC Server started
INFO 05/03/2025 07:08:22 PM UTC Server started
INFO 05/03/2025 07:08:22 PM UTC New e-mail: e3244885-6f23-4b3f-8c4a-37d2309b9540
INFO 05/03/2025 07:08:22 PM UTC New e-mail: e3244885-6f23-4b3f-8c4a-37d2309b9540
WARNING 05/03/2025 07:24:26 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f94cb0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
WARNING 05/03/2025 07:24:26 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f94cb0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 07:24:26 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 07:24:26 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 07:24:26 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 07:24:26 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 07:24:26 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 34346), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:24:26 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 34346), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:24:26 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 34346), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:24:26 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 34346), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:24:26 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 34346), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:24:26 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 34346), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:24:26 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 07:24:26 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 07:24:26 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 07:24:26 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 07:24:26 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 34346), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:24:26 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 34346), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:24:26 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
INFO 05/03/2025 07:24:26 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
Exception in thread Thread-8:
Exception in thread Thread-8:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/app/modules/parser.py", line 145, in run
  File "/app/modules/parser.py", line 145, in run
    self.mq_channel.start_consuming()
    self.mq_channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
    raise self._closing_reason  # pylint: disable=E0702
    raise self._closing_reason  # pylint: disable=E0702
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
WARNING 05/03/2025 07:24:26 PM UTC ParserThread unexpectedly crashed, restarted it
WARNING 05/03/2025 07:24:26 PM UTC ParserThread unexpectedly crashed, restarted it
INFO 05/03/2025 07:24:26 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:24:26 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:24:26 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 57550), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:24:26 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 57550), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:24:26 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f96060>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f96060> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:24:26 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f96060>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f96060> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:24:26 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f96060> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:24:26 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f96060> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:24:26 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f96060> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:24:26 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f96060> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:24:26 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f96060> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:24:26 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe7f8f96060> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:24:26 PM UTC Created channel=1
INFO 05/03/2025 07:24:26 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
INFO 05/03/2025 07:24:58 PM UTC Creating default categories in database
INFO 05/03/2025 07:24:58 PM UTC Creating default categories in database
INFO 05/03/2025 07:24:58 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:24:58 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:24:58 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 40970), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:24:58 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.27', 40970), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:24:58 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192030>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192030> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:24:58 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192030>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192030> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:24:58 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192030> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:24:58 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192030> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:24:58 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192030> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:24:58 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192030> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:24:58 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192030> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:24:58 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192030> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:24:58 PM UTC Created channel=1
INFO 05/03/2025 07:24:58 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Available chat formats from metadata: chat_template.default
Available chat formats from metadata: chat_template.default
INFO 05/03/2025 07:25:08 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:25:08 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:25:08 PM UTC Socket connected: <socket.socket fd=13, family=2, type=1, proto=6, laddr=('10.0.1.27', 39310), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:25:08 PM UTC Socket connected: <socket.socket fd=13, family=2, type=1, proto=6, laddr=('10.0.1.27', 39310), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:25:08 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192f90>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192f90> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:25:08 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192f90>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192f90> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:25:08 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192f90> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:25:08 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192f90> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:25:08 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192f90> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:25:08 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192f90> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:25:08 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192f90> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:25:08 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d192f90> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:25:08 PM UTC Created channel=1
INFO 05/03/2025 07:25:08 PM UTC Created channel=1
INFO 05/03/2025 07:25:08 PM UTC New e-mail: 9e216b5c-2daf-44f4-b939-9a4a83cdd235
INFO 05/03/2025 07:25:08 PM UTC New e-mail: 9e216b5c-2daf-44f4-b939-9a4a83cdd235
INFO 05/03/2025 07:25:08 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:25:08 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:25:08 PM UTC Socket connected: <socket.socket fd=17, family=2, type=1, proto=6, laddr=('10.0.1.27', 39318), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:25:08 PM UTC Socket connected: <socket.socket fd=17, family=2, type=1, proto=6, laddr=('10.0.1.27', 39318), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:25:08 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d1bbf50>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d1bbf50> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:25:08 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d1bbf50>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d1bbf50> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:25:08 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d1bbf50> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:25:08 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d1bbf50> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:25:08 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d1bbf50> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:25:08 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d1bbf50> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:25:08 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d1bbf50> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:25:08 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x75281d1bbf50> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:25:08 PM UTC Created channel=1
INFO 05/03/2025 07:25:08 PM UTC Created channel=1
INFO 05/03/2025 07:25:08 PM UTC Server started
INFO 05/03/2025 07:25:08 PM UTC Server started
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  103772.56 ms /   965 tokens (  107.54 ms per token,     9.30 tokens per second)
llama_perf_context_print: prompt eval time =  103772.56 ms /   965 tokens (  107.54 ms per token,     9.30 tokens per second)
llama_perf_context_print:        eval time =   23090.52 ms /   100 runs   (  230.91 ms per token,     4.33 tokens per second)
llama_perf_context_print:        eval time =   23090.52 ms /   100 runs   (  230.91 ms per token,     4.33 tokens per second)
llama_perf_context_print:       total time =  129400.42 ms /  1065 tokens
llama_perf_context_print:       total time =  129400.42 ms /  1065 tokens
INFO 05/03/2025 07:27:18 PM UTC E-mail parsing finished: 9e216b5c-2daf-44f4-b939-9a4a83cdd235
INFO 05/03/2025 07:27:18 PM UTC E-mail parsing finished: 9e216b5c-2daf-44f4-b939-9a4a83cdd235
INFO 05/03/2025 07:27:18 PM UTC New e-mail: 76cc3787-5a0f-4803-8d9d-e3970c05874f
INFO 05/03/2025 07:27:18 PM UTC New e-mail: 76cc3787-5a0f-4803-8d9d-e3970c05874f
Llama.generate: 489 prefix-match hit, remaining 111 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 111 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   42066.15 ms /   111 tokens (  378.97 ms per token,     2.64 tokens per second)
llama_perf_context_print: prompt eval time =   42066.15 ms /   111 tokens (  378.97 ms per token,     2.64 tokens per second)
llama_perf_context_print:        eval time =     230.07 ms /     1 runs   (  230.07 ms per token,     4.35 tokens per second)
llama_perf_context_print:        eval time =     230.07 ms /     1 runs   (  230.07 ms per token,     4.35 tokens per second)
llama_perf_context_print:       total time =   42372.44 ms /   112 tokens
llama_perf_context_print:       total time =   42372.44 ms /   112 tokens
INFO 05/03/2025 07:28:00 PM UTC E-mail parsing finished: 76cc3787-5a0f-4803-8d9d-e3970c05874f
INFO 05/03/2025 07:28:00 PM UTC E-mail parsing finished: 76cc3787-5a0f-4803-8d9d-e3970c05874f
INFO 05/03/2025 07:28:00 PM UTC New e-mail: 2e084289-f065-4873-ba28-2fa125e4f40c
INFO 05/03/2025 07:28:00 PM UTC New e-mail: 2e084289-f065-4873-ba28-2fa125e4f40c
Llama.generate: 536 prefix-match hit, remaining 80 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 80 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   42160.19 ms /    80 tokens (  527.00 ms per token,     1.90 tokens per second)
llama_perf_context_print: prompt eval time =   42160.19 ms /    80 tokens (  527.00 ms per token,     1.90 tokens per second)
llama_perf_context_print:        eval time =     238.98 ms /     1 runs   (  238.98 ms per token,     4.18 tokens per second)
llama_perf_context_print:        eval time =     238.98 ms /     1 runs   (  238.98 ms per token,     4.18 tokens per second)
llama_perf_context_print:       total time =   42451.91 ms /    81 tokens
llama_perf_context_print:       total time =   42451.91 ms /    81 tokens
INFO 05/03/2025 07:28:43 PM UTC E-mail parsing finished: 2e084289-f065-4873-ba28-2fa125e4f40c
INFO 05/03/2025 07:28:43 PM UTC E-mail parsing finished: 2e084289-f065-4873-ba28-2fa125e4f40c
INFO 05/03/2025 07:28:43 PM UTC New e-mail: 125f204e-8b81-4bfc-bd67-924e86bc12bf
INFO 05/03/2025 07:28:43 PM UTC New e-mail: 125f204e-8b81-4bfc-bd67-924e86bc12bf
Llama.generate: 489 prefix-match hit, remaining 720 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 720 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  101195.31 ms /   720 tokens (  140.55 ms per token,     7.11 tokens per second)
llama_perf_context_print: prompt eval time =  101195.31 ms /   720 tokens (  140.55 ms per token,     7.11 tokens per second)
llama_perf_context_print:        eval time =   38882.79 ms /   170 runs   (  228.72 ms per token,     4.37 tokens per second)
llama_perf_context_print:        eval time =   38882.79 ms /   170 runs   (  228.72 ms per token,     4.37 tokens per second)
llama_perf_context_print:       total time =  143960.30 ms /   890 tokens
llama_perf_context_print:       total time =  143960.30 ms /   890 tokens
INFO 05/03/2025 07:31:07 PM UTC E-mail parsing finished: 125f204e-8b81-4bfc-bd67-924e86bc12bf
INFO 05/03/2025 07:31:07 PM UTC E-mail parsing finished: 125f204e-8b81-4bfc-bd67-924e86bc12bf
INFO 05/03/2025 07:31:07 PM UTC New e-mail: 2dc35172-1e7e-4572-88aa-88f5b5062cb3
INFO 05/03/2025 07:31:07 PM UTC New e-mail: 2dc35172-1e7e-4572-88aa-88f5b5062cb3
Llama.generate: 489 prefix-match hit, remaining 1285 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1285 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  154996.88 ms /  1285 tokens (  120.62 ms per token,     8.29 tokens per second)
llama_perf_context_print: prompt eval time =  154996.88 ms /  1285 tokens (  120.62 ms per token,     8.29 tokens per second)
llama_perf_context_print:        eval time =   24236.03 ms /    98 runs   (  247.31 ms per token,     4.04 tokens per second)
llama_perf_context_print:        eval time =   24236.03 ms /    98 runs   (  247.31 ms per token,     4.04 tokens per second)
llama_perf_context_print:       total time =  181422.39 ms /  1383 tokens
llama_perf_context_print:       total time =  181422.39 ms /  1383 tokens
INFO 05/03/2025 07:34:08 PM UTC E-mail parsing finished: 2dc35172-1e7e-4572-88aa-88f5b5062cb3
INFO 05/03/2025 07:34:08 PM UTC E-mail parsing finished: 2dc35172-1e7e-4572-88aa-88f5b5062cb3
INFO 05/03/2025 07:34:08 PM UTC New e-mail: 17b4d63c-4ac5-43ba-9cb4-9d7f733ed420
INFO 05/03/2025 07:34:08 PM UTC New e-mail: 17b4d63c-4ac5-43ba-9cb4-9d7f733ed420
Llama.generate: 531 prefix-match hit, remaining 722 prompt tokens to eval
Llama.generate: 531 prefix-match hit, remaining 722 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  100359.96 ms /   722 tokens (  139.00 ms per token,     7.19 tokens per second)
llama_perf_context_print: prompt eval time =  100359.96 ms /   722 tokens (  139.00 ms per token,     7.19 tokens per second)
llama_perf_context_print:        eval time =   25828.65 ms /   109 runs   (  236.96 ms per token,     4.22 tokens per second)
llama_perf_context_print:        eval time =   25828.65 ms /   109 runs   (  236.96 ms per token,     4.22 tokens per second)
llama_perf_context_print:       total time =  128982.09 ms /   831 tokens
llama_perf_context_print:       total time =  128982.09 ms /   831 tokens
INFO 05/03/2025 07:36:17 PM UTC E-mail parsing finished: 17b4d63c-4ac5-43ba-9cb4-9d7f733ed420
INFO 05/03/2025 07:36:17 PM UTC E-mail parsing finished: 17b4d63c-4ac5-43ba-9cb4-9d7f733ed420
INFO 05/03/2025 07:36:17 PM UTC New e-mail: e62845fd-0c6b-45ff-b5f4-79a81a52f73c
INFO 05/03/2025 07:36:17 PM UTC New e-mail: e62845fd-0c6b-45ff-b5f4-79a81a52f73c
Llama.generate: 535 prefix-match hit, remaining 328 prompt tokens to eval
Llama.generate: 535 prefix-match hit, remaining 328 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   50089.67 ms /   328 tokens (  152.71 ms per token,     6.55 tokens per second)
llama_perf_context_print: prompt eval time =   50089.67 ms /   328 tokens (  152.71 ms per token,     6.55 tokens per second)
llama_perf_context_print:        eval time =   26880.96 ms /   117 runs   (  229.75 ms per token,     4.35 tokens per second)
llama_perf_context_print:        eval time =   26880.96 ms /   117 runs   (  229.75 ms per token,     4.35 tokens per second)
llama_perf_context_print:       total time =   79695.41 ms /   445 tokens
llama_perf_context_print:       total time =   79695.41 ms /   445 tokens
INFO 05/03/2025 07:37:37 PM UTC E-mail parsing finished: e62845fd-0c6b-45ff-b5f4-79a81a52f73c
INFO 05/03/2025 07:37:37 PM UTC E-mail parsing finished: e62845fd-0c6b-45ff-b5f4-79a81a52f73c
INFO 05/03/2025 07:37:37 PM UTC New e-mail: ed770096-b7bf-4f04-9507-24f7e80f67d1
INFO 05/03/2025 07:37:37 PM UTC New e-mail: ed770096-b7bf-4f04-9507-24f7e80f67d1
Llama.generate: 489 prefix-match hit, remaining 11614 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 11614 prompt tokens to eval
WARNING 05/03/2025 07:38:22 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337917f0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
WARNING 05/03/2025 07:38:22 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337917f0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 07:38:22 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 07:38:22 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 07:38:22 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 07:38:22 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 07:38:22 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 35160), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:38:22 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 35160), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:38:22 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 35160), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:38:22 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 35160), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:38:22 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 35160), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:38:22 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 35160), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:38:22 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 07:38:22 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 07:38:22 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 07:38:22 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 07:38:22 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 35160), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:38:22 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 35160), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:38:22 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
INFO 05/03/2025 07:38:22 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
Exception in thread Thread-1:
Exception in thread Thread-1:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/app/modules/parser.py", line 145, in run
  File "/app/modules/parser.py", line 145, in run
    self.mq_channel.start_consuming()
    self.mq_channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
    raise self._closing_reason  # pylint: disable=E0702
    raise self._closing_reason  # pylint: disable=E0702
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
WARNING 05/03/2025 07:38:23 PM UTC ParserThread unexpectedly crashed, restarted it
WARNING 05/03/2025 07:38:23 PM UTC ParserThread unexpectedly crashed, restarted it
INFO 05/03/2025 07:38:23 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:38:23 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 07:38:23 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 38420), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:38:23 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 38420), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 07:38:23 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c1f10>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c1f10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:38:23 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c1f10>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c1f10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 07:38:23 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c1f10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:38:23 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c1f10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:38:23 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c1f10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:38:23 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c1f10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:38:23 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c1f10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:38:23 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c1f10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 07:38:23 PM UTC Created channel=1
INFO 05/03/2025 07:38:23 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Available chat formats from metadata: chat_template.default
Available chat formats from metadata: chat_template.default
INFO 05/03/2025 07:38:32 PM UTC New e-mail: e3244885-6f23-4b3f-8c4a-37d2309b9540
INFO 05/03/2025 07:38:32 PM UTC New e-mail: e3244885-6f23-4b3f-8c4a-37d2309b9540
llama_perf_context_print:        load time = 1866328.75 ms
llama_perf_context_print:        load time = 1866328.75 ms
llama_perf_context_print: prompt eval time = 1866309.36 ms / 15021 tokens (  124.25 ms per token,     8.05 tokens per second)
llama_perf_context_print: prompt eval time = 1866309.36 ms / 15021 tokens (  124.25 ms per token,     8.05 tokens per second)
llama_perf_context_print:        eval time =  302745.24 ms /   149 runs   ( 2031.85 ms per token,     0.49 tokens per second)
llama_perf_context_print:        eval time =  302745.24 ms /   149 runs   ( 2031.85 ms per token,     0.49 tokens per second)
llama_perf_context_print:       total time = 2178377.68 ms / 15170 tokens
llama_perf_context_print:       total time = 2178377.68 ms / 15170 tokens
Exception in thread Thread-7 (_start_parsing):
Exception in thread Thread-7 (_start_parsing):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/usr/local/lib/python3.12/threading.py", line 1012, in run
  File "/usr/local/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
    self._target(*self._args, **self._kwargs)
  File "/app/modules/parser.py", line 110, in _start_parsing
  File "/app/modules/parser.py", line 110, in _start_parsing
    channel.connection.add_callback_threadsafe(cb)
    channel.connection.add_callback_threadsafe(cb)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 742, in add_callback_threadsafe
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 742, in add_callback_threadsafe
    raise exceptions.ConnectionWrongStateError(
    raise exceptions.ConnectionWrongStateError(
pika.exceptions.ConnectionWrongStateError: BlockingConnection.add_callback_threadsafe() called on closed or closing connection.
pika.exceptions.ConnectionWrongStateError: BlockingConnection.add_callback_threadsafe() called on closed or closing connection.
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time = 1370070.12 ms / 11614 tokens (  117.97 ms per token,     8.48 tokens per second)
llama_perf_context_print: prompt eval time = 1370070.12 ms / 11614 tokens (  117.97 ms per token,     8.48 tokens per second)
llama_perf_context_print:        eval time =     328.40 ms /     1 runs   (  328.40 ms per token,     3.05 tokens per second)
llama_perf_context_print:        eval time =     328.40 ms /     1 runs   (  328.40 ms per token,     3.05 tokens per second)
llama_perf_context_print:       total time = 1370495.16 ms / 11615 tokens
llama_perf_context_print:       total time = 1370495.16 ms / 11615 tokens
INFO 05/03/2025 08:00:27 PM UTC E-mail parsing finished: ed770096-b7bf-4f04-9507-24f7e80f67d1
INFO 05/03/2025 08:00:27 PM UTC E-mail parsing finished: ed770096-b7bf-4f04-9507-24f7e80f67d1
INFO 05/03/2025 08:00:27 PM UTC New e-mail: 7ec6fff6-77c5-4307-a7c3-576aac3adf3f
INFO 05/03/2025 08:00:27 PM UTC New e-mail: 7ec6fff6-77c5-4307-a7c3-576aac3adf3f
Llama.generate: 489 prefix-match hit, remaining 541 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 541 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   59971.14 ms /   541 tokens (  110.85 ms per token,     9.02 tokens per second)
llama_perf_context_print: prompt eval time =   59971.14 ms /   541 tokens (  110.85 ms per token,     9.02 tokens per second)
llama_perf_context_print:        eval time =   36246.96 ms /   163 runs   (  222.37 ms per token,     4.50 tokens per second)
llama_perf_context_print:        eval time =   36246.96 ms /   163 runs   (  222.37 ms per token,     4.50 tokens per second)
llama_perf_context_print:       total time =  100031.93 ms /   704 tokens
llama_perf_context_print:       total time =  100031.93 ms /   704 tokens
INFO 05/03/2025 08:02:08 PM UTC E-mail parsing finished: 7ec6fff6-77c5-4307-a7c3-576aac3adf3f
INFO 05/03/2025 08:02:08 PM UTC E-mail parsing finished: 7ec6fff6-77c5-4307-a7c3-576aac3adf3f
INFO 05/03/2025 08:02:08 PM UTC New e-mail: 5a387050-4f06-4b0a-80cd-58debd352b82
INFO 05/03/2025 08:02:08 PM UTC New e-mail: 5a387050-4f06-4b0a-80cd-58debd352b82
Llama.generate: 541 prefix-match hit, remaining 4794 prompt tokens to eval
Llama.generate: 541 prefix-match hit, remaining 4794 prompt tokens to eval
ERROR 05/03/2025 08:02:08 PM UTC Unknown exception occurred
ERROR 05/03/2025 08:02:08 PM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '1937-6' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '1937-6' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1937-6' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1937-6' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 1937, 'tag_id': 5}, {'event_id': 1937, 'tag_id': 6}, {'event_id': 1937, 'tag_id': 7}, {'event_id': 1937, 'tag_id': 6}]]
[parameters: [{'event_id': 1937, 'tag_id': 5}, {'event_id': 1937, 'tag_id': 6}, {'event_id': 1937, 'tag_id': 7}, {'event_id': 1937, 'tag_id': 6}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time = 1615398.46 ms
llama_perf_context_print:        load time = 1615398.46 ms
llama_perf_context_print: prompt eval time = 1615396.57 ms / 15021 tokens (  107.54 ms per token,     9.30 tokens per second)
llama_perf_context_print: prompt eval time = 1615396.57 ms / 15021 tokens (  107.54 ms per token,     9.30 tokens per second)
llama_perf_context_print:        eval time =    3164.25 ms /     1 runs   ( 3164.25 ms per token,     0.32 tokens per second)
llama_perf_context_print:        eval time =    3164.25 ms /     1 runs   ( 3164.25 ms per token,     0.32 tokens per second)
llama_perf_context_print:       total time = 1618624.63 ms / 15022 tokens
llama_perf_context_print:       total time = 1618624.63 ms / 15022 tokens
INFO 05/03/2025 08:05:31 PM UTC E-mail parsing finished: e3244885-6f23-4b3f-8c4a-37d2309b9540
INFO 05/03/2025 08:05:31 PM UTC E-mail parsing finished: e3244885-6f23-4b3f-8c4a-37d2309b9540
INFO 05/03/2025 08:05:31 PM UTC New e-mail: 46f025cc-4784-4c2e-a2ba-5c9689cc8cf5
INFO 05/03/2025 08:05:31 PM UTC New e-mail: 46f025cc-4784-4c2e-a2ba-5c9689cc8cf5
Llama.generate: 489 prefix-match hit, remaining 561 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 561 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  560025.40 ms /  4794 tokens (  116.82 ms per token,     8.56 tokens per second)
llama_perf_context_print: prompt eval time =  560025.40 ms /  4794 tokens (  116.82 ms per token,     8.56 tokens per second)
llama_perf_context_print:        eval time =   38230.78 ms /   216 runs   (  176.99 ms per token,     5.65 tokens per second)
llama_perf_context_print:        eval time =   38230.78 ms /   216 runs   (  176.99 ms per token,     5.65 tokens per second)
llama_perf_context_print:       total time =  602631.28 ms /  5010 tokens
llama_perf_context_print:       total time =  602631.28 ms /  5010 tokens
INFO 05/03/2025 08:12:10 PM UTC E-mail parsing finished: 5a387050-4f06-4b0a-80cd-58debd352b82
INFO 05/03/2025 08:12:10 PM UTC E-mail parsing finished: 5a387050-4f06-4b0a-80cd-58debd352b82
INFO 05/03/2025 08:12:10 PM UTC New e-mail: dbc39ecf-0eb8-4d63-a4dd-098a236bb4f9
INFO 05/03/2025 08:12:10 PM UTC New e-mail: dbc39ecf-0eb8-4d63-a4dd-098a236bb4f9
Llama.generate: 543 prefix-match hit, remaining 369 prompt tokens to eval
Llama.generate: 543 prefix-match hit, remaining 369 prompt tokens to eval
ERROR 05/03/2025 08:12:10 PM UTC Unknown exception occurred
ERROR 05/03/2025 08:12:10 PM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '1938-6' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '1938-6' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 134, in add_events_to_db
  File "/app/modules/validator.py", line 134, in add_events_to_db
    event_row = self.validate_and_create_event_row(db_session, parsed_event, new_events.user_timezone)
    event_row = self.validate_and_create_event_row(db_session, parsed_event, new_events.user_timezone)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/modules/validator.py", line 116, in validate_and_create_event_row
  File "/app/modules/validator.py", line 116, in validate_and_create_event_row
    event_row.tags.append(self.get_or_create_tag(db_session, tag_name))
    event_row.tags.append(self.get_or_create_tag(db_session, tag_name))
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/modules/validator.py", line 72, in get_or_create_tag
  File "/app/modules/validator.py", line 72, in get_or_create_tag
    tag_row = db_session.execute(query).scalar_one_or_none()
    tag_row = db_session.execute(query).scalar_one_or_none()
              ^^^^^^^^^^^^^^^^^^^^^^^^^
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2362, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2362, in execute
    return self._execute_internal(
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2226, in _execute_internal
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2226, in _execute_internal
    ) = compile_state_cls.orm_pre_session_exec(
    ) = compile_state_cls.orm_pre_session_exec(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 561, in orm_pre_session_exec
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 561, in orm_pre_session_exec
    session._autoflush()
    session._autoflush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3061, in _autoflush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3061, in _autoflush
    raise e.with_traceback(sys.exc_info()[2])
    raise e.with_traceback(sys.exc_info()[2])
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3050, in _autoflush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3050, in _autoflush
    self.flush()
    self.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)
sqlalchemy.exc.IntegrityError: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)
(pymysql.err.IntegrityError) (1062, "Duplicate entry '1938-6' for key 'tags_to_events.PRIMARY'")
(pymysql.err.IntegrityError) (1062, "Duplicate entry '1938-6' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 1938, 'tag_id': 6}, {'event_id': 1938, 'tag_id': 7}, {'event_id': 1938, 'tag_id': 5}, {'event_id': 1938, 'tag_id': 3}, {'event_id': 1938, 'tag_id': 2}, {'event_id': 1938, 'tag_id': 8}, {'event_id': 1938, 'tag_id': 1}, {'event_id': 1938, 'tag_id': 6}, {'event_id': 1938, 'tag_id': 8}]]
[parameters: [{'event_id': 1938, 'tag_id': 6}, {'event_id': 1938, 'tag_id': 7}, {'event_id': 1938, 'tag_id': 5}, {'event_id': 1938, 'tag_id': 3}, {'event_id': 1938, 'tag_id': 2}, {'event_id': 1938, 'tag_id': 8}, {'event_id': 1938, 'tag_id': 1}, {'event_id': 1938, 'tag_id': 6}, {'event_id': 1938, 'tag_id': 8}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   49045.45 ms /   369 tokens (  132.91 ms per token,     7.52 tokens per second)
llama_perf_context_print: prompt eval time =   49045.45 ms /   369 tokens (  132.91 ms per token,     7.52 tokens per second)
llama_perf_context_print:        eval time =   15167.89 ms /   115 runs   (  131.89 ms per token,     7.58 tokens per second)
llama_perf_context_print:        eval time =   15167.89 ms /   115 runs   (  131.89 ms per token,     7.58 tokens per second)
llama_perf_context_print:       total time =   67115.55 ms /   484 tokens
llama_perf_context_print:       total time =   67115.55 ms /   484 tokens
INFO 05/03/2025 08:13:17 PM UTC E-mail parsing finished: dbc39ecf-0eb8-4d63-a4dd-098a236bb4f9
INFO 05/03/2025 08:13:17 PM UTC E-mail parsing finished: dbc39ecf-0eb8-4d63-a4dd-098a236bb4f9
INFO 05/03/2025 08:13:17 PM UTC New e-mail: f77ae77f-8cea-4d25-a4cc-7bc519d7d20d
INFO 05/03/2025 08:13:17 PM UTC New e-mail: f77ae77f-8cea-4d25-a4cc-7bc519d7d20d
Llama.generate: 489 prefix-match hit, remaining 786 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 786 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   93155.18 ms /   786 tokens (  118.52 ms per token,     8.44 tokens per second)
llama_perf_context_print: prompt eval time =   93155.18 ms /   786 tokens (  118.52 ms per token,     8.44 tokens per second)
llama_perf_context_print:        eval time =   11252.01 ms /    80 runs   (  140.65 ms per token,     7.11 tokens per second)
llama_perf_context_print:        eval time =   11252.01 ms /    80 runs   (  140.65 ms per token,     7.11 tokens per second)
llama_perf_context_print:       total time =  106227.51 ms /   866 tokens
llama_perf_context_print:       total time =  106227.51 ms /   866 tokens
INFO 05/03/2025 08:15:04 PM UTC E-mail parsing finished: f77ae77f-8cea-4d25-a4cc-7bc519d7d20d
INFO 05/03/2025 08:15:04 PM UTC E-mail parsing finished: f77ae77f-8cea-4d25-a4cc-7bc519d7d20d
INFO 05/03/2025 08:15:04 PM UTC New e-mail: be66ad39-92ce-4f85-9fd9-64185defce2b
INFO 05/03/2025 08:15:04 PM UTC New e-mail: be66ad39-92ce-4f85-9fd9-64185defce2b
Llama.generate: 519 prefix-match hit, remaining 1201 prompt tokens to eval
Llama.generate: 519 prefix-match hit, remaining 1201 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  146850.12 ms /  1201 tokens (  122.27 ms per token,     8.18 tokens per second)
llama_perf_context_print: prompt eval time =  146850.12 ms /  1201 tokens (  122.27 ms per token,     8.18 tokens per second)
llama_perf_context_print:        eval time =     160.10 ms /     1 runs   (  160.10 ms per token,     6.25 tokens per second)
llama_perf_context_print:        eval time =     160.10 ms /     1 runs   (  160.10 ms per token,     6.25 tokens per second)
llama_perf_context_print:       total time =  147089.19 ms /  1202 tokens
llama_perf_context_print:       total time =  147089.19 ms /  1202 tokens
INFO 05/03/2025 08:17:31 PM UTC E-mail parsing finished: be66ad39-92ce-4f85-9fd9-64185defce2b
INFO 05/03/2025 08:17:31 PM UTC E-mail parsing finished: be66ad39-92ce-4f85-9fd9-64185defce2b
INFO 05/03/2025 08:17:31 PM UTC New e-mail: b847e3b4-9641-4c3b-a44d-03c1af809809
INFO 05/03/2025 08:17:31 PM UTC New e-mail: b847e3b4-9641-4c3b-a44d-03c1af809809
Llama.generate: 489 prefix-match hit, remaining 845 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 845 prompt tokens to eval
llama_perf_context_print:        load time = 1615398.46 ms
llama_perf_context_print:        load time = 1615398.46 ms
llama_perf_context_print: prompt eval time =   89914.59 ms /   561 tokens (  160.28 ms per token,     6.24 tokens per second)
llama_perf_context_print: prompt eval time =   89914.59 ms /   561 tokens (  160.28 ms per token,     6.24 tokens per second)
llama_perf_context_print:        eval time =  667407.63 ms /   163 runs   ( 4094.53 ms per token,     0.24 tokens per second)
llama_perf_context_print:        eval time =  667407.63 ms /   163 runs   ( 4094.53 ms per token,     0.24 tokens per second)
llama_perf_context_print:       total time =  761716.35 ms /   724 tokens
llama_perf_context_print:       total time =  761716.35 ms /   724 tokens
INFO 05/03/2025 08:18:13 PM UTC E-mail parsing finished: 46f025cc-4784-4c2e-a2ba-5c9689cc8cf5
INFO 05/03/2025 08:18:13 PM UTC E-mail parsing finished: 46f025cc-4784-4c2e-a2ba-5c9689cc8cf5
INFO 05/03/2025 08:18:13 PM UTC New e-mail: e4c8d911-de87-441d-9814-f900c8ac074d
INFO 05/03/2025 08:18:13 PM UTC New e-mail: e4c8d911-de87-441d-9814-f900c8ac074d
Llama.generate: 489 prefix-match hit, remaining 165 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 165 prompt tokens to eval
ERROR 05/03/2025 08:18:13 PM UTC Unknown exception occurred
ERROR 05/03/2025 08:18:13 PM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '1941-5' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '1941-5' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1941-5' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1941-5' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 1941, 'tag_id': 5}, {'event_id': 1941, 'tag_id': 5}, {'event_id': 1941, 'tag_id': 5}, {'event_id': 1941, 'tag_id': 5}, {'event_id': 1941, 'tag_id': 5}]]
[parameters: [{'event_id': 1941, 'tag_id': 5}, {'event_id': 1941, 'tag_id': 5}, {'event_id': 1941, 'tag_id': 5}, {'event_id': 1941, 'tag_id': 5}, {'event_id': 1941, 'tag_id': 5}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time = 1615398.46 ms
llama_perf_context_print:        load time = 1615398.46 ms
llama_perf_context_print: prompt eval time =   47388.34 ms /   165 tokens (  287.20 ms per token,     3.48 tokens per second)
llama_perf_context_print: prompt eval time =   47388.34 ms /   165 tokens (  287.20 ms per token,     3.48 tokens per second)
llama_perf_context_print:        eval time =    2943.26 ms /     1 runs   ( 2943.26 ms per token,     0.34 tokens per second)
llama_perf_context_print:        eval time =    2943.26 ms /     1 runs   ( 2943.26 ms per token,     0.34 tokens per second)
llama_perf_context_print:       total time =   50402.79 ms /   166 tokens
llama_perf_context_print:       total time =   50402.79 ms /   166 tokens
INFO 05/03/2025 08:19:03 PM UTC E-mail parsing finished: e4c8d911-de87-441d-9814-f900c8ac074d
INFO 05/03/2025 08:19:03 PM UTC E-mail parsing finished: e4c8d911-de87-441d-9814-f900c8ac074d
INFO 05/03/2025 08:19:03 PM UTC New e-mail: 9f952698-e836-408e-abcb-29d885eaac16
INFO 05/03/2025 08:19:03 PM UTC New e-mail: 9f952698-e836-408e-abcb-29d885eaac16
Llama.generate: 489 prefix-match hit, remaining 12357 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 12357 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  100239.72 ms /   845 tokens (  118.63 ms per token,     8.43 tokens per second)
llama_perf_context_print: prompt eval time =  100239.72 ms /   845 tokens (  118.63 ms per token,     8.43 tokens per second)
llama_perf_context_print:        eval time =   18612.04 ms /    80 runs   (  232.65 ms per token,     4.30 tokens per second)
llama_perf_context_print:        eval time =   18612.04 ms /    80 runs   (  232.65 ms per token,     4.30 tokens per second)
llama_perf_context_print:       total time =  120647.33 ms /   925 tokens
llama_perf_context_print:       total time =  120647.33 ms /   925 tokens
INFO 05/03/2025 08:19:31 PM UTC E-mail parsing finished: b847e3b4-9641-4c3b-a44d-03c1af809809
INFO 05/03/2025 08:19:31 PM UTC E-mail parsing finished: b847e3b4-9641-4c3b-a44d-03c1af809809
INFO 05/03/2025 08:19:31 PM UTC New e-mail: ceab61f0-0902-49e8-b6f8-57d8b4021afd
INFO 05/03/2025 08:19:31 PM UTC New e-mail: ceab61f0-0902-49e8-b6f8-57d8b4021afd
Llama.generate: 541 prefix-match hit, remaining 329 prompt tokens to eval
Llama.generate: 541 prefix-match hit, remaining 329 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   49154.81 ms /   329 tokens (  149.41 ms per token,     6.69 tokens per second)
llama_perf_context_print: prompt eval time =   49154.81 ms /   329 tokens (  149.41 ms per token,     6.69 tokens per second)
llama_perf_context_print:        eval time =   25974.93 ms /   125 runs   (  207.80 ms per token,     4.81 tokens per second)
llama_perf_context_print:        eval time =   25974.93 ms /   125 runs   (  207.80 ms per token,     4.81 tokens per second)
llama_perf_context_print:       total time =   78326.05 ms /   454 tokens
llama_perf_context_print:       total time =   78326.05 ms /   454 tokens
INFO 05/03/2025 08:20:50 PM UTC E-mail parsing finished: ceab61f0-0902-49e8-b6f8-57d8b4021afd
INFO 05/03/2025 08:20:50 PM UTC E-mail parsing finished: ceab61f0-0902-49e8-b6f8-57d8b4021afd
INFO 05/03/2025 08:20:50 PM UTC New e-mail: 2bf29808-6685-45ff-833c-9609f91424d5
INFO 05/03/2025 08:20:50 PM UTC New e-mail: 2bf29808-6685-45ff-833c-9609f91424d5
Llama.generate: 489 prefix-match hit, remaining 590 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 590 prompt tokens to eval
ERROR 05/03/2025 08:20:50 PM UTC Unknown exception occurred
ERROR 05/03/2025 08:20:50 PM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '1943-5' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '1943-5' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1943-5' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1943-5' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 1943, 'tag_id': 5}, {'event_id': 1943, 'tag_id': 6}, {'event_id': 1943, 'tag_id': 5}, {'event_id': 1943, 'tag_id': 4}, {'event_id': 1943, 'tag_id': 6}, {'event_id': 1943, 'tag_id': 2}]]
[parameters: [{'event_id': 1943, 'tag_id': 5}, {'event_id': 1943, 'tag_id': 6}, {'event_id': 1943, 'tag_id': 5}, {'event_id': 1943, 'tag_id': 4}, {'event_id': 1943, 'tag_id': 6}, {'event_id': 1943, 'tag_id': 2}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   96011.35 ms /   590 tokens (  162.73 ms per token,     6.15 tokens per second)
llama_perf_context_print: prompt eval time =   96011.35 ms /   590 tokens (  162.73 ms per token,     6.15 tokens per second)
llama_perf_context_print:        eval time =   16550.37 ms /    74 runs   (  223.65 ms per token,     4.47 tokens per second)
llama_perf_context_print:        eval time =   16550.37 ms /    74 runs   (  223.65 ms per token,     4.47 tokens per second)
llama_perf_context_print:       total time =  114346.06 ms /   664 tokens
llama_perf_context_print:       total time =  114346.06 ms /   664 tokens
INFO 05/03/2025 08:22:44 PM UTC E-mail parsing finished: 2bf29808-6685-45ff-833c-9609f91424d5
INFO 05/03/2025 08:22:44 PM UTC E-mail parsing finished: 2bf29808-6685-45ff-833c-9609f91424d5
INFO 05/03/2025 08:22:44 PM UTC New e-mail: d2c2d328-5110-48ba-9813-8df09aa96bfd
INFO 05/03/2025 08:22:44 PM UTC New e-mail: d2c2d328-5110-48ba-9813-8df09aa96bfd
Llama.generate: 489 prefix-match hit, remaining 358 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 358 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   50041.42 ms /   358 tokens (  139.78 ms per token,     7.15 tokens per second)
llama_perf_context_print: prompt eval time =   50041.42 ms /   358 tokens (  139.78 ms per token,     7.15 tokens per second)
llama_perf_context_print:        eval time =   23536.33 ms /   104 runs   (  226.31 ms per token,     4.42 tokens per second)
llama_perf_context_print:        eval time =   23536.33 ms /   104 runs   (  226.31 ms per token,     4.42 tokens per second)
llama_perf_context_print:       total time =   76081.97 ms /   462 tokens
llama_perf_context_print:       total time =   76081.97 ms /   462 tokens
INFO 05/03/2025 08:24:00 PM UTC E-mail parsing finished: d2c2d328-5110-48ba-9813-8df09aa96bfd
INFO 05/03/2025 08:24:00 PM UTC E-mail parsing finished: d2c2d328-5110-48ba-9813-8df09aa96bfd
INFO 05/03/2025 08:24:00 PM UTC New e-mail: 489682be-00c8-4da1-98d6-5f29c55eee25
INFO 05/03/2025 08:24:00 PM UTC New e-mail: 489682be-00c8-4da1-98d6-5f29c55eee25
Llama.generate: 489 prefix-match hit, remaining 612 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 612 prompt tokens to eval
ERROR 05/03/2025 08:24:00 PM UTC Unknown exception occurred
ERROR 05/03/2025 08:24:00 PM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '1945-6' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '1945-6' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1945-6' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1945-6' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 1945, 'tag_id': 6}, {'event_id': 1945, 'tag_id': 5}, {'event_id': 1945, 'tag_id': 4}, {'event_id': 1945, 'tag_id': 6}]]
[parameters: [{'event_id': 1945, 'tag_id': 6}, {'event_id': 1945, 'tag_id': 5}, {'event_id': 1945, 'tag_id': 4}, {'event_id': 1945, 'tag_id': 6}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   98055.83 ms /   612 tokens (  160.22 ms per token,     6.24 tokens per second)
llama_perf_context_print: prompt eval time =   98055.83 ms /   612 tokens (  160.22 ms per token,     6.24 tokens per second)
llama_perf_context_print:        eval time =   27848.29 ms /   125 runs   (  222.79 ms per token,     4.49 tokens per second)
llama_perf_context_print:        eval time =   27848.29 ms /   125 runs   (  222.79 ms per token,     4.49 tokens per second)
llama_perf_context_print:       total time =  129120.39 ms /   737 tokens
llama_perf_context_print:       total time =  129120.39 ms /   737 tokens
INFO 05/03/2025 08:26:09 PM UTC E-mail parsing finished: 489682be-00c8-4da1-98d6-5f29c55eee25
INFO 05/03/2025 08:26:09 PM UTC E-mail parsing finished: 489682be-00c8-4da1-98d6-5f29c55eee25
INFO 05/03/2025 08:26:09 PM UTC New e-mail: 5a7c29fd-085c-469f-8ce3-9ad819f411b2
INFO 05/03/2025 08:26:09 PM UTC New e-mail: 5a7c29fd-085c-469f-8ce3-9ad819f411b2
Llama.generate: 529 prefix-match hit, remaining 767 prompt tokens to eval
Llama.generate: 529 prefix-match hit, remaining 767 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   96199.09 ms /   767 tokens (  125.42 ms per token,     7.97 tokens per second)
llama_perf_context_print: prompt eval time =   96199.09 ms /   767 tokens (  125.42 ms per token,     7.97 tokens per second)
llama_perf_context_print:        eval time =   27821.27 ms /   125 runs   (  222.57 ms per token,     4.49 tokens per second)
llama_perf_context_print:        eval time =   27821.27 ms /   125 runs   (  222.57 ms per token,     4.49 tokens per second)
llama_perf_context_print:       total time =  126941.77 ms /   892 tokens
llama_perf_context_print:       total time =  126941.77 ms /   892 tokens
INFO 05/03/2025 08:28:16 PM UTC E-mail parsing finished: 5a7c29fd-085c-469f-8ce3-9ad819f411b2
INFO 05/03/2025 08:28:16 PM UTC E-mail parsing finished: 5a7c29fd-085c-469f-8ce3-9ad819f411b2
INFO 05/03/2025 08:28:16 PM UTC New e-mail: 368a16bf-4898-415f-9e6f-8bff9e8f1a45
INFO 05/03/2025 08:28:16 PM UTC New e-mail: 368a16bf-4898-415f-9e6f-8bff9e8f1a45
Llama.generate: 489 prefix-match hit, remaining 550 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 550 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   91943.97 ms /   550 tokens (  167.17 ms per token,     5.98 tokens per second)
llama_perf_context_print: prompt eval time =   91943.97 ms /   550 tokens (  167.17 ms per token,     5.98 tokens per second)
llama_perf_context_print:        eval time =   18631.20 ms /    81 runs   (  230.01 ms per token,     4.35 tokens per second)
llama_perf_context_print:        eval time =   18631.20 ms /    81 runs   (  230.01 ms per token,     4.35 tokens per second)
llama_perf_context_print:       total time =  112425.92 ms /   631 tokens
llama_perf_context_print:       total time =  112425.92 ms /   631 tokens
INFO 05/03/2025 08:30:09 PM UTC E-mail parsing finished: 368a16bf-4898-415f-9e6f-8bff9e8f1a45
INFO 05/03/2025 08:30:09 PM UTC E-mail parsing finished: 368a16bf-4898-415f-9e6f-8bff9e8f1a45
INFO 05/03/2025 08:30:09 PM UTC New e-mail: 6f6acf25-43be-4b3c-8ff2-236211b5329c
INFO 05/03/2025 08:30:09 PM UTC New e-mail: 6f6acf25-43be-4b3c-8ff2-236211b5329c
Llama.generate: 489 prefix-match hit, remaining 589 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 589 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   93636.41 ms /   589 tokens (  158.98 ms per token,     6.29 tokens per second)
llama_perf_context_print: prompt eval time =   93636.41 ms /   589 tokens (  158.98 ms per token,     6.29 tokens per second)
llama_perf_context_print:        eval time =   27074.27 ms /   115 runs   (  235.43 ms per token,     4.25 tokens per second)
llama_perf_context_print:        eval time =   27074.27 ms /   115 runs   (  235.43 ms per token,     4.25 tokens per second)
llama_perf_context_print:       total time =  123574.91 ms /   704 tokens
llama_perf_context_print:       total time =  123574.91 ms /   704 tokens
INFO 05/03/2025 08:32:12 PM UTC E-mail parsing finished: 6f6acf25-43be-4b3c-8ff2-236211b5329c
INFO 05/03/2025 08:32:12 PM UTC E-mail parsing finished: 6f6acf25-43be-4b3c-8ff2-236211b5329c
INFO 05/03/2025 08:32:12 PM UTC New e-mail: 222bd041-5a59-49c3-a0f0-a41a402b3f09
INFO 05/03/2025 08:32:12 PM UTC New e-mail: 222bd041-5a59-49c3-a0f0-a41a402b3f09
Llama.generate: 489 prefix-match hit, remaining 13047 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 13047 prompt tokens to eval
llama_perf_context_print:        load time = 1615398.46 ms
llama_perf_context_print:        load time = 1615398.46 ms
llama_perf_context_print: prompt eval time = 1603046.57 ms / 12357 tokens (  129.73 ms per token,     7.71 tokens per second)
llama_perf_context_print: prompt eval time = 1603046.57 ms / 12357 tokens (  129.73 ms per token,     7.71 tokens per second)
llama_perf_context_print:        eval time =    2885.31 ms /     1 runs   ( 2885.31 ms per token,     0.35 tokens per second)
llama_perf_context_print:        eval time =    2885.31 ms /     1 runs   ( 2885.31 ms per token,     0.35 tokens per second)
llama_perf_context_print:       total time = 1605988.31 ms / 12358 tokens
llama_perf_context_print:       total time = 1605988.31 ms / 12358 tokens
INFO 05/03/2025 08:45:49 PM UTC E-mail parsing finished: 9f952698-e836-408e-abcb-29d885eaac16
INFO 05/03/2025 08:45:49 PM UTC E-mail parsing finished: 9f952698-e836-408e-abcb-29d885eaac16
INFO 05/03/2025 08:45:49 PM UTC New e-mail: 29250d6e-4446-43de-bf64-edd094876161
INFO 05/03/2025 08:45:49 PM UTC New e-mail: 29250d6e-4446-43de-bf64-edd094876161
Llama.generate: 489 prefix-match hit, remaining 377 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 377 prompt tokens to eval
llama_perf_context_print:        load time = 1615398.46 ms
llama_perf_context_print:        load time = 1615398.46 ms
llama_perf_context_print: prompt eval time =   49783.88 ms /   377 tokens (  132.05 ms per token,     7.57 tokens per second)
llama_perf_context_print: prompt eval time =   49783.88 ms /   377 tokens (  132.05 ms per token,     7.57 tokens per second)
llama_perf_context_print:        eval time =  480038.35 ms /   120 runs   ( 4000.32 ms per token,     0.25 tokens per second)
llama_perf_context_print:        eval time =  480038.35 ms /   120 runs   ( 4000.32 ms per token,     0.25 tokens per second)
llama_perf_context_print:       total time =  532759.99 ms /   497 tokens
llama_perf_context_print:       total time =  532759.99 ms /   497 tokens
INFO 05/03/2025 08:54:42 PM UTC E-mail parsing finished: 29250d6e-4446-43de-bf64-edd094876161
INFO 05/03/2025 08:54:42 PM UTC E-mail parsing finished: 29250d6e-4446-43de-bf64-edd094876161
INFO 05/03/2025 08:54:42 PM UTC New e-mail: cea52e4d-6432-4953-8182-5d41846e3e0d
INFO 05/03/2025 08:54:42 PM UTC New e-mail: cea52e4d-6432-4953-8182-5d41846e3e0d
Llama.generate: 489 prefix-match hit, remaining 752 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 752 prompt tokens to eval
ERROR 05/03/2025 08:54:42 PM UTC Unknown exception occurred
ERROR 05/03/2025 08:54:42 PM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '1950-5' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '1950-5' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1950-5' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1950-5' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 1950, 'tag_id': 2}, {'event_id': 1950, 'tag_id': 5}, {'event_id': 1950, 'tag_id': 4}, {'event_id': 1950, 'tag_id': 5}, {'event_id': 1950, 'tag_id': 5}, {'event_id': 1950, 'tag_id': 5}, {'event_id': 1950, 'tag_id': 8}]]
[parameters: [{'event_id': 1950, 'tag_id': 2}, {'event_id': 1950, 'tag_id': 5}, {'event_id': 1950, 'tag_id': 4}, {'event_id': 1950, 'tag_id': 5}, {'event_id': 1950, 'tag_id': 5}, {'event_id': 1950, 'tag_id': 5}, {'event_id': 1950, 'tag_id': 8}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time = 1615701.11 ms / 13047 tokens (  123.84 ms per token,     8.08 tokens per second)
llama_perf_context_print: prompt eval time = 1615701.11 ms / 13047 tokens (  123.84 ms per token,     8.08 tokens per second)
llama_perf_context_print:        eval time =     288.67 ms /     1 runs   (  288.67 ms per token,     3.46 tokens per second)
llama_perf_context_print:        eval time =     288.67 ms /     1 runs   (  288.67 ms per token,     3.46 tokens per second)
llama_perf_context_print:       total time = 1616021.23 ms / 13048 tokens
llama_perf_context_print:       total time = 1616021.23 ms / 13048 tokens
INFO 05/03/2025 08:59:08 PM UTC E-mail parsing finished: 222bd041-5a59-49c3-a0f0-a41a402b3f09
INFO 05/03/2025 08:59:08 PM UTC E-mail parsing finished: 222bd041-5a59-49c3-a0f0-a41a402b3f09
INFO 05/03/2025 08:59:08 PM UTC New e-mail: de25321f-b608-437b-99da-1721fe93cb1e
INFO 05/03/2025 08:59:08 PM UTC New e-mail: de25321f-b608-437b-99da-1721fe93cb1e
Llama.generate: 489 prefix-match hit, remaining 527 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 527 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   47980.90 ms /   527 tokens (   91.05 ms per token,    10.98 tokens per second)
llama_perf_context_print: prompt eval time =   47980.90 ms /   527 tokens (   91.05 ms per token,    10.98 tokens per second)
llama_perf_context_print:        eval time =     144.51 ms /     1 runs   (  144.51 ms per token,     6.92 tokens per second)
llama_perf_context_print:        eval time =     144.51 ms /     1 runs   (  144.51 ms per token,     6.92 tokens per second)
llama_perf_context_print:       total time =   48259.86 ms /   528 tokens
llama_perf_context_print:       total time =   48259.86 ms /   528 tokens
INFO 05/03/2025 08:59:57 PM UTC E-mail parsing finished: de25321f-b608-437b-99da-1721fe93cb1e
INFO 05/03/2025 08:59:57 PM UTC E-mail parsing finished: de25321f-b608-437b-99da-1721fe93cb1e
INFO 05/03/2025 08:59:57 PM UTC New e-mail: 4735cca3-d635-4908-8a35-20b4a5bddab5
INFO 05/03/2025 08:59:57 PM UTC New e-mail: 4735cca3-d635-4908-8a35-20b4a5bddab5
Llama.generate: 489 prefix-match hit, remaining 480 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 480 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   53995.40 ms /   480 tokens (  112.49 ms per token,     8.89 tokens per second)
llama_perf_context_print: prompt eval time =   53995.40 ms /   480 tokens (  112.49 ms per token,     8.89 tokens per second)
llama_perf_context_print:        eval time =     200.31 ms /     1 runs   (  200.31 ms per token,     4.99 tokens per second)
llama_perf_context_print:        eval time =     200.31 ms /     1 runs   (  200.31 ms per token,     4.99 tokens per second)
llama_perf_context_print:       total time =   54228.61 ms /   481 tokens
llama_perf_context_print:       total time =   54228.61 ms /   481 tokens
INFO 05/03/2025 09:00:51 PM UTC E-mail parsing finished: 4735cca3-d635-4908-8a35-20b4a5bddab5
INFO 05/03/2025 09:00:51 PM UTC E-mail parsing finished: 4735cca3-d635-4908-8a35-20b4a5bddab5
INFO 05/03/2025 09:00:51 PM UTC New e-mail: 7d081997-14c4-4d02-8000-f6e70e885357
INFO 05/03/2025 09:00:51 PM UTC New e-mail: 7d081997-14c4-4d02-8000-f6e70e885357
Llama.generate: 489 prefix-match hit, remaining 318 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 318 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   46462.08 ms /   318 tokens (  146.11 ms per token,     6.84 tokens per second)
llama_perf_context_print: prompt eval time =   46462.08 ms /   318 tokens (  146.11 ms per token,     6.84 tokens per second)
llama_perf_context_print:        eval time =     150.41 ms /     1 runs   (  150.41 ms per token,     6.65 tokens per second)
llama_perf_context_print:        eval time =     150.41 ms /     1 runs   (  150.41 ms per token,     6.65 tokens per second)
llama_perf_context_print:       total time =   46740.44 ms /   319 tokens
llama_perf_context_print:       total time =   46740.44 ms /   319 tokens
INFO 05/03/2025 09:01:38 PM UTC E-mail parsing finished: 7d081997-14c4-4d02-8000-f6e70e885357
INFO 05/03/2025 09:01:38 PM UTC E-mail parsing finished: 7d081997-14c4-4d02-8000-f6e70e885357
INFO 05/03/2025 09:01:38 PM UTC New e-mail: 6cd62d69-06d0-49b6-8923-b3add051a145
INFO 05/03/2025 09:01:38 PM UTC New e-mail: 6cd62d69-06d0-49b6-8923-b3add051a145
Llama.generate: 489 prefix-match hit, remaining 133 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 133 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   41291.81 ms /   133 tokens (  310.46 ms per token,     3.22 tokens per second)
llama_perf_context_print: prompt eval time =   41291.81 ms /   133 tokens (  310.46 ms per token,     3.22 tokens per second)
llama_perf_context_print:        eval time =     192.56 ms /     1 runs   (  192.56 ms per token,     5.19 tokens per second)
llama_perf_context_print:        eval time =     192.56 ms /     1 runs   (  192.56 ms per token,     5.19 tokens per second)
llama_perf_context_print:       total time =   41519.36 ms /   134 tokens
llama_perf_context_print:       total time =   41519.36 ms /   134 tokens
INFO 05/03/2025 09:02:19 PM UTC E-mail parsing finished: 6cd62d69-06d0-49b6-8923-b3add051a145
INFO 05/03/2025 09:02:19 PM UTC E-mail parsing finished: 6cd62d69-06d0-49b6-8923-b3add051a145
INFO 05/03/2025 09:02:19 PM UTC New e-mail: f2be0cc1-bff4-43b4-a601-0da5a2522e79
INFO 05/03/2025 09:02:19 PM UTC New e-mail: f2be0cc1-bff4-43b4-a601-0da5a2522e79
Llama.generate: 489 prefix-match hit, remaining 12000 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 12000 prompt tokens to eval
WARNING 05/03/2025 09:25:32 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c1f10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
WARNING 05/03/2025 09:25:32 PM UTC Received remote Channel.Close (406): 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c1f10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>>
INFO 05/03/2025 09:25:32 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 09:25:32 PM UTC Closing connection (200): Normal shutdown
INFO 05/03/2025 09:25:32 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 09:25:32 PM UTC Closing connection (200): 'Normal shutdown'
INFO 05/03/2025 09:25:32 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 38420), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 09:25:32 PM UTC Aborting transport connection: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 38420), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 09:25:32 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 38420), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 09:25:32 PM UTC _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 38420), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 09:25:32 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 38420), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 09:25:32 PM UTC Deactivating transport: state=1; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 38420), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 09:25:32 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 09:25:32 PM UTC AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 09:25:32 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 09:25:32 PM UTC Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
INFO 05/03/2025 09:25:32 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 38420), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 09:25:32 PM UTC Closing transport socket and unlinking: state=3; <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 38420), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 09:25:32 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
INFO 05/03/2025 09:25:32 PM UTC User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
Exception in thread Thread-8:
Exception in thread Thread-8:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
    self.run()
  File "/app/modules/parser.py", line 145, in run
  File "/app/modules/parser.py", line 145, in run
    self.mq_channel.start_consuming()
    self.mq_channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2049, in _process_data_events
    raise self._closing_reason  # pylint: disable=E0702
    raise self._closing_reason  # pylint: disable=E0702
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
pika.exceptions.ChannelClosedByBroker: (406, 'PRECONDITION_FAILED - delivery acknowledgement on channel 1 timed out. Timeout value used: 1800000 ms. This timeout value can be configured, see consumers doc guide to learn more')
WARNING 05/03/2025 09:25:33 PM UTC ParserThread unexpectedly crashed, restarted it
WARNING 05/03/2025 09:25:33 PM UTC ParserThread unexpectedly crashed, restarted it
INFO 05/03/2025 09:25:33 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 09:25:33 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 09:25:33 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 54612), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 09:25:33 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 54612), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 09:25:33 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c3bc0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c3bc0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 09:25:33 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c3bc0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c3bc0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 09:25:33 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c3bc0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:33 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c3bc0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:33 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c3bc0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:33 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c3bc0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:33 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c3bc0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:33 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x773c337c3bc0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:33 PM UTC Created channel=1
INFO 05/03/2025 09:25:33 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
INFO 05/03/2025 09:25:45 PM UTC Creating default categories in database
INFO 05/03/2025 09:25:45 PM UTC Creating default categories in database
INFO 05/03/2025 09:25:45 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 09:25:45 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 09:25:45 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 36652), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 09:25:45 PM UTC Socket connected: <socket.socket fd=9, family=2, type=1, proto=6, laddr=('10.0.1.190', 36652), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 09:25:45 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf43fe0dc10>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf43fe0dc10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 09:25:45 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf43fe0dc10>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf43fe0dc10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 09:25:45 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf43fe0dc10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:45 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf43fe0dc10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:45 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf43fe0dc10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:45 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf43fe0dc10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:45 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf43fe0dc10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:45 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf43fe0dc10> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:45 PM UTC Created channel=1
INFO 05/03/2025 09:25:45 PM UTC Created channel=1
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from /llm/llama.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   2:                               general.name str              = Merged_Model_2025_04_19
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   3:                         general.size_label str              = 3.2B
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   4:                          llama.block_count u32              = 28
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   5:                       llama.context_length u32              = 131072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  14:                          general.file_type u32              = 32
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128004
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type  f32:   58 tensors
llama_model_loader: - type bf16:  197 tensors
llama_model_loader: - type bf16:  197 tensors
print_info: file format = GGUF V3 (latest)
print_info: file format = GGUF V3 (latest)
print_info: file type   = BF16
print_info: file type   = BF16
print_info: file size   = 5.98 GiB (16.00 BPW) 
print_info: file size   = 5.98 GiB (16.00 BPW) 
init_tokenizer: initializing tokenizer for type 2
init_tokenizer: initializing tokenizer for type 2
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128007 '<|end_header_id|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128001 '<|end_of_text|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128006 '<|start_header_id|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128000 '<|begin_of_text|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128010 '<|python_tag|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG
load: special tokens cache size = 256
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_ctx_train      = 131072
print_info: n_embd           = 3072
print_info: n_embd           = 3072
print_info: n_layer          = 28
print_info: n_layer          = 28
print_info: n_head           = 24
print_info: n_head           = 24
print_info: n_head_kv        = 8
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa            = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 3
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model type       = 3B
print_info: model params     = 3.21 B
print_info: model params     = 3.21 B
print_info: general.name     = Merged_Model_2025_04_19
print_info: general.name     = Merged_Model_2025_04_19
print_info: vocab type       = BPE
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: PAD token        = 128004 '<|finetune_right_pad_id|>'
print_info: LF token         = 198 'Ċ'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   0 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   1 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   2 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   3 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   4 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   5 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   6 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   7 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   8 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer   9 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  10 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  11 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  12 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  13 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  14 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  15 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  16 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  17 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  18 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  19 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  20 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  21 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  22 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  23 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  24 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  25 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  26 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  27 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: layer  28 assigned to device CPU
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors: tensor 'token_embd.weight' (bf16) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB
.........................................................................................
.........................................................................................
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_seq_max     = 1
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx         = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_ctx_per_seq = 32768
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_batch       = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: n_ubatch      = 512
llama_init_from_model: flash_attn    = 0
llama_init_from_model: flash_attn    = 0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_base     = 500000.0
llama_init_from_model: freq_scale    = 1
llama_init_from_model: freq_scale    = 1
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_init_from_model: n_ctx_per_seq (32768) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: kv_size = 32768, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_kv_cache_init:        CPU KV buffer size =  3584.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model: KV self size  = 3584.00 MiB, K (f16): 1792.00 MiB, V (f16): 1792.00 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU  output buffer size =     0.49 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model:        CPU compute buffer size =  1624.01 MiB
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph nodes  = 902
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
llama_init_from_model: graph splits = 450 (with bs=512), 1 (with bs=1)
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = "26 July 2024" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0][\'role\'] == \'system\' %}\n    {%- set system_message = messages[0][\'content\'] %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = "" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- "Environment: ipython\n" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- "Tools: " + builtin_tools | reject(\'equalto\', \'code_interpreter\') | join(", ") + "\n\n"}}\n{%- endif %}\n{{- "Cutting Knowledge Date: December 2023\n" }}\n{{- "Today Date: " + date_string + "\n\n" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- "<|eot_id|>" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0][\'content\'] %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception("Cannot put tools in the first user message when there\'s no first user message!") }}\n{%- endif %}\n    {{- \'<|start_header_id|>user<|end_header_id|>\n\n\' -}}\n    {{- "Given the following functions, please respond with a JSON for a function call " }}\n    {{- "with its proper arguments that best answers the given prompt.\n\n" }}\n    {{- \'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.\' }}\n    {{- "Do not use variables.\n\n" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- "\n\n" }}\n    {%- endfor %}\n    {{- first_user_message + "<|eot_id|>"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == \'ipython\' or message.role == \'tool\' or \'tool_calls\' in message) %}\n        {{- \'<|start_header_id|>\' + message[\'role\'] + \'<|end_header_id|>\n\n\'+ message[\'content\'] + \'<|eot_id|>\' }}\n    {%- elif \'tool_calls\' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception("This model only supports single tool-calls at once!") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- "<|python_tag|>" + tool_call.name + ".call(" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + \'="\' + arg_val + \'"\' }}\n                {%- if not loop.last %}\n                    {{- ", " }}\n                {%- endif %}\n                {%- endfor %}\n            {{- ")" }}\n        {%- else  %}\n            {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' -}}\n            {{- \'{"name": "\' + tool_call.name + \'", \' }}\n            {{- \'"parameters": \' }}\n            {{- tool_call.arguments | tojson }}\n            {{- "}" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we\'re in ipython mode #}\n            {{- "<|eom_id|>" }}\n        {%- else %}\n            {{- "<|eot_id|>" }}\n        {%- endif %}\n    {%- elif message.role == "tool" or message.role == "ipython" %}\n        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- "<|eot_id|>" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- \'<|start_header_id|>assistant<|end_header_id|>\n\n\' }}\n{%- endif %}\n', 'tokenizer.ggml.padding_token_id': '128004', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '32', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_2025_04_19', 'general.type': 'model', 'general.size_label': '3.2B', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}
Available chat formats from metadata: chat_template.default
Available chat formats from metadata: chat_template.default
INFO 05/03/2025 09:25:52 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 09:25:52 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 09:25:52 PM UTC Socket connected: <socket.socket fd=13, family=2, type=1, proto=6, laddr=('10.0.1.190', 37040), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 09:25:52 PM UTC Socket connected: <socket.socket fd=13, family=2, type=1, proto=6, laddr=('10.0.1.190', 37040), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 09:25:52 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf42178f800>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf42178f800> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 09:25:52 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf42178f800>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf42178f800> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 09:25:52 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf42178f800> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:52 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf42178f800> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:52 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf42178f800> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:52 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf42178f800> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:52 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf42178f800> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:52 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf42178f800> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:52 PM UTC Created channel=1
INFO 05/03/2025 09:25:52 PM UTC Created channel=1
INFO 05/03/2025 09:25:52 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 09:25:52 PM UTC Pika version 1.3.2 connecting to ('192.168.42.176', 5672)
INFO 05/03/2025 09:25:52 PM UTC Socket connected: <socket.socket fd=18, family=2, type=1, proto=6, laddr=('10.0.1.190', 37054), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 09:25:52 PM UTC Socket connected: <socket.socket fd=18, family=2, type=1, proto=6, laddr=('10.0.1.190', 37054), raddr=('192.168.42.176', 5672)>
INFO 05/03/2025 09:25:52 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf4217b74a0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf4217b74a0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 09:25:52 PM UTC Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf4217b74a0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf4217b74a0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>).
INFO 05/03/2025 09:25:52 PM UTC New e-mail: cea52e4d-6432-4953-8182-5d41846e3e0d
INFO 05/03/2025 09:25:52 PM UTC New e-mail: cea52e4d-6432-4953-8182-5d41846e3e0d
INFO 05/03/2025 09:25:52 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf4217b74a0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:52 PM UTC AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf4217b74a0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:52 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf4217b74a0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:52 PM UTC AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf4217b74a0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:52 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf4217b74a0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:52 PM UTC Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7bf4217b74a0> params=<ConnectionParameters host=192.168.42.176 port=5672 virtual_host=/events-parser ssl=False>>
INFO 05/03/2025 09:25:52 PM UTC Created channel=1
INFO 05/03/2025 09:25:52 PM UTC Created channel=1
INFO 05/03/2025 09:25:52 PM UTC Server started
INFO 05/03/2025 09:25:52 PM UTC Server started
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time = 1472520.98 ms / 12000 tokens (  122.71 ms per token,     8.15 tokens per second)
llama_perf_context_print: prompt eval time = 1472520.98 ms / 12000 tokens (  122.71 ms per token,     8.15 tokens per second)
llama_perf_context_print:        eval time =   28892.61 ms /    80 runs   (  361.16 ms per token,     2.77 tokens per second)
llama_perf_context_print:        eval time =   28892.61 ms /    80 runs   (  361.16 ms per token,     2.77 tokens per second)
llama_perf_context_print:       total time = 1503189.69 ms / 12080 tokens
llama_perf_context_print:       total time = 1503189.69 ms / 12080 tokens
INFO 05/03/2025 09:27:22 PM UTC E-mail parsing finished: f2be0cc1-bff4-43b4-a601-0da5a2522e79
INFO 05/03/2025 09:27:22 PM UTC E-mail parsing finished: f2be0cc1-bff4-43b4-a601-0da5a2522e79
INFO 05/03/2025 09:27:22 PM UTC New e-mail: 93a27a0e-30f1-4a97-8204-816d18742613
INFO 05/03/2025 09:27:22 PM UTC New e-mail: 93a27a0e-30f1-4a97-8204-816d18742613
Llama.generate: 489 prefix-match hit, remaining 340 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 340 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   48932.24 ms /   340 tokens (  143.92 ms per token,     6.95 tokens per second)
llama_perf_context_print: prompt eval time =   48932.24 ms /   340 tokens (  143.92 ms per token,     6.95 tokens per second)
llama_perf_context_print:        eval time =   26514.98 ms /   120 runs   (  220.96 ms per token,     4.53 tokens per second)
llama_perf_context_print:        eval time =   26514.98 ms /   120 runs   (  220.96 ms per token,     4.53 tokens per second)
llama_perf_context_print:       total time =   78155.41 ms /   460 tokens
llama_perf_context_print:       total time =   78155.41 ms /   460 tokens
INFO 05/03/2025 09:28:41 PM UTC E-mail parsing finished: 93a27a0e-30f1-4a97-8204-816d18742613
INFO 05/03/2025 09:28:41 PM UTC E-mail parsing finished: 93a27a0e-30f1-4a97-8204-816d18742613
INFO 05/03/2025 09:28:41 PM UTC New e-mail: 67780437-834f-4a16-8f98-fb325eb5754f
INFO 05/03/2025 09:28:41 PM UTC New e-mail: 67780437-834f-4a16-8f98-fb325eb5754f
WARNING 05/03/2025 09:28:41 PM UTC Events from an email rejected due to data validation errors
WARNING 05/03/2025 09:28:41 PM UTC Events from an email rejected due to data validation errors
Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 151, in _on_new_events
  File "/app/modules/validator.py", line 151, in _on_new_events
    data: NewEvents = NewEvents.model_validate_json(body)
    data: NewEvents = NewEvents.model_validate_json(body)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 2 validation errors for NewEvents
pydantic_core._pydantic_core.ValidationError: 2 validation errors for NewEvents
events.0.start_date
events.0.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
events.1.start_date
events.1.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
Llama.generate: 489 prefix-match hit, remaining 243 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 243 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  167860.73 ms /  1241 tokens (  135.26 ms per token,     7.39 tokens per second)
llama_perf_context_print: prompt eval time =  167860.73 ms /  1241 tokens (  135.26 ms per token,     7.39 tokens per second)
llama_perf_context_print:        eval time =   58442.10 ms /   216 runs   (  270.57 ms per token,     3.70 tokens per second)
llama_perf_context_print:        eval time =   58442.10 ms /   216 runs   (  270.57 ms per token,     3.70 tokens per second)
llama_perf_context_print:       total time =  231494.33 ms /  1457 tokens
llama_perf_context_print:       total time =  231494.33 ms /  1457 tokens
INFO 05/03/2025 09:29:43 PM UTC E-mail parsing finished: cea52e4d-6432-4953-8182-5d41846e3e0d
INFO 05/03/2025 09:29:43 PM UTC E-mail parsing finished: cea52e4d-6432-4953-8182-5d41846e3e0d
INFO 05/03/2025 09:29:43 PM UTC New e-mail: 4005bbf5-8176-4dcf-9f3d-e96aa026ebfd
INFO 05/03/2025 09:29:43 PM UTC New e-mail: 4005bbf5-8176-4dcf-9f3d-e96aa026ebfd
Llama.generate: 489 prefix-match hit, remaining 549 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 549 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   76350.17 ms /   243 tokens (  314.20 ms per token,     3.18 tokens per second)
llama_perf_context_print: prompt eval time =   76350.17 ms /   243 tokens (  314.20 ms per token,     3.18 tokens per second)
llama_perf_context_print:        eval time =   18789.21 ms /    86 runs   (  218.48 ms per token,     4.58 tokens per second)
llama_perf_context_print:        eval time =   18789.21 ms /    86 runs   (  218.48 ms per token,     4.58 tokens per second)
llama_perf_context_print:       total time =   97382.34 ms /   329 tokens
llama_perf_context_print:       total time =   97382.34 ms /   329 tokens
INFO 05/03/2025 09:30:18 PM UTC E-mail parsing finished: 67780437-834f-4a16-8f98-fb325eb5754f
INFO 05/03/2025 09:30:18 PM UTC E-mail parsing finished: 67780437-834f-4a16-8f98-fb325eb5754f
INFO 05/03/2025 09:30:18 PM UTC New e-mail: d1782104-0608-4e26-ba32-17f22c429e14
INFO 05/03/2025 09:30:18 PM UTC New e-mail: d1782104-0608-4e26-ba32-17f22c429e14
Llama.generate: 489 prefix-match hit, remaining 180 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 180 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   45682.54 ms /   180 tokens (  253.79 ms per token,     3.94 tokens per second)
llama_perf_context_print: prompt eval time =   45682.54 ms /   180 tokens (  253.79 ms per token,     3.94 tokens per second)
llama_perf_context_print:        eval time =     242.26 ms /     1 runs   (  242.26 ms per token,     4.13 tokens per second)
llama_perf_context_print:        eval time =     242.26 ms /     1 runs   (  242.26 ms per token,     4.13 tokens per second)
llama_perf_context_print:       total time =   45977.54 ms /   181 tokens
llama_perf_context_print:       total time =   45977.54 ms /   181 tokens
INFO 05/03/2025 09:31:04 PM UTC E-mail parsing finished: d1782104-0608-4e26-ba32-17f22c429e14
INFO 05/03/2025 09:31:04 PM UTC E-mail parsing finished: d1782104-0608-4e26-ba32-17f22c429e14
INFO 05/03/2025 09:31:04 PM UTC New e-mail: 03461a9f-c9fe-45eb-b175-0888d15f6f36
INFO 05/03/2025 09:31:04 PM UTC New e-mail: 03461a9f-c9fe-45eb-b175-0888d15f6f36
Llama.generate: 489 prefix-match hit, remaining 103 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 103 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   98174.78 ms /   549 tokens (  178.82 ms per token,     5.59 tokens per second)
llama_perf_context_print: prompt eval time =   98174.78 ms /   549 tokens (  178.82 ms per token,     5.59 tokens per second)
llama_perf_context_print:        eval time =   33704.44 ms /   141 runs   (  239.04 ms per token,     4.18 tokens per second)
llama_perf_context_print:        eval time =   33704.44 ms /   141 runs   (  239.04 ms per token,     4.18 tokens per second)
llama_perf_context_print:       total time =  135502.89 ms /   690 tokens
llama_perf_context_print:       total time =  135502.89 ms /   690 tokens
INFO 05/03/2025 09:31:59 PM UTC E-mail parsing finished: 4005bbf5-8176-4dcf-9f3d-e96aa026ebfd
INFO 05/03/2025 09:31:59 PM UTC E-mail parsing finished: 4005bbf5-8176-4dcf-9f3d-e96aa026ebfd
INFO 05/03/2025 09:31:59 PM UTC New e-mail: e8ae81a4-98ea-4d75-b588-42dbb691f7c1
INFO 05/03/2025 09:31:59 PM UTC New e-mail: e8ae81a4-98ea-4d75-b588-42dbb691f7c1
Llama.generate: 489 prefix-match hit, remaining 1728 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1728 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   62366.55 ms /   103 tokens (  605.50 ms per token,     1.65 tokens per second)
llama_perf_context_print: prompt eval time =   62366.55 ms /   103 tokens (  605.50 ms per token,     1.65 tokens per second)
llama_perf_context_print:        eval time =     231.60 ms /     1 runs   (  231.60 ms per token,     4.32 tokens per second)
llama_perf_context_print:        eval time =     231.60 ms /     1 runs   (  231.60 ms per token,     4.32 tokens per second)
llama_perf_context_print:       total time =   62642.66 ms /   104 tokens
llama_perf_context_print:       total time =   62642.66 ms /   104 tokens
INFO 05/03/2025 09:32:07 PM UTC E-mail parsing finished: 03461a9f-c9fe-45eb-b175-0888d15f6f36
INFO 05/03/2025 09:32:07 PM UTC E-mail parsing finished: 03461a9f-c9fe-45eb-b175-0888d15f6f36
INFO 05/03/2025 09:32:07 PM UTC New e-mail: 00615dee-08f4-46a1-8d17-ed76c658e340
INFO 05/03/2025 09:32:07 PM UTC New e-mail: 00615dee-08f4-46a1-8d17-ed76c658e340
Llama.generate: 489 prefix-match hit, remaining 589 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 589 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   96714.74 ms /   589 tokens (  164.20 ms per token,     6.09 tokens per second)
llama_perf_context_print: prompt eval time =   96714.74 ms /   589 tokens (  164.20 ms per token,     6.09 tokens per second)
llama_perf_context_print:        eval time =   22090.47 ms /    97 runs   (  227.74 ms per token,     4.39 tokens per second)
llama_perf_context_print:        eval time =   22090.47 ms /    97 runs   (  227.74 ms per token,     4.39 tokens per second)
llama_perf_context_print:       total time =  121175.89 ms /   686 tokens
llama_perf_context_print:       total time =  121175.89 ms /   686 tokens
INFO 05/03/2025 09:34:08 PM UTC E-mail parsing finished: 00615dee-08f4-46a1-8d17-ed76c658e340
INFO 05/03/2025 09:34:08 PM UTC E-mail parsing finished: 00615dee-08f4-46a1-8d17-ed76c658e340
INFO 05/03/2025 09:34:08 PM UTC New e-mail: 9ffdcd17-8ced-4a60-9416-f352050c613a
INFO 05/03/2025 09:34:08 PM UTC New e-mail: 9ffdcd17-8ced-4a60-9416-f352050c613a
Llama.generate: 535 prefix-match hit, remaining 1166 prompt tokens to eval
Llama.generate: 535 prefix-match hit, remaining 1166 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  200233.18 ms /  1728 tokens (  115.88 ms per token,     8.63 tokens per second)
llama_perf_context_print: prompt eval time =  200233.18 ms /  1728 tokens (  115.88 ms per token,     8.63 tokens per second)
llama_perf_context_print:        eval time =   14795.50 ms /    50 runs   (  295.91 ms per token,     3.38 tokens per second)
llama_perf_context_print:        eval time =   14795.50 ms /    50 runs   (  295.91 ms per token,     3.38 tokens per second)
llama_perf_context_print:       total time =  216134.93 ms /  1778 tokens
llama_perf_context_print:       total time =  216134.93 ms /  1778 tokens
INFO 05/03/2025 09:35:35 PM UTC E-mail parsing finished: e8ae81a4-98ea-4d75-b588-42dbb691f7c1
INFO 05/03/2025 09:35:35 PM UTC E-mail parsing finished: e8ae81a4-98ea-4d75-b588-42dbb691f7c1
WARNING 05/03/2025 09:35:35 PM UTC Events from an email rejected due to data validation errors
WARNING 05/03/2025 09:35:35 PM UTC Events from an email rejected due to data validation errors
Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 151, in _on_new_events
  File "/app/modules/validator.py", line 151, in _on_new_events
    data: NewEvents = NewEvents.model_validate_json(body)
    data: NewEvents = NewEvents.model_validate_json(body)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
events.0.start_date
events.0.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
INFO 05/03/2025 09:35:35 PM UTC New e-mail: f58d7672-adaf-4317-b620-6f88e97ea218
INFO 05/03/2025 09:35:35 PM UTC New e-mail: f58d7672-adaf-4317-b620-6f88e97ea218
Llama.generate: 489 prefix-match hit, remaining 394 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 394 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   45763.29 ms /   394 tokens (  116.15 ms per token,     8.61 tokens per second)
llama_perf_context_print: prompt eval time =   45763.29 ms /   394 tokens (  116.15 ms per token,     8.61 tokens per second)
llama_perf_context_print:        eval time =     280.77 ms /     1 runs   (  280.77 ms per token,     3.56 tokens per second)
llama_perf_context_print:        eval time =     280.77 ms /     1 runs   (  280.77 ms per token,     3.56 tokens per second)
llama_perf_context_print:       total time =   46094.41 ms /   395 tokens
llama_perf_context_print:       total time =   46094.41 ms /   395 tokens
INFO 05/03/2025 09:36:21 PM UTC E-mail parsing finished: f58d7672-adaf-4317-b620-6f88e97ea218
INFO 05/03/2025 09:36:21 PM UTC E-mail parsing finished: f58d7672-adaf-4317-b620-6f88e97ea218
INFO 05/03/2025 09:36:21 PM UTC New e-mail: 2eacd3b1-6d8c-4ca5-a93c-fd81be1b5304
INFO 05/03/2025 09:36:21 PM UTC New e-mail: 2eacd3b1-6d8c-4ca5-a93c-fd81be1b5304
Llama.generate: 540 prefix-match hit, remaining 236 prompt tokens to eval
Llama.generate: 540 prefix-match hit, remaining 236 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  155929.08 ms /  1166 tokens (  133.73 ms per token,     7.48 tokens per second)
llama_perf_context_print: prompt eval time =  155929.08 ms /  1166 tokens (  133.73 ms per token,     7.48 tokens per second)
llama_perf_context_print:        eval time =   43182.60 ms /   179 runs   (  241.24 ms per token,     4.15 tokens per second)
llama_perf_context_print:        eval time =   43182.60 ms /   179 runs   (  241.24 ms per token,     4.15 tokens per second)
llama_perf_context_print:       total time =  202926.57 ms /  1345 tokens
llama_perf_context_print:       total time =  202926.57 ms /  1345 tokens
INFO 05/03/2025 09:37:31 PM UTC E-mail parsing finished: 9ffdcd17-8ced-4a60-9416-f352050c613a
INFO 05/03/2025 09:37:31 PM UTC E-mail parsing finished: 9ffdcd17-8ced-4a60-9416-f352050c613a
INFO 05/03/2025 09:37:31 PM UTC New e-mail: 6291dc34-dbf1-4764-a5cd-e6d666868d82
INFO 05/03/2025 09:37:31 PM UTC New e-mail: 6291dc34-dbf1-4764-a5cd-e6d666868d82
Llama.generate: 489 prefix-match hit, remaining 374 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 374 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   67601.65 ms /   236 tokens (  286.45 ms per token,     3.49 tokens per second)
llama_perf_context_print: prompt eval time =   67601.65 ms /   236 tokens (  286.45 ms per token,     3.49 tokens per second)
llama_perf_context_print:        eval time =   11560.69 ms /    50 runs   (  231.21 ms per token,     4.33 tokens per second)
llama_perf_context_print:        eval time =   11560.69 ms /    50 runs   (  231.21 ms per token,     4.33 tokens per second)
llama_perf_context_print:       total time =   80321.74 ms /   286 tokens
llama_perf_context_print:       total time =   80321.74 ms /   286 tokens
INFO 05/03/2025 09:37:41 PM UTC E-mail parsing finished: 2eacd3b1-6d8c-4ca5-a93c-fd81be1b5304
INFO 05/03/2025 09:37:41 PM UTC E-mail parsing finished: 2eacd3b1-6d8c-4ca5-a93c-fd81be1b5304
WARNING 05/03/2025 09:37:41 PM UTC Events from an email rejected due to data validation errors
WARNING 05/03/2025 09:37:41 PM UTC Events from an email rejected due to data validation errors
Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 151, in _on_new_events
  File "/app/modules/validator.py", line 151, in _on_new_events
    data: NewEvents = NewEvents.model_validate_json(body)
    data: NewEvents = NewEvents.model_validate_json(body)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
events.0.start_date
events.0.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
INFO 05/03/2025 09:37:41 PM UTC New e-mail: 3b55272d-46a5-4e72-85cf-4e5b42ab2254
INFO 05/03/2025 09:37:41 PM UTC New e-mail: 3b55272d-46a5-4e72-85cf-4e5b42ab2254
Llama.generate: 489 prefix-match hit, remaining 382 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 382 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   47757.80 ms /   382 tokens (  125.02 ms per token,     8.00 tokens per second)
llama_perf_context_print: prompt eval time =   47757.80 ms /   382 tokens (  125.02 ms per token,     8.00 tokens per second)
llama_perf_context_print:        eval time =     211.37 ms /     1 runs   (  211.37 ms per token,     4.73 tokens per second)
llama_perf_context_print:        eval time =     211.37 ms /     1 runs   (  211.37 ms per token,     4.73 tokens per second)
llama_perf_context_print:       total time =   48001.27 ms /   383 tokens
llama_perf_context_print:       total time =   48001.27 ms /   383 tokens
INFO 05/03/2025 09:38:29 PM UTC E-mail parsing finished: 3b55272d-46a5-4e72-85cf-4e5b42ab2254
INFO 05/03/2025 09:38:29 PM UTC E-mail parsing finished: 3b55272d-46a5-4e72-85cf-4e5b42ab2254
INFO 05/03/2025 09:38:29 PM UTC New e-mail: e1ea0a4e-18e1-4ec7-a3a1-132631f8ac5c
INFO 05/03/2025 09:38:29 PM UTC New e-mail: e1ea0a4e-18e1-4ec7-a3a1-132631f8ac5c
Llama.generate: 489 prefix-match hit, remaining 704 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 704 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   54896.39 ms /   374 tokens (  146.78 ms per token,     6.81 tokens per second)
llama_perf_context_print: prompt eval time =   54896.39 ms /   374 tokens (  146.78 ms per token,     6.81 tokens per second)
llama_perf_context_print:        eval time =   15651.30 ms /    79 runs   (  198.12 ms per token,     5.05 tokens per second)
llama_perf_context_print:        eval time =   15651.30 ms /    79 runs   (  198.12 ms per token,     5.05 tokens per second)
llama_perf_context_print:       total time =   72608.09 ms /   453 tokens
llama_perf_context_print:       total time =   72608.09 ms /   453 tokens
INFO 05/03/2025 09:38:43 PM UTC E-mail parsing finished: 6291dc34-dbf1-4764-a5cd-e6d666868d82
INFO 05/03/2025 09:38:43 PM UTC E-mail parsing finished: 6291dc34-dbf1-4764-a5cd-e6d666868d82
INFO 05/03/2025 09:38:43 PM UTC New e-mail: 1dfa300f-1993-4422-bf36-de0a2b9ea3d1
INFO 05/03/2025 09:38:43 PM UTC New e-mail: 1dfa300f-1993-4422-bf36-de0a2b9ea3d1
Llama.generate: 489 prefix-match hit, remaining 481 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 481 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   53891.27 ms /   481 tokens (  112.04 ms per token,     8.93 tokens per second)
llama_perf_context_print: prompt eval time =   53891.27 ms /   481 tokens (  112.04 ms per token,     8.93 tokens per second)
llama_perf_context_print:        eval time =     194.06 ms /     1 runs   (  194.06 ms per token,     5.15 tokens per second)
llama_perf_context_print:        eval time =     194.06 ms /     1 runs   (  194.06 ms per token,     5.15 tokens per second)
llama_perf_context_print:       total time =   54176.06 ms /   482 tokens
llama_perf_context_print:       total time =   54176.06 ms /   482 tokens
INFO 05/03/2025 09:39:38 PM UTC E-mail parsing finished: 1dfa300f-1993-4422-bf36-de0a2b9ea3d1
INFO 05/03/2025 09:39:38 PM UTC E-mail parsing finished: 1dfa300f-1993-4422-bf36-de0a2b9ea3d1
INFO 05/03/2025 09:39:38 PM UTC New e-mail: af8644d5-8e35-4db0-a9aa-5703f2a3926f
INFO 05/03/2025 09:39:38 PM UTC New e-mail: af8644d5-8e35-4db0-a9aa-5703f2a3926f
Llama.generate: 489 prefix-match hit, remaining 357 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 357 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   97495.59 ms /   704 tokens (  138.49 ms per token,     7.22 tokens per second)
llama_perf_context_print: prompt eval time =   97495.59 ms /   704 tokens (  138.49 ms per token,     7.22 tokens per second)
llama_perf_context_print:        eval time =     298.54 ms /     1 runs   (  298.54 ms per token,     3.35 tokens per second)
llama_perf_context_print:        eval time =     298.54 ms /     1 runs   (  298.54 ms per token,     3.35 tokens per second)
llama_perf_context_print:       total time =   97862.44 ms /   705 tokens
llama_perf_context_print:       total time =   97862.44 ms /   705 tokens
INFO 05/03/2025 09:40:07 PM UTC E-mail parsing finished: e1ea0a4e-18e1-4ec7-a3a1-132631f8ac5c
INFO 05/03/2025 09:40:07 PM UTC E-mail parsing finished: e1ea0a4e-18e1-4ec7-a3a1-132631f8ac5c
INFO 05/03/2025 09:40:07 PM UTC New e-mail: 1e9049c7-9735-46e0-8eee-6fd923dc2616
INFO 05/03/2025 09:40:07 PM UTC New e-mail: 1e9049c7-9735-46e0-8eee-6fd923dc2616
Llama.generate: 489 prefix-match hit, remaining 182 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 182 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   51796.89 ms /   357 tokens (  145.09 ms per token,     6.89 tokens per second)
llama_perf_context_print: prompt eval time =   51796.89 ms /   357 tokens (  145.09 ms per token,     6.89 tokens per second)
llama_perf_context_print:        eval time =     251.59 ms /     1 runs   (  251.59 ms per token,     3.97 tokens per second)
llama_perf_context_print:        eval time =     251.59 ms /     1 runs   (  251.59 ms per token,     3.97 tokens per second)
llama_perf_context_print:       total time =   52122.96 ms /   358 tokens
llama_perf_context_print:       total time =   52122.96 ms /   358 tokens
INFO 05/03/2025 09:40:30 PM UTC E-mail parsing finished: af8644d5-8e35-4db0-a9aa-5703f2a3926f
INFO 05/03/2025 09:40:30 PM UTC E-mail parsing finished: af8644d5-8e35-4db0-a9aa-5703f2a3926f
INFO 05/03/2025 09:40:30 PM UTC New e-mail: fe0fef2b-b845-4f18-840b-fe4a864d8e85
INFO 05/03/2025 09:40:30 PM UTC New e-mail: fe0fef2b-b845-4f18-840b-fe4a864d8e85
Llama.generate: 489 prefix-match hit, remaining 64 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 64 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   39466.70 ms /   182 tokens (  216.85 ms per token,     4.61 tokens per second)
llama_perf_context_print: prompt eval time =   39466.70 ms /   182 tokens (  216.85 ms per token,     4.61 tokens per second)
llama_perf_context_print:        eval time =     281.98 ms /     1 runs   (  281.98 ms per token,     3.55 tokens per second)
llama_perf_context_print:        eval time =     281.98 ms /     1 runs   (  281.98 ms per token,     3.55 tokens per second)
llama_perf_context_print:       total time =   39847.89 ms /   183 tokens
llama_perf_context_print:       total time =   39847.89 ms /   183 tokens
INFO 05/03/2025 09:40:47 PM UTC E-mail parsing finished: 1e9049c7-9735-46e0-8eee-6fd923dc2616
INFO 05/03/2025 09:40:47 PM UTC E-mail parsing finished: 1e9049c7-9735-46e0-8eee-6fd923dc2616
INFO 05/03/2025 09:40:47 PM UTC New e-mail: 8f2014c7-4fd6-4a5c-bcc6-27bc66cf5d08
INFO 05/03/2025 09:40:47 PM UTC New e-mail: 8f2014c7-4fd6-4a5c-bcc6-27bc66cf5d08
Llama.generate: 489 prefix-match hit, remaining 1378 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1378 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   37719.67 ms /    64 tokens (  589.37 ms per token,     1.70 tokens per second)
llama_perf_context_print: prompt eval time =   37719.67 ms /    64 tokens (  589.37 ms per token,     1.70 tokens per second)
llama_perf_context_print:        eval time =     242.99 ms /     1 runs   (  242.99 ms per token,     4.12 tokens per second)
llama_perf_context_print:        eval time =     242.99 ms /     1 runs   (  242.99 ms per token,     4.12 tokens per second)
llama_perf_context_print:       total time =   38018.68 ms /    65 tokens
llama_perf_context_print:       total time =   38018.68 ms /    65 tokens
INFO 05/03/2025 09:41:08 PM UTC E-mail parsing finished: fe0fef2b-b845-4f18-840b-fe4a864d8e85
INFO 05/03/2025 09:41:08 PM UTC E-mail parsing finished: fe0fef2b-b845-4f18-840b-fe4a864d8e85
INFO 05/03/2025 09:41:08 PM UTC New e-mail: 9fe2ca0e-025d-415a-afed-c81c2c1c2341
INFO 05/03/2025 09:41:08 PM UTC New e-mail: 9fe2ca0e-025d-415a-afed-c81c2c1c2341
Llama.generate: 489 prefix-match hit, remaining 566 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 566 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   89770.84 ms /   566 tokens (  158.61 ms per token,     6.30 tokens per second)
llama_perf_context_print: prompt eval time =   89770.84 ms /   566 tokens (  158.61 ms per token,     6.30 tokens per second)
llama_perf_context_print:        eval time =   31783.69 ms /   135 runs   (  235.43 ms per token,     4.25 tokens per second)
llama_perf_context_print:        eval time =   31783.69 ms /   135 runs   (  235.43 ms per token,     4.25 tokens per second)
llama_perf_context_print:       total time =  124849.79 ms /   701 tokens
llama_perf_context_print:       total time =  124849.79 ms /   701 tokens
INFO 05/03/2025 09:43:13 PM UTC E-mail parsing finished: 9fe2ca0e-025d-415a-afed-c81c2c1c2341
INFO 05/03/2025 09:43:13 PM UTC E-mail parsing finished: 9fe2ca0e-025d-415a-afed-c81c2c1c2341
INFO 05/03/2025 09:43:13 PM UTC New e-mail: dd254699-18b4-4ed3-a355-c5361d961f45
INFO 05/03/2025 09:43:13 PM UTC New e-mail: dd254699-18b4-4ed3-a355-c5361d961f45
Llama.generate: 489 prefix-match hit, remaining 10822 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 10822 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  160147.33 ms /  1378 tokens (  116.22 ms per token,     8.60 tokens per second)
llama_perf_context_print: prompt eval time =  160147.33 ms /  1378 tokens (  116.22 ms per token,     8.60 tokens per second)
llama_perf_context_print:        eval time =   50123.90 ms /   184 runs   (  272.41 ms per token,     3.67 tokens per second)
llama_perf_context_print:        eval time =   50123.90 ms /   184 runs   (  272.41 ms per token,     3.67 tokens per second)
llama_perf_context_print:       total time =  214474.74 ms /  1562 tokens
llama_perf_context_print:       total time =  214474.74 ms /  1562 tokens
INFO 05/03/2025 09:44:21 PM UTC E-mail parsing finished: 8f2014c7-4fd6-4a5c-bcc6-27bc66cf5d08
INFO 05/03/2025 09:44:21 PM UTC E-mail parsing finished: 8f2014c7-4fd6-4a5c-bcc6-27bc66cf5d08
INFO 05/03/2025 09:44:21 PM UTC New e-mail: e829988b-0cc6-45fc-b3d6-126c2c71479b
INFO 05/03/2025 09:44:21 PM UTC New e-mail: e829988b-0cc6-45fc-b3d6-126c2c71479b
Llama.generate: 489 prefix-match hit, remaining 230 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 230 prompt tokens to eval
ERROR 05/03/2025 09:44:22 PM UTC Unknown exception occurred
ERROR 05/03/2025 09:44:22 PM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '1962-6' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '1962-6' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1962-6' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '1962-6' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 1962, 'tag_id': 6}, {'event_id': 1962, 'tag_id': 5}, {'event_id': 1962, 'tag_id': 6}, {'event_id': 1962, 'tag_id': 5}]]
[parameters: [{'event_id': 1962, 'tag_id': 6}, {'event_id': 1962, 'tag_id': 5}, {'event_id': 1962, 'tag_id': 6}, {'event_id': 1962, 'tag_id': 5}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   47793.65 ms /   230 tokens (  207.80 ms per token,     4.81 tokens per second)
llama_perf_context_print: prompt eval time =   47793.65 ms /   230 tokens (  207.80 ms per token,     4.81 tokens per second)
llama_perf_context_print:        eval time =     306.96 ms /     1 runs   (  306.96 ms per token,     3.26 tokens per second)
llama_perf_context_print:        eval time =     306.96 ms /     1 runs   (  306.96 ms per token,     3.26 tokens per second)
llama_perf_context_print:       total time =   48155.17 ms /   231 tokens
llama_perf_context_print:       total time =   48155.17 ms /   231 tokens
INFO 05/03/2025 09:45:10 PM UTC E-mail parsing finished: e829988b-0cc6-45fc-b3d6-126c2c71479b
INFO 05/03/2025 09:45:10 PM UTC E-mail parsing finished: e829988b-0cc6-45fc-b3d6-126c2c71479b
INFO 05/03/2025 09:45:10 PM UTC New e-mail: 1bdbab15-f18c-478d-984e-6bac40daf444
INFO 05/03/2025 09:45:10 PM UTC New e-mail: 1bdbab15-f18c-478d-984e-6bac40daf444
Llama.generate: 489 prefix-match hit, remaining 472 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 472 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   53196.51 ms /   472 tokens (  112.70 ms per token,     8.87 tokens per second)
llama_perf_context_print: prompt eval time =   53196.51 ms /   472 tokens (  112.70 ms per token,     8.87 tokens per second)
llama_perf_context_print:        eval time =   19163.50 ms /    74 runs   (  258.97 ms per token,     3.86 tokens per second)
llama_perf_context_print:        eval time =   19163.50 ms /    74 runs   (  258.97 ms per token,     3.86 tokens per second)
llama_perf_context_print:       total time =   74108.05 ms /   546 tokens
llama_perf_context_print:       total time =   74108.05 ms /   546 tokens
INFO 05/03/2025 09:46:24 PM UTC E-mail parsing finished: 1bdbab15-f18c-478d-984e-6bac40daf444
INFO 05/03/2025 09:46:24 PM UTC E-mail parsing finished: 1bdbab15-f18c-478d-984e-6bac40daf444
INFO 05/03/2025 09:46:24 PM UTC New e-mail: 35e449f1-7536-4e03-a044-90e89d2fead0
INFO 05/03/2025 09:46:24 PM UTC New e-mail: 35e449f1-7536-4e03-a044-90e89d2fead0
Llama.generate: 489 prefix-match hit, remaining 180 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 180 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   42666.86 ms /   180 tokens (  237.04 ms per token,     4.22 tokens per second)
llama_perf_context_print: prompt eval time =   42666.86 ms /   180 tokens (  237.04 ms per token,     4.22 tokens per second)
llama_perf_context_print:        eval time =     287.94 ms /     1 runs   (  287.94 ms per token,     3.47 tokens per second)
llama_perf_context_print:        eval time =     287.94 ms /     1 runs   (  287.94 ms per token,     3.47 tokens per second)
llama_perf_context_print:       total time =   43020.66 ms /   181 tokens
llama_perf_context_print:       total time =   43020.66 ms /   181 tokens
INFO 05/03/2025 09:47:07 PM UTC E-mail parsing finished: 35e449f1-7536-4e03-a044-90e89d2fead0
INFO 05/03/2025 09:47:07 PM UTC E-mail parsing finished: 35e449f1-7536-4e03-a044-90e89d2fead0
INFO 05/03/2025 09:47:07 PM UTC New e-mail: 0817e544-6875-4f5c-a45b-bce3b577a95e
INFO 05/03/2025 09:47:07 PM UTC New e-mail: 0817e544-6875-4f5c-a45b-bce3b577a95e
Llama.generate: 489 prefix-match hit, remaining 114 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 114 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   41642.49 ms /   114 tokens (  365.29 ms per token,     2.74 tokens per second)
llama_perf_context_print: prompt eval time =   41642.49 ms /   114 tokens (  365.29 ms per token,     2.74 tokens per second)
llama_perf_context_print:        eval time =     270.08 ms /     1 runs   (  270.08 ms per token,     3.70 tokens per second)
llama_perf_context_print:        eval time =     270.08 ms /     1 runs   (  270.08 ms per token,     3.70 tokens per second)
llama_perf_context_print:       total time =   41975.18 ms /   115 tokens
llama_perf_context_print:       total time =   41975.18 ms /   115 tokens
INFO 05/03/2025 09:47:49 PM UTC E-mail parsing finished: 0817e544-6875-4f5c-a45b-bce3b577a95e
INFO 05/03/2025 09:47:49 PM UTC E-mail parsing finished: 0817e544-6875-4f5c-a45b-bce3b577a95e
INFO 05/03/2025 09:47:49 PM UTC New e-mail: 3af738e1-6f91-46a9-8bfb-4dc8b8c62800
INFO 05/03/2025 09:47:49 PM UTC New e-mail: 3af738e1-6f91-46a9-8bfb-4dc8b8c62800
Llama.generate: 489 prefix-match hit, remaining 1475 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1475 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  148448.26 ms /  1475 tokens (  100.64 ms per token,     9.94 tokens per second)
llama_perf_context_print: prompt eval time =  148448.26 ms /  1475 tokens (  100.64 ms per token,     9.94 tokens per second)
llama_perf_context_print:        eval time =     263.99 ms /     1 runs   (  263.99 ms per token,     3.79 tokens per second)
llama_perf_context_print:        eval time =     263.99 ms /     1 runs   (  263.99 ms per token,     3.79 tokens per second)
llama_perf_context_print:       total time =  148783.26 ms /  1476 tokens
llama_perf_context_print:       total time =  148783.26 ms /  1476 tokens
INFO 05/03/2025 09:50:18 PM UTC E-mail parsing finished: 3af738e1-6f91-46a9-8bfb-4dc8b8c62800
INFO 05/03/2025 09:50:18 PM UTC E-mail parsing finished: 3af738e1-6f91-46a9-8bfb-4dc8b8c62800
INFO 05/03/2025 09:50:18 PM UTC New e-mail: 50b1adec-9d04-4183-a68b-89054c4219ae
INFO 05/03/2025 09:50:18 PM UTC New e-mail: 50b1adec-9d04-4183-a68b-89054c4219ae
Llama.generate: 489 prefix-match hit, remaining 1638 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1638 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  191695.89 ms /  1638 tokens (  117.03 ms per token,     8.54 tokens per second)
llama_perf_context_print: prompt eval time =  191695.89 ms /  1638 tokens (  117.03 ms per token,     8.54 tokens per second)
llama_perf_context_print:        eval time =     252.09 ms /     1 runs   (  252.09 ms per token,     3.97 tokens per second)
llama_perf_context_print:        eval time =     252.09 ms /     1 runs   (  252.09 ms per token,     3.97 tokens per second)
llama_perf_context_print:       total time =  192066.53 ms /  1639 tokens
llama_perf_context_print:       total time =  192066.53 ms /  1639 tokens
INFO 05/03/2025 09:53:30 PM UTC E-mail parsing finished: 50b1adec-9d04-4183-a68b-89054c4219ae
INFO 05/03/2025 09:53:30 PM UTC E-mail parsing finished: 50b1adec-9d04-4183-a68b-89054c4219ae
INFO 05/03/2025 09:53:30 PM UTC New e-mail: 33b2ebb4-e170-4f69-a3dc-079a61382d0a
INFO 05/03/2025 09:53:30 PM UTC New e-mail: 33b2ebb4-e170-4f69-a3dc-079a61382d0a
Llama.generate: 489 prefix-match hit, remaining 1526 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1526 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  146167.28 ms /  1526 tokens (   95.78 ms per token,    10.44 tokens per second)
llama_perf_context_print: prompt eval time =  146167.28 ms /  1526 tokens (   95.78 ms per token,    10.44 tokens per second)
llama_perf_context_print:        eval time =     293.25 ms /     1 runs   (  293.25 ms per token,     3.41 tokens per second)
llama_perf_context_print:        eval time =     293.25 ms /     1 runs   (  293.25 ms per token,     3.41 tokens per second)
llama_perf_context_print:       total time =  146526.37 ms /  1527 tokens
llama_perf_context_print:       total time =  146526.37 ms /  1527 tokens
INFO 05/03/2025 09:55:56 PM UTC E-mail parsing finished: 33b2ebb4-e170-4f69-a3dc-079a61382d0a
INFO 05/03/2025 09:55:56 PM UTC E-mail parsing finished: 33b2ebb4-e170-4f69-a3dc-079a61382d0a
INFO 05/03/2025 09:55:56 PM UTC New e-mail: e601690a-ded3-4874-abe6-cc1ed8aa7a5c
INFO 05/03/2025 09:55:56 PM UTC New e-mail: e601690a-ded3-4874-abe6-cc1ed8aa7a5c
Llama.generate: 489 prefix-match hit, remaining 1412 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1412 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  140979.64 ms /  1412 tokens (   99.84 ms per token,    10.02 tokens per second)
llama_perf_context_print: prompt eval time =  140979.64 ms /  1412 tokens (   99.84 ms per token,    10.02 tokens per second)
llama_perf_context_print:        eval time =     292.07 ms /     1 runs   (  292.07 ms per token,     3.42 tokens per second)
llama_perf_context_print:        eval time =     292.07 ms /     1 runs   (  292.07 ms per token,     3.42 tokens per second)
llama_perf_context_print:       total time =  141356.07 ms /  1413 tokens
llama_perf_context_print:       total time =  141356.07 ms /  1413 tokens
INFO 05/03/2025 09:58:18 PM UTC E-mail parsing finished: e601690a-ded3-4874-abe6-cc1ed8aa7a5c
INFO 05/03/2025 09:58:18 PM UTC E-mail parsing finished: e601690a-ded3-4874-abe6-cc1ed8aa7a5c
INFO 05/03/2025 09:58:18 PM UTC New e-mail: d7a0d50f-a640-469a-9249-1f2b60a49787
INFO 05/03/2025 09:58:18 PM UTC New e-mail: d7a0d50f-a640-469a-9249-1f2b60a49787
Llama.generate: 489 prefix-match hit, remaining 1265 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1265 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  142441.90 ms /  1265 tokens (  112.60 ms per token,     8.88 tokens per second)
llama_perf_context_print: prompt eval time =  142441.90 ms /  1265 tokens (  112.60 ms per token,     8.88 tokens per second)
llama_perf_context_print:        eval time =     303.13 ms /     1 runs   (  303.13 ms per token,     3.30 tokens per second)
llama_perf_context_print:        eval time =     303.13 ms /     1 runs   (  303.13 ms per token,     3.30 tokens per second)
llama_perf_context_print:       total time =  142803.54 ms /  1266 tokens
llama_perf_context_print:       total time =  142803.54 ms /  1266 tokens
INFO 05/03/2025 10:00:40 PM UTC E-mail parsing finished: d7a0d50f-a640-469a-9249-1f2b60a49787
INFO 05/03/2025 10:00:40 PM UTC E-mail parsing finished: d7a0d50f-a640-469a-9249-1f2b60a49787
INFO 05/03/2025 10:00:40 PM UTC New e-mail: 898cfbcd-9d26-4d9b-a02e-e1ede9ce7979
INFO 05/03/2025 10:00:40 PM UTC New e-mail: 898cfbcd-9d26-4d9b-a02e-e1ede9ce7979
Llama.generate: 520 prefix-match hit, remaining 22 prompt tokens to eval
Llama.generate: 520 prefix-match hit, remaining 22 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =    2027.17 ms /    22 tokens (   92.14 ms per token,    10.85 tokens per second)
llama_perf_context_print: prompt eval time =    2027.17 ms /    22 tokens (   92.14 ms per token,    10.85 tokens per second)
llama_perf_context_print:        eval time =     269.23 ms /     1 runs   (  269.23 ms per token,     3.71 tokens per second)
llama_perf_context_print:        eval time =     269.23 ms /     1 runs   (  269.23 ms per token,     3.71 tokens per second)
llama_perf_context_print:       total time =    2349.11 ms /    23 tokens
llama_perf_context_print:       total time =    2349.11 ms /    23 tokens
INFO 05/03/2025 10:00:43 PM UTC E-mail parsing finished: 898cfbcd-9d26-4d9b-a02e-e1ede9ce7979
INFO 05/03/2025 10:00:43 PM UTC E-mail parsing finished: 898cfbcd-9d26-4d9b-a02e-e1ede9ce7979
INFO 05/03/2025 10:00:43 PM UTC New e-mail: f36469b8-35ad-43dd-bd40-eee9347da439
INFO 05/03/2025 10:00:43 PM UTC New e-mail: f36469b8-35ad-43dd-bd40-eee9347da439
Llama.generate: 489 prefix-match hit, remaining 1204 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1204 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  139459.38 ms /  1204 tokens (  115.83 ms per token,     8.63 tokens per second)
llama_perf_context_print: prompt eval time =  139459.38 ms /  1204 tokens (  115.83 ms per token,     8.63 tokens per second)
llama_perf_context_print:        eval time =     258.06 ms /     1 runs   (  258.06 ms per token,     3.88 tokens per second)
llama_perf_context_print:        eval time =     258.06 ms /     1 runs   (  258.06 ms per token,     3.88 tokens per second)
llama_perf_context_print:       total time =  139791.93 ms /  1205 tokens
llama_perf_context_print:       total time =  139791.93 ms /  1205 tokens
INFO 05/03/2025 10:03:03 PM UTC E-mail parsing finished: f36469b8-35ad-43dd-bd40-eee9347da439
INFO 05/03/2025 10:03:03 PM UTC E-mail parsing finished: f36469b8-35ad-43dd-bd40-eee9347da439
INFO 05/03/2025 10:03:03 PM UTC New e-mail: ed2abddb-a318-4a25-ba5e-cc00dd1a3ca5
INFO 05/03/2025 10:03:03 PM UTC New e-mail: ed2abddb-a318-4a25-ba5e-cc00dd1a3ca5
Llama.generate: 489 prefix-match hit, remaining 1139 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1139 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time = 1324021.70 ms / 10822 tokens (  122.35 ms per token,     8.17 tokens per second)
llama_perf_context_print: prompt eval time = 1324021.70 ms / 10822 tokens (  122.35 ms per token,     8.17 tokens per second)
llama_perf_context_print:        eval time =     408.87 ms /     1 runs   (  408.87 ms per token,     2.45 tokens per second)
llama_perf_context_print:        eval time =     408.87 ms /     1 runs   (  408.87 ms per token,     2.45 tokens per second)
llama_perf_context_print:       total time = 1324465.28 ms / 10823 tokens
llama_perf_context_print:       total time = 1324465.28 ms / 10823 tokens
INFO 05/03/2025 10:05:17 PM UTC E-mail parsing finished: dd254699-18b4-4ed3-a355-c5361d961f45
INFO 05/03/2025 10:05:17 PM UTC E-mail parsing finished: dd254699-18b4-4ed3-a355-c5361d961f45
INFO 05/03/2025 10:05:17 PM UTC New e-mail: b2b7aa56-f95c-40ab-9c27-f8b96ecbea35
INFO 05/03/2025 10:05:17 PM UTC New e-mail: b2b7aa56-f95c-40ab-9c27-f8b96ecbea35
Llama.generate: 489 prefix-match hit, remaining 1139 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1139 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  136953.63 ms /  1139 tokens (  120.24 ms per token,     8.32 tokens per second)
llama_perf_context_print: prompt eval time =  136953.63 ms /  1139 tokens (  120.24 ms per token,     8.32 tokens per second)
llama_perf_context_print:        eval time =     297.30 ms /     1 runs   (  297.30 ms per token,     3.36 tokens per second)
llama_perf_context_print:        eval time =     297.30 ms /     1 runs   (  297.30 ms per token,     3.36 tokens per second)
llama_perf_context_print:       total time =  137299.93 ms /  1140 tokens
llama_perf_context_print:       total time =  137299.93 ms /  1140 tokens
INFO 05/03/2025 10:05:20 PM UTC E-mail parsing finished: ed2abddb-a318-4a25-ba5e-cc00dd1a3ca5
INFO 05/03/2025 10:05:20 PM UTC E-mail parsing finished: ed2abddb-a318-4a25-ba5e-cc00dd1a3ca5
INFO 05/03/2025 10:05:20 PM UTC New e-mail: 01a70e99-cc01-4e18-92ac-fb7af1ed2816
INFO 05/03/2025 10:05:20 PM UTC New e-mail: 01a70e99-cc01-4e18-92ac-fb7af1ed2816
Llama.generate: 489 prefix-match hit, remaining 1078 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1078 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  133132.96 ms /  1078 tokens (  123.50 ms per token,     8.10 tokens per second)
llama_perf_context_print: prompt eval time =  133132.96 ms /  1078 tokens (  123.50 ms per token,     8.10 tokens per second)
llama_perf_context_print:        eval time =     306.52 ms /     1 runs   (  306.52 ms per token,     3.26 tokens per second)
llama_perf_context_print:        eval time =     306.52 ms /     1 runs   (  306.52 ms per token,     3.26 tokens per second)
llama_perf_context_print:       total time =  133484.21 ms /  1079 tokens
llama_perf_context_print:       total time =  133484.21 ms /  1079 tokens
INFO 05/03/2025 10:07:33 PM UTC E-mail parsing finished: 01a70e99-cc01-4e18-92ac-fb7af1ed2816
INFO 05/03/2025 10:07:33 PM UTC E-mail parsing finished: 01a70e99-cc01-4e18-92ac-fb7af1ed2816
INFO 05/03/2025 10:07:33 PM UTC New e-mail: a7c2ec2d-34b9-48ab-a595-1a29afe85384
INFO 05/03/2025 10:07:33 PM UTC New e-mail: a7c2ec2d-34b9-48ab-a595-1a29afe85384
Llama.generate: 489 prefix-match hit, remaining 768 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 768 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  147235.46 ms /  1139 tokens (  129.27 ms per token,     7.74 tokens per second)
llama_perf_context_print: prompt eval time =  147235.46 ms /  1139 tokens (  129.27 ms per token,     7.74 tokens per second)
llama_perf_context_print:        eval time =     246.81 ms /     1 runs   (  246.81 ms per token,     4.05 tokens per second)
llama_perf_context_print:        eval time =     246.81 ms /     1 runs   (  246.81 ms per token,     4.05 tokens per second)
llama_perf_context_print:       total time =  147559.86 ms /  1140 tokens
llama_perf_context_print:       total time =  147559.86 ms /  1140 tokens
INFO 05/03/2025 10:07:45 PM UTC E-mail parsing finished: b2b7aa56-f95c-40ab-9c27-f8b96ecbea35
INFO 05/03/2025 10:07:45 PM UTC E-mail parsing finished: b2b7aa56-f95c-40ab-9c27-f8b96ecbea35
INFO 05/03/2025 10:07:45 PM UTC New e-mail: 3a270b7a-fda8-47fe-8ba0-c08959f483d2
INFO 05/03/2025 10:07:45 PM UTC New e-mail: 3a270b7a-fda8-47fe-8ba0-c08959f483d2
Llama.generate: 520 prefix-match hit, remaining 615 prompt tokens to eval
Llama.generate: 520 prefix-match hit, remaining 615 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   88072.26 ms /   768 tokens (  114.68 ms per token,     8.72 tokens per second)
llama_perf_context_print: prompt eval time =   88072.26 ms /   768 tokens (  114.68 ms per token,     8.72 tokens per second)
llama_perf_context_print:        eval time =     247.37 ms /     1 runs   (  247.37 ms per token,     4.04 tokens per second)
llama_perf_context_print:        eval time =     247.37 ms /     1 runs   (  247.37 ms per token,     4.04 tokens per second)
llama_perf_context_print:       total time =   88406.67 ms /   769 tokens
llama_perf_context_print:       total time =   88406.67 ms /   769 tokens
INFO 05/03/2025 10:09:02 PM UTC E-mail parsing finished: a7c2ec2d-34b9-48ab-a595-1a29afe85384
INFO 05/03/2025 10:09:02 PM UTC E-mail parsing finished: a7c2ec2d-34b9-48ab-a595-1a29afe85384
INFO 05/03/2025 10:09:02 PM UTC New e-mail: 6fe209be-310b-41e3-97a2-b00ae1ca6161
INFO 05/03/2025 10:09:02 PM UTC New e-mail: 6fe209be-310b-41e3-97a2-b00ae1ca6161
Llama.generate: 489 prefix-match hit, remaining 585 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 585 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   96156.88 ms /   615 tokens (  156.35 ms per token,     6.40 tokens per second)
llama_perf_context_print: prompt eval time =   96156.88 ms /   615 tokens (  156.35 ms per token,     6.40 tokens per second)
llama_perf_context_print:        eval time =     222.10 ms /     1 runs   (  222.10 ms per token,     4.50 tokens per second)
llama_perf_context_print:        eval time =     222.10 ms /     1 runs   (  222.10 ms per token,     4.50 tokens per second)
llama_perf_context_print:       total time =   96441.77 ms /   616 tokens
llama_perf_context_print:       total time =   96441.77 ms /   616 tokens
INFO 05/03/2025 10:09:21 PM UTC E-mail parsing finished: 3a270b7a-fda8-47fe-8ba0-c08959f483d2
INFO 05/03/2025 10:09:21 PM UTC E-mail parsing finished: 3a270b7a-fda8-47fe-8ba0-c08959f483d2
INFO 05/03/2025 10:09:21 PM UTC New e-mail: b1ba1cbb-683b-4cd0-82f9-fcff3b4bb37f
INFO 05/03/2025 10:09:21 PM UTC New e-mail: b1ba1cbb-683b-4cd0-82f9-fcff3b4bb37f
Llama.generate: 499 prefix-match hit, remaining 29 prompt tokens to eval
Llama.generate: 499 prefix-match hit, remaining 29 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =    8869.01 ms /    29 tokens (  305.83 ms per token,     3.27 tokens per second)
llama_perf_context_print: prompt eval time =    8869.01 ms /    29 tokens (  305.83 ms per token,     3.27 tokens per second)
llama_perf_context_print:        eval time =     250.76 ms /     1 runs   (  250.76 ms per token,     3.99 tokens per second)
llama_perf_context_print:        eval time =     250.76 ms /     1 runs   (  250.76 ms per token,     3.99 tokens per second)
llama_perf_context_print:       total time =    9158.21 ms /    30 tokens
llama_perf_context_print:       total time =    9158.21 ms /    30 tokens
INFO 05/03/2025 10:09:30 PM UTC E-mail parsing finished: b1ba1cbb-683b-4cd0-82f9-fcff3b4bb37f
INFO 05/03/2025 10:09:30 PM UTC E-mail parsing finished: b1ba1cbb-683b-4cd0-82f9-fcff3b4bb37f
INFO 05/03/2025 10:09:30 PM UTC New e-mail: 2fbe04ac-8cd0-4a11-9389-cee62bb32a83
INFO 05/03/2025 10:09:30 PM UTC New e-mail: 2fbe04ac-8cd0-4a11-9389-cee62bb32a83
Llama.generate: 489 prefix-match hit, remaining 298 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 298 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   49194.67 ms /   298 tokens (  165.08 ms per token,     6.06 tokens per second)
llama_perf_context_print: prompt eval time =   49194.67 ms /   298 tokens (  165.08 ms per token,     6.06 tokens per second)
llama_perf_context_print:        eval time =     184.44 ms /     1 runs   (  184.44 ms per token,     5.42 tokens per second)
llama_perf_context_print:        eval time =     184.44 ms /     1 runs   (  184.44 ms per token,     5.42 tokens per second)
llama_perf_context_print:       total time =   49419.82 ms /   299 tokens
llama_perf_context_print:       total time =   49419.82 ms /   299 tokens
INFO 05/03/2025 10:10:20 PM UTC E-mail parsing finished: 2fbe04ac-8cd0-4a11-9389-cee62bb32a83
INFO 05/03/2025 10:10:20 PM UTC E-mail parsing finished: 2fbe04ac-8cd0-4a11-9389-cee62bb32a83
INFO 05/03/2025 10:10:20 PM UTC New e-mail: 8e1e016b-a1ca-477d-bb75-531e04e8495b
INFO 05/03/2025 10:10:20 PM UTC New e-mail: 8e1e016b-a1ca-477d-bb75-531e04e8495b
Llama.generate: 489 prefix-match hit, remaining 384 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 384 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   84560.18 ms /   585 tokens (  144.55 ms per token,     6.92 tokens per second)
llama_perf_context_print: prompt eval time =   84560.18 ms /   585 tokens (  144.55 ms per token,     6.92 tokens per second)
llama_perf_context_print:        eval time =     299.36 ms /     1 runs   (  299.36 ms per token,     3.34 tokens per second)
llama_perf_context_print:        eval time =     299.36 ms /     1 runs   (  299.36 ms per token,     3.34 tokens per second)
llama_perf_context_print:       total time =   84952.59 ms /   586 tokens
llama_perf_context_print:       total time =   84952.59 ms /   586 tokens
INFO 05/03/2025 10:10:27 PM UTC E-mail parsing finished: 6fe209be-310b-41e3-97a2-b00ae1ca6161
INFO 05/03/2025 10:10:27 PM UTC E-mail parsing finished: 6fe209be-310b-41e3-97a2-b00ae1ca6161
INFO 05/03/2025 10:10:27 PM UTC New e-mail: 9c951844-4951-4051-9942-889dce58fa14
INFO 05/03/2025 10:10:27 PM UTC New e-mail: 9c951844-4951-4051-9942-889dce58fa14
Llama.generate: 538 prefix-match hit, remaining 424 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 424 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   46495.93 ms /   384 tokens (  121.08 ms per token,     8.26 tokens per second)
llama_perf_context_print: prompt eval time =   46495.93 ms /   384 tokens (  121.08 ms per token,     8.26 tokens per second)
llama_perf_context_print:        eval time =   15807.06 ms /    84 runs   (  188.18 ms per token,     5.31 tokens per second)
llama_perf_context_print:        eval time =   15807.06 ms /    84 runs   (  188.18 ms per token,     5.31 tokens per second)
llama_perf_context_print:       total time =   64297.08 ms /   468 tokens
llama_perf_context_print:       total time =   64297.08 ms /   468 tokens
INFO 05/03/2025 10:11:24 PM UTC E-mail parsing finished: 8e1e016b-a1ca-477d-bb75-531e04e8495b
INFO 05/03/2025 10:11:24 PM UTC E-mail parsing finished: 8e1e016b-a1ca-477d-bb75-531e04e8495b
INFO 05/03/2025 10:11:24 PM UTC New e-mail: 9778a5b1-d875-4d52-bebd-9f43dc7b4856
INFO 05/03/2025 10:11:24 PM UTC New e-mail: 9778a5b1-d875-4d52-bebd-9f43dc7b4856
Llama.generate: 489 prefix-match hit, remaining 184 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 184 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   48077.28 ms /   424 tokens (  113.39 ms per token,     8.82 tokens per second)
llama_perf_context_print: prompt eval time =   48077.28 ms /   424 tokens (  113.39 ms per token,     8.82 tokens per second)
llama_perf_context_print:        eval time =   16950.23 ms /    82 runs   (  206.71 ms per token,     4.84 tokens per second)
llama_perf_context_print:        eval time =   16950.23 ms /    82 runs   (  206.71 ms per token,     4.84 tokens per second)
llama_perf_context_print:       total time =   66992.37 ms /   506 tokens
llama_perf_context_print:       total time =   66992.37 ms /   506 tokens
INFO 05/03/2025 10:11:34 PM UTC E-mail parsing finished: 9c951844-4951-4051-9942-889dce58fa14
INFO 05/03/2025 10:11:34 PM UTC E-mail parsing finished: 9c951844-4951-4051-9942-889dce58fa14
INFO 05/03/2025 10:11:34 PM UTC New e-mail: 69687791-3eb9-4cee-be51-4baa19499547
INFO 05/03/2025 10:11:34 PM UTC New e-mail: 69687791-3eb9-4cee-be51-4baa19499547
Llama.generate: 489 prefix-match hit, remaining 287 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 287 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   49057.97 ms /   184 tokens (  266.62 ms per token,     3.75 tokens per second)
llama_perf_context_print: prompt eval time =   49057.97 ms /   184 tokens (  266.62 ms per token,     3.75 tokens per second)
llama_perf_context_print:        eval time =     222.65 ms /     1 runs   (  222.65 ms per token,     4.49 tokens per second)
llama_perf_context_print:        eval time =     222.65 ms /     1 runs   (  222.65 ms per token,     4.49 tokens per second)
llama_perf_context_print:       total time =   49327.66 ms /   185 tokens
llama_perf_context_print:       total time =   49327.66 ms /   185 tokens
INFO 05/03/2025 10:12:13 PM UTC E-mail parsing finished: 9778a5b1-d875-4d52-bebd-9f43dc7b4856
INFO 05/03/2025 10:12:13 PM UTC E-mail parsing finished: 9778a5b1-d875-4d52-bebd-9f43dc7b4856
INFO 05/03/2025 10:12:13 PM UTC New e-mail: 53fe0a66-9765-4bc5-91e0-2d94914801be
INFO 05/03/2025 10:12:13 PM UTC New e-mail: 53fe0a66-9765-4bc5-91e0-2d94914801be
Llama.generate: 489 prefix-match hit, remaining 166 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 166 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   44844.39 ms /   287 tokens (  156.25 ms per token,     6.40 tokens per second)
llama_perf_context_print: prompt eval time =   44844.39 ms /   287 tokens (  156.25 ms per token,     6.40 tokens per second)
llama_perf_context_print:        eval time =   31422.31 ms /   119 runs   (  264.05 ms per token,     3.79 tokens per second)
llama_perf_context_print:        eval time =   31422.31 ms /   119 runs   (  264.05 ms per token,     3.79 tokens per second)
llama_perf_context_print:       total time =   78779.38 ms /   406 tokens
llama_perf_context_print:       total time =   78779.38 ms /   406 tokens
INFO 05/03/2025 10:12:53 PM UTC E-mail parsing finished: 69687791-3eb9-4cee-be51-4baa19499547
INFO 05/03/2025 10:12:53 PM UTC E-mail parsing finished: 69687791-3eb9-4cee-be51-4baa19499547
WARNING 05/03/2025 10:12:53 PM UTC Events from an email rejected due to data validation errors
WARNING 05/03/2025 10:12:53 PM UTC Events from an email rejected due to data validation errors
Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 151, in _on_new_events
  File "/app/modules/validator.py", line 151, in _on_new_events
    data: NewEvents = NewEvents.model_validate_json(body)
    data: NewEvents = NewEvents.model_validate_json(body)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 2 validation errors for NewEvents
pydantic_core._pydantic_core.ValidationError: 2 validation errors for NewEvents
events.0.start_date
events.0.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
events.1.start_date
events.1.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
INFO 05/03/2025 10:12:53 PM UTC New e-mail: d8cc72f2-ee04-4260-af1c-cf5bbfdc8c23
INFO 05/03/2025 10:12:53 PM UTC New e-mail: d8cc72f2-ee04-4260-af1c-cf5bbfdc8c23
Llama.generate: 489 prefix-match hit, remaining 502 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 502 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   62353.52 ms /   166 tokens (  375.62 ms per token,     2.66 tokens per second)
llama_perf_context_print: prompt eval time =   62353.52 ms /   166 tokens (  375.62 ms per token,     2.66 tokens per second)
llama_perf_context_print:        eval time =     245.52 ms /     1 runs   (  245.52 ms per token,     4.07 tokens per second)
llama_perf_context_print:        eval time =     245.52 ms /     1 runs   (  245.52 ms per token,     4.07 tokens per second)
llama_perf_context_print:       total time =   62674.35 ms /   167 tokens
llama_perf_context_print:       total time =   62674.35 ms /   167 tokens
INFO 05/03/2025 10:13:16 PM UTC E-mail parsing finished: 53fe0a66-9765-4bc5-91e0-2d94914801be
INFO 05/03/2025 10:13:16 PM UTC E-mail parsing finished: 53fe0a66-9765-4bc5-91e0-2d94914801be
INFO 05/03/2025 10:13:16 PM UTC New e-mail: 92bc7344-c13b-43b2-95db-84faa96f2d2d
INFO 05/03/2025 10:13:16 PM UTC New e-mail: 92bc7344-c13b-43b2-95db-84faa96f2d2d
Llama.generate: 492 prefix-match hit, remaining 1322 prompt tokens to eval
Llama.generate: 492 prefix-match hit, remaining 1322 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   49949.91 ms /   502 tokens (   99.50 ms per token,    10.05 tokens per second)
llama_perf_context_print: prompt eval time =   49949.91 ms /   502 tokens (   99.50 ms per token,    10.05 tokens per second)
llama_perf_context_print:        eval time =   34578.81 ms /   131 runs   (  263.96 ms per token,     3.79 tokens per second)
llama_perf_context_print:        eval time =   34578.81 ms /   131 runs   (  263.96 ms per token,     3.79 tokens per second)
llama_perf_context_print:       total time =   87266.95 ms /   633 tokens
llama_perf_context_print:       total time =   87266.95 ms /   633 tokens
INFO 05/03/2025 10:14:20 PM UTC E-mail parsing finished: d8cc72f2-ee04-4260-af1c-cf5bbfdc8c23
INFO 05/03/2025 10:14:20 PM UTC E-mail parsing finished: d8cc72f2-ee04-4260-af1c-cf5bbfdc8c23
INFO 05/03/2025 10:14:20 PM UTC New e-mail: 7479cadd-0173-457e-8840-d5961b433033
INFO 05/03/2025 10:14:20 PM UTC New e-mail: 7479cadd-0173-457e-8840-d5961b433033
Llama.generate: 538 prefix-match hit, remaining 281 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 281 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   45459.44 ms /   281 tokens (  161.78 ms per token,     6.18 tokens per second)
llama_perf_context_print: prompt eval time =   45459.44 ms /   281 tokens (  161.78 ms per token,     6.18 tokens per second)
llama_perf_context_print:        eval time =   19603.53 ms /    79 runs   (  248.15 ms per token,     4.03 tokens per second)
llama_perf_context_print:        eval time =   19603.53 ms /    79 runs   (  248.15 ms per token,     4.03 tokens per second)
llama_perf_context_print:       total time =   66757.13 ms /   360 tokens
llama_perf_context_print:       total time =   66757.13 ms /   360 tokens
INFO 05/03/2025 10:15:27 PM UTC E-mail parsing finished: 7479cadd-0173-457e-8840-d5961b433033
INFO 05/03/2025 10:15:27 PM UTC E-mail parsing finished: 7479cadd-0173-457e-8840-d5961b433033
INFO 05/03/2025 10:15:27 PM UTC New e-mail: dc3b8e24-8704-4733-839d-30f1d18a0e0d
INFO 05/03/2025 10:15:27 PM UTC New e-mail: dc3b8e24-8704-4733-839d-30f1d18a0e0d
Llama.generate: 489 prefix-match hit, remaining 510 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 510 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  179612.88 ms /  1322 tokens (  135.86 ms per token,     7.36 tokens per second)
llama_perf_context_print: prompt eval time =  179612.88 ms /  1322 tokens (  135.86 ms per token,     7.36 tokens per second)
llama_perf_context_print:        eval time =     230.25 ms /     1 runs   (  230.25 ms per token,     4.34 tokens per second)
llama_perf_context_print:        eval time =     230.25 ms /     1 runs   (  230.25 ms per token,     4.34 tokens per second)
llama_perf_context_print:       total time =  179892.64 ms /  1323 tokens
llama_perf_context_print:       total time =  179892.64 ms /  1323 tokens
INFO 05/03/2025 10:16:16 PM UTC E-mail parsing finished: 92bc7344-c13b-43b2-95db-84faa96f2d2d
INFO 05/03/2025 10:16:16 PM UTC E-mail parsing finished: 92bc7344-c13b-43b2-95db-84faa96f2d2d
INFO 05/03/2025 10:16:16 PM UTC New e-mail: 3f26c40d-0e65-4635-9735-f2a49985a202
INFO 05/03/2025 10:16:16 PM UTC New e-mail: 3f26c40d-0e65-4635-9735-f2a49985a202
Llama.generate: 489 prefix-match hit, remaining 187 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 187 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   49588.78 ms /   510 tokens (   97.23 ms per token,    10.28 tokens per second)
llama_perf_context_print: prompt eval time =   49588.78 ms /   510 tokens (   97.23 ms per token,    10.28 tokens per second)
llama_perf_context_print:        eval time =   62521.57 ms /   247 runs   (  253.12 ms per token,     3.95 tokens per second)
llama_perf_context_print:        eval time =   62521.57 ms /   247 runs   (  253.12 ms per token,     3.95 tokens per second)
llama_perf_context_print:       total time =  117956.95 ms /   757 tokens
llama_perf_context_print:       total time =  117956.95 ms /   757 tokens
INFO 05/03/2025 10:17:25 PM UTC E-mail parsing finished: dc3b8e24-8704-4733-839d-30f1d18a0e0d
INFO 05/03/2025 10:17:25 PM UTC E-mail parsing finished: dc3b8e24-8704-4733-839d-30f1d18a0e0d
INFO 05/03/2025 10:17:25 PM UTC New e-mail: b970b0c0-9aad-4123-928d-f383faecc0d1
INFO 05/03/2025 10:17:25 PM UTC New e-mail: b970b0c0-9aad-4123-928d-f383faecc0d1
Llama.generate: 489 prefix-match hit, remaining 336 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 336 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   76545.92 ms /   187 tokens (  409.34 ms per token,     2.44 tokens per second)
llama_perf_context_print: prompt eval time =   76545.92 ms /   187 tokens (  409.34 ms per token,     2.44 tokens per second)
llama_perf_context_print:        eval time =     216.50 ms /     1 runs   (  216.50 ms per token,     4.62 tokens per second)
llama_perf_context_print:        eval time =     216.50 ms /     1 runs   (  216.50 ms per token,     4.62 tokens per second)
llama_perf_context_print:       total time =   76846.91 ms /   188 tokens
llama_perf_context_print:       total time =   76846.91 ms /   188 tokens
INFO 05/03/2025 10:17:33 PM UTC E-mail parsing finished: 3f26c40d-0e65-4635-9735-f2a49985a202
INFO 05/03/2025 10:17:33 PM UTC E-mail parsing finished: 3f26c40d-0e65-4635-9735-f2a49985a202
INFO 05/03/2025 10:17:33 PM UTC New e-mail: bb2f538c-1eb7-466b-b4c6-fc91f7fa3fdd
INFO 05/03/2025 10:17:33 PM UTC New e-mail: bb2f538c-1eb7-466b-b4c6-fc91f7fa3fdd
Llama.generate: 489 prefix-match hit, remaining 676 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 676 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   50014.33 ms /   336 tokens (  148.85 ms per token,     6.72 tokens per second)
llama_perf_context_print: prompt eval time =   50014.33 ms /   336 tokens (  148.85 ms per token,     6.72 tokens per second)
llama_perf_context_print:        eval time =   21848.55 ms /    86 runs   (  254.05 ms per token,     3.94 tokens per second)
llama_perf_context_print:        eval time =   21848.55 ms /    86 runs   (  254.05 ms per token,     3.94 tokens per second)
llama_perf_context_print:       total time =   73790.52 ms /   422 tokens
llama_perf_context_print:       total time =   73790.52 ms /   422 tokens
INFO 05/03/2025 10:18:38 PM UTC E-mail parsing finished: b970b0c0-9aad-4123-928d-f383faecc0d1
INFO 05/03/2025 10:18:38 PM UTC E-mail parsing finished: b970b0c0-9aad-4123-928d-f383faecc0d1
INFO 05/03/2025 10:18:38 PM UTC New e-mail: 64439e13-c99f-428d-8f3f-8c1208ac2319
INFO 05/03/2025 10:18:38 PM UTC New e-mail: 64439e13-c99f-428d-8f3f-8c1208ac2319
Llama.generate: 489 prefix-match hit, remaining 673 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 673 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  107043.30 ms /   676 tokens (  158.35 ms per token,     6.32 tokens per second)
llama_perf_context_print: prompt eval time =  107043.30 ms /   676 tokens (  158.35 ms per token,     6.32 tokens per second)
llama_perf_context_print:        eval time =   16278.36 ms /    69 runs   (  235.92 ms per token,     4.24 tokens per second)
llama_perf_context_print:        eval time =   16278.36 ms /    69 runs   (  235.92 ms per token,     4.24 tokens per second)
llama_perf_context_print:       total time =  124762.44 ms /   745 tokens
llama_perf_context_print:       total time =  124762.44 ms /   745 tokens
INFO 05/03/2025 10:19:38 PM UTC E-mail parsing finished: bb2f538c-1eb7-466b-b4c6-fc91f7fa3fdd
INFO 05/03/2025 10:19:38 PM UTC E-mail parsing finished: bb2f538c-1eb7-466b-b4c6-fc91f7fa3fdd
INFO 05/03/2025 10:19:38 PM UTC New e-mail: 8755dda0-c67d-476a-bf71-de75634231c9
INFO 05/03/2025 10:19:38 PM UTC New e-mail: 8755dda0-c67d-476a-bf71-de75634231c9
Llama.generate: 489 prefix-match hit, remaining 491 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 491 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  101026.96 ms /   673 tokens (  150.11 ms per token,     6.66 tokens per second)
llama_perf_context_print: prompt eval time =  101026.96 ms /   673 tokens (  150.11 ms per token,     6.66 tokens per second)
llama_perf_context_print:        eval time =   24051.10 ms /   100 runs   (  240.51 ms per token,     4.16 tokens per second)
llama_perf_context_print:        eval time =   24051.10 ms /   100 runs   (  240.51 ms per token,     4.16 tokens per second)
llama_perf_context_print:       total time =  127262.67 ms /   773 tokens
llama_perf_context_print:       total time =  127262.67 ms /   773 tokens
INFO 05/03/2025 10:20:46 PM UTC E-mail parsing finished: 64439e13-c99f-428d-8f3f-8c1208ac2319
INFO 05/03/2025 10:20:46 PM UTC E-mail parsing finished: 64439e13-c99f-428d-8f3f-8c1208ac2319
INFO 05/03/2025 10:20:46 PM UTC New e-mail: c644f0c3-a212-489a-b816-31a2c6fdb5f3
INFO 05/03/2025 10:20:46 PM UTC New e-mail: c644f0c3-a212-489a-b816-31a2c6fdb5f3
Llama.generate: 489 prefix-match hit, remaining 382 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 382 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   63498.06 ms /   491 tokens (  129.32 ms per token,     7.73 tokens per second)
llama_perf_context_print: prompt eval time =   63498.06 ms /   491 tokens (  129.32 ms per token,     7.73 tokens per second)
llama_perf_context_print:        eval time =    9816.49 ms /    50 runs   (  196.33 ms per token,     5.09 tokens per second)
llama_perf_context_print:        eval time =    9816.49 ms /    50 runs   (  196.33 ms per token,     5.09 tokens per second)
llama_perf_context_print:       total time =   74422.84 ms /   541 tokens
llama_perf_context_print:       total time =   74422.84 ms /   541 tokens
INFO 05/03/2025 10:20:52 PM UTC E-mail parsing finished: 8755dda0-c67d-476a-bf71-de75634231c9
INFO 05/03/2025 10:20:52 PM UTC E-mail parsing finished: 8755dda0-c67d-476a-bf71-de75634231c9
WARNING 05/03/2025 10:20:52 PM UTC Events from an email rejected due to data validation errors
WARNING 05/03/2025 10:20:52 PM UTC Events from an email rejected due to data validation errors
Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 151, in _on_new_events
  File "/app/modules/validator.py", line 151, in _on_new_events
    data: NewEvents = NewEvents.model_validate_json(body)
    data: NewEvents = NewEvents.model_validate_json(body)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
events.0.start_date
events.0.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
INFO 05/03/2025 10:20:52 PM UTC New e-mail: b7018a82-c4fe-45d0-95ad-023d368e5c03
INFO 05/03/2025 10:20:52 PM UTC New e-mail: b7018a82-c4fe-45d0-95ad-023d368e5c03
Llama.generate: 489 prefix-match hit, remaining 789 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 789 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   49550.56 ms /   382 tokens (  129.71 ms per token,     7.71 tokens per second)
llama_perf_context_print: prompt eval time =   49550.56 ms /   382 tokens (  129.71 ms per token,     7.71 tokens per second)
llama_perf_context_print:        eval time =     289.46 ms /     1 runs   (  289.46 ms per token,     3.45 tokens per second)
llama_perf_context_print:        eval time =     289.46 ms /     1 runs   (  289.46 ms per token,     3.45 tokens per second)
llama_perf_context_print:       total time =   49892.95 ms /   383 tokens
llama_perf_context_print:       total time =   49892.95 ms /   383 tokens
INFO 05/03/2025 10:21:36 PM UTC E-mail parsing finished: c644f0c3-a212-489a-b816-31a2c6fdb5f3
INFO 05/03/2025 10:21:36 PM UTC E-mail parsing finished: c644f0c3-a212-489a-b816-31a2c6fdb5f3
INFO 05/03/2025 10:21:36 PM UTC New e-mail: d79ad3e9-3285-4656-99cd-dee87b5ddf09
INFO 05/03/2025 10:21:36 PM UTC New e-mail: d79ad3e9-3285-4656-99cd-dee87b5ddf09
Llama.generate: 489 prefix-match hit, remaining 9406 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 9406 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   98322.01 ms /   789 tokens (  124.62 ms per token,     8.02 tokens per second)
llama_perf_context_print: prompt eval time =   98322.01 ms /   789 tokens (  124.62 ms per token,     8.02 tokens per second)
llama_perf_context_print:        eval time =   35062.65 ms /   156 runs   (  224.76 ms per token,     4.45 tokens per second)
llama_perf_context_print:        eval time =   35062.65 ms /   156 runs   (  224.76 ms per token,     4.45 tokens per second)
llama_perf_context_print:       total time =  136913.60 ms /   945 tokens
llama_perf_context_print:       total time =  136913.60 ms /   945 tokens
INFO 05/03/2025 10:23:09 PM UTC E-mail parsing finished: b7018a82-c4fe-45d0-95ad-023d368e5c03
INFO 05/03/2025 10:23:09 PM UTC E-mail parsing finished: b7018a82-c4fe-45d0-95ad-023d368e5c03
INFO 05/03/2025 10:23:09 PM UTC New e-mail: dd1793ef-6171-43f4-bf0a-4733e470665c
INFO 05/03/2025 10:23:09 PM UTC New e-mail: dd1793ef-6171-43f4-bf0a-4733e470665c
Llama.generate: 536 prefix-match hit, remaining 526 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 526 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   61203.09 ms /   526 tokens (  116.36 ms per token,     8.59 tokens per second)
llama_perf_context_print: prompt eval time =   61203.09 ms /   526 tokens (  116.36 ms per token,     8.59 tokens per second)
llama_perf_context_print:        eval time =     268.22 ms /     1 runs   (  268.22 ms per token,     3.73 tokens per second)
llama_perf_context_print:        eval time =     268.22 ms /     1 runs   (  268.22 ms per token,     3.73 tokens per second)
llama_perf_context_print:       total time =   61506.49 ms /   527 tokens
llama_perf_context_print:       total time =   61506.49 ms /   527 tokens
INFO 05/03/2025 10:24:11 PM UTC E-mail parsing finished: dd1793ef-6171-43f4-bf0a-4733e470665c
INFO 05/03/2025 10:24:11 PM UTC E-mail parsing finished: dd1793ef-6171-43f4-bf0a-4733e470665c
INFO 05/03/2025 10:24:11 PM UTC New e-mail: 83f8f7ca-8b05-4628-aff8-6b482c73d891
INFO 05/03/2025 10:24:11 PM UTC New e-mail: 83f8f7ca-8b05-4628-aff8-6b482c73d891
Llama.generate: 489 prefix-match hit, remaining 109 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 109 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   43176.22 ms /   109 tokens (  396.11 ms per token,     2.52 tokens per second)
llama_perf_context_print: prompt eval time =   43176.22 ms /   109 tokens (  396.11 ms per token,     2.52 tokens per second)
llama_perf_context_print:        eval time =   23368.89 ms /   105 runs   (  222.56 ms per token,     4.49 tokens per second)
llama_perf_context_print:        eval time =   23368.89 ms /   105 runs   (  222.56 ms per token,     4.49 tokens per second)
llama_perf_context_print:       total time =   69143.10 ms /   214 tokens
llama_perf_context_print:       total time =   69143.10 ms /   214 tokens
INFO 05/03/2025 10:25:20 PM UTC E-mail parsing finished: 83f8f7ca-8b05-4628-aff8-6b482c73d891
INFO 05/03/2025 10:25:20 PM UTC E-mail parsing finished: 83f8f7ca-8b05-4628-aff8-6b482c73d891
INFO 05/03/2025 10:25:20 PM UTC New e-mail: 94cd2fc5-8a1f-4c4e-947c-61a0eca15439
INFO 05/03/2025 10:25:20 PM UTC New e-mail: 94cd2fc5-8a1f-4c4e-947c-61a0eca15439
Llama.generate: 538 prefix-match hit, remaining 82 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 82 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   40933.69 ms /    82 tokens (  499.19 ms per token,     2.00 tokens per second)
llama_perf_context_print: prompt eval time =   40933.69 ms /    82 tokens (  499.19 ms per token,     2.00 tokens per second)
llama_perf_context_print:        eval time =     266.97 ms /     1 runs   (  266.97 ms per token,     3.75 tokens per second)
llama_perf_context_print:        eval time =     266.97 ms /     1 runs   (  266.97 ms per token,     3.75 tokens per second)
llama_perf_context_print:       total time =   41244.99 ms /    83 tokens
llama_perf_context_print:       total time =   41244.99 ms /    83 tokens
INFO 05/03/2025 10:26:01 PM UTC E-mail parsing finished: 94cd2fc5-8a1f-4c4e-947c-61a0eca15439
INFO 05/03/2025 10:26:01 PM UTC E-mail parsing finished: 94cd2fc5-8a1f-4c4e-947c-61a0eca15439
INFO 05/03/2025 10:26:01 PM UTC New e-mail: f58dd4a3-a55a-416b-adae-142930840d00
INFO 05/03/2025 10:26:01 PM UTC New e-mail: f58dd4a3-a55a-416b-adae-142930840d00
Llama.generate: 489 prefix-match hit, remaining 167 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 167 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   47651.10 ms /   167 tokens (  285.34 ms per token,     3.50 tokens per second)
llama_perf_context_print: prompt eval time =   47651.10 ms /   167 tokens (  285.34 ms per token,     3.50 tokens per second)
llama_perf_context_print:        eval time =   20873.52 ms /    93 runs   (  224.45 ms per token,     4.46 tokens per second)
llama_perf_context_print:        eval time =   20873.52 ms /    93 runs   (  224.45 ms per token,     4.46 tokens per second)
llama_perf_context_print:       total time =   70897.09 ms /   260 tokens
llama_perf_context_print:       total time =   70897.09 ms /   260 tokens
INFO 05/03/2025 10:27:12 PM UTC E-mail parsing finished: f58dd4a3-a55a-416b-adae-142930840d00
INFO 05/03/2025 10:27:12 PM UTC E-mail parsing finished: f58dd4a3-a55a-416b-adae-142930840d00
INFO 05/03/2025 10:27:12 PM UTC New e-mail: e4dbb4c8-f00f-4773-9d85-03531c86871c
INFO 05/03/2025 10:27:12 PM UTC New e-mail: e4dbb4c8-f00f-4773-9d85-03531c86871c
Llama.generate: 489 prefix-match hit, remaining 299 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 299 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   49138.29 ms /   299 tokens (  164.34 ms per token,     6.08 tokens per second)
llama_perf_context_print: prompt eval time =   49138.29 ms /   299 tokens (  164.34 ms per token,     6.08 tokens per second)
llama_perf_context_print:        eval time =     231.49 ms /     1 runs   (  231.49 ms per token,     4.32 tokens per second)
llama_perf_context_print:        eval time =     231.49 ms /     1 runs   (  231.49 ms per token,     4.32 tokens per second)
llama_perf_context_print:       total time =   49413.07 ms /   300 tokens
llama_perf_context_print:       total time =   49413.07 ms /   300 tokens
INFO 05/03/2025 10:28:01 PM UTC E-mail parsing finished: e4dbb4c8-f00f-4773-9d85-03531c86871c
INFO 05/03/2025 10:28:01 PM UTC E-mail parsing finished: e4dbb4c8-f00f-4773-9d85-03531c86871c
INFO 05/03/2025 10:28:01 PM UTC New e-mail: c703a27e-a4f1-44fb-b88e-1d29dd32f6df
INFO 05/03/2025 10:28:01 PM UTC New e-mail: c703a27e-a4f1-44fb-b88e-1d29dd32f6df
Llama.generate: 489 prefix-match hit, remaining 220 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 220 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   49414.60 ms /   220 tokens (  224.61 ms per token,     4.45 tokens per second)
llama_perf_context_print: prompt eval time =   49414.60 ms /   220 tokens (  224.61 ms per token,     4.45 tokens per second)
llama_perf_context_print:        eval time =   32502.67 ms /   145 runs   (  224.16 ms per token,     4.46 tokens per second)
llama_perf_context_print:        eval time =   32502.67 ms /   145 runs   (  224.16 ms per token,     4.46 tokens per second)
llama_perf_context_print:       total time =   85391.84 ms /   365 tokens
llama_perf_context_print:       total time =   85391.84 ms /   365 tokens
INFO 05/03/2025 10:29:27 PM UTC E-mail parsing finished: c703a27e-a4f1-44fb-b88e-1d29dd32f6df
INFO 05/03/2025 10:29:27 PM UTC E-mail parsing finished: c703a27e-a4f1-44fb-b88e-1d29dd32f6df
INFO 05/03/2025 10:29:27 PM UTC New e-mail: 6769df34-f390-42a5-a7c1-7a296ca14f93
INFO 05/03/2025 10:29:27 PM UTC New e-mail: 6769df34-f390-42a5-a7c1-7a296ca14f93
Llama.generate: 489 prefix-match hit, remaining 454 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 454 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   52104.05 ms /   454 tokens (  114.77 ms per token,     8.71 tokens per second)
llama_perf_context_print: prompt eval time =   52104.05 ms /   454 tokens (  114.77 ms per token,     8.71 tokens per second)
llama_perf_context_print:        eval time =   19472.73 ms /    84 runs   (  231.82 ms per token,     4.31 tokens per second)
llama_perf_context_print:        eval time =   19472.73 ms /    84 runs   (  231.82 ms per token,     4.31 tokens per second)
llama_perf_context_print:       total time =   73381.52 ms /   538 tokens
llama_perf_context_print:       total time =   73381.52 ms /   538 tokens
INFO 05/03/2025 10:30:40 PM UTC E-mail parsing finished: 6769df34-f390-42a5-a7c1-7a296ca14f93
INFO 05/03/2025 10:30:40 PM UTC E-mail parsing finished: 6769df34-f390-42a5-a7c1-7a296ca14f93
INFO 05/03/2025 10:30:40 PM UTC New e-mail: 31f3cea3-c30f-4223-a143-2b8639fe80e7
INFO 05/03/2025 10:30:40 PM UTC New e-mail: 31f3cea3-c30f-4223-a143-2b8639fe80e7
Llama.generate: 536 prefix-match hit, remaining 456 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 456 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   54559.93 ms /   456 tokens (  119.65 ms per token,     8.36 tokens per second)
llama_perf_context_print: prompt eval time =   54559.93 ms /   456 tokens (  119.65 ms per token,     8.36 tokens per second)
llama_perf_context_print:        eval time =   57619.98 ms /   246 runs   (  234.23 ms per token,     4.27 tokens per second)
llama_perf_context_print:        eval time =   57619.98 ms /   246 runs   (  234.23 ms per token,     4.27 tokens per second)
llama_perf_context_print:       total time =  117622.27 ms /   702 tokens
llama_perf_context_print:       total time =  117622.27 ms /   702 tokens
INFO 05/03/2025 10:32:38 PM UTC E-mail parsing finished: 31f3cea3-c30f-4223-a143-2b8639fe80e7
INFO 05/03/2025 10:32:38 PM UTC E-mail parsing finished: 31f3cea3-c30f-4223-a143-2b8639fe80e7
INFO 05/03/2025 10:32:38 PM UTC New e-mail: 9fd48877-8904-4551-88a5-5050c122859c
INFO 05/03/2025 10:32:38 PM UTC New e-mail: 9fd48877-8904-4551-88a5-5050c122859c
Llama.generate: 489 prefix-match hit, remaining 641 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 641 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   94463.48 ms /   641 tokens (  147.37 ms per token,     6.79 tokens per second)
llama_perf_context_print: prompt eval time =   94463.48 ms /   641 tokens (  147.37 ms per token,     6.79 tokens per second)
llama_perf_context_print:        eval time =   12354.80 ms /    54 runs   (  228.79 ms per token,     4.37 tokens per second)
llama_perf_context_print:        eval time =   12354.80 ms /    54 runs   (  228.79 ms per token,     4.37 tokens per second)
llama_perf_context_print:       total time =  107943.34 ms /   695 tokens
llama_perf_context_print:       total time =  107943.34 ms /   695 tokens
INFO 05/03/2025 10:34:26 PM UTC E-mail parsing finished: 9fd48877-8904-4551-88a5-5050c122859c
INFO 05/03/2025 10:34:26 PM UTC E-mail parsing finished: 9fd48877-8904-4551-88a5-5050c122859c
WARNING 05/03/2025 10:34:26 PM UTC Events from an email rejected due to data validation errors
WARNING 05/03/2025 10:34:26 PM UTC Events from an email rejected due to data validation errors
Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 151, in _on_new_events
  File "/app/modules/validator.py", line 151, in _on_new_events
    data: NewEvents = NewEvents.model_validate_json(body)
    data: NewEvents = NewEvents.model_validate_json(body)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
events.0.start_date
events.0.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
INFO 05/03/2025 10:34:26 PM UTC New e-mail: ed10179c-fb82-4fe2-a1b6-4479eed15024
INFO 05/03/2025 10:34:26 PM UTC New e-mail: ed10179c-fb82-4fe2-a1b6-4479eed15024
Llama.generate: 489 prefix-match hit, remaining 528 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 528 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   62253.28 ms /   528 tokens (  117.90 ms per token,     8.48 tokens per second)
llama_perf_context_print: prompt eval time =   62253.28 ms /   528 tokens (  117.90 ms per token,     8.48 tokens per second)
llama_perf_context_print:        eval time =   10807.56 ms /    50 runs   (  216.15 ms per token,     4.63 tokens per second)
llama_perf_context_print:        eval time =   10807.56 ms /    50 runs   (  216.15 ms per token,     4.63 tokens per second)
llama_perf_context_print:       total time =   74165.51 ms /   578 tokens
llama_perf_context_print:       total time =   74165.51 ms /   578 tokens
INFO 05/03/2025 10:35:40 PM UTC E-mail parsing finished: ed10179c-fb82-4fe2-a1b6-4479eed15024
INFO 05/03/2025 10:35:40 PM UTC E-mail parsing finished: ed10179c-fb82-4fe2-a1b6-4479eed15024
WARNING 05/03/2025 10:35:40 PM UTC Events from an email rejected due to data validation errors
WARNING 05/03/2025 10:35:40 PM UTC Events from an email rejected due to data validation errors
Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 151, in _on_new_events
  File "/app/modules/validator.py", line 151, in _on_new_events
    data: NewEvents = NewEvents.model_validate_json(body)
    data: NewEvents = NewEvents.model_validate_json(body)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
events.0.start_date
events.0.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
INFO 05/03/2025 10:35:40 PM UTC New e-mail: 96adb3fe-51aa-4d05-88ba-b8096605d2a5
INFO 05/03/2025 10:35:40 PM UTC New e-mail: 96adb3fe-51aa-4d05-88ba-b8096605d2a5
Llama.generate: 542 prefix-match hit, remaining 347 prompt tokens to eval
Llama.generate: 542 prefix-match hit, remaining 347 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   53181.62 ms /   347 tokens (  153.26 ms per token,     6.52 tokens per second)
llama_perf_context_print: prompt eval time =   53181.62 ms /   347 tokens (  153.26 ms per token,     6.52 tokens per second)
llama_perf_context_print:        eval time =     187.39 ms /     1 runs   (  187.39 ms per token,     5.34 tokens per second)
llama_perf_context_print:        eval time =     187.39 ms /     1 runs   (  187.39 ms per token,     5.34 tokens per second)
llama_perf_context_print:       total time =   53458.30 ms /   348 tokens
llama_perf_context_print:       total time =   53458.30 ms /   348 tokens
INFO 05/03/2025 10:36:33 PM UTC E-mail parsing finished: 96adb3fe-51aa-4d05-88ba-b8096605d2a5
INFO 05/03/2025 10:36:33 PM UTC E-mail parsing finished: 96adb3fe-51aa-4d05-88ba-b8096605d2a5
INFO 05/03/2025 10:36:33 PM UTC New e-mail: f9f63b51-d4f8-4226-922f-12b30b6ceff9
INFO 05/03/2025 10:36:33 PM UTC New e-mail: f9f63b51-d4f8-4226-922f-12b30b6ceff9
Llama.generate: 489 prefix-match hit, remaining 257 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 257 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   44261.59 ms /   257 tokens (  172.22 ms per token,     5.81 tokens per second)
llama_perf_context_print: prompt eval time =   44261.59 ms /   257 tokens (  172.22 ms per token,     5.81 tokens per second)
llama_perf_context_print:        eval time =   13188.27 ms /    58 runs   (  227.38 ms per token,     4.40 tokens per second)
llama_perf_context_print:        eval time =   13188.27 ms /    58 runs   (  227.38 ms per token,     4.40 tokens per second)
llama_perf_context_print:       total time =   58629.98 ms /   315 tokens
llama_perf_context_print:       total time =   58629.98 ms /   315 tokens
INFO 05/03/2025 10:37:32 PM UTC E-mail parsing finished: f9f63b51-d4f8-4226-922f-12b30b6ceff9
INFO 05/03/2025 10:37:32 PM UTC E-mail parsing finished: f9f63b51-d4f8-4226-922f-12b30b6ceff9
WARNING 05/03/2025 10:37:32 PM UTC Events from an email rejected due to data validation errors
WARNING 05/03/2025 10:37:32 PM UTC Events from an email rejected due to data validation errors
Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 151, in _on_new_events
  File "/app/modules/validator.py", line 151, in _on_new_events
    data: NewEvents = NewEvents.model_validate_json(body)
    data: NewEvents = NewEvents.model_validate_json(body)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
events.0.start_date
events.0.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
INFO 05/03/2025 10:37:32 PM UTC New e-mail: c796b742-d626-4c9e-8b0e-36120a928845
INFO 05/03/2025 10:37:32 PM UTC New e-mail: c796b742-d626-4c9e-8b0e-36120a928845
Llama.generate: 489 prefix-match hit, remaining 139 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 139 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   43637.99 ms /   139 tokens (  313.94 ms per token,     3.19 tokens per second)
llama_perf_context_print: prompt eval time =   43637.99 ms /   139 tokens (  313.94 ms per token,     3.19 tokens per second)
llama_perf_context_print:        eval time =     223.65 ms /     1 runs   (  223.65 ms per token,     4.47 tokens per second)
llama_perf_context_print:        eval time =     223.65 ms /     1 runs   (  223.65 ms per token,     4.47 tokens per second)
llama_perf_context_print:       total time =   43926.39 ms /   140 tokens
llama_perf_context_print:       total time =   43926.39 ms /   140 tokens
INFO 05/03/2025 10:38:16 PM UTC E-mail parsing finished: c796b742-d626-4c9e-8b0e-36120a928845
INFO 05/03/2025 10:38:16 PM UTC E-mail parsing finished: c796b742-d626-4c9e-8b0e-36120a928845
INFO 05/03/2025 10:38:16 PM UTC New e-mail: bfaae58b-6ba4-4785-be62-69983bfc3a70
INFO 05/03/2025 10:38:16 PM UTC New e-mail: bfaae58b-6ba4-4785-be62-69983bfc3a70
Llama.generate: 489 prefix-match hit, remaining 553 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 553 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   91092.25 ms /   553 tokens (  164.72 ms per token,     6.07 tokens per second)
llama_perf_context_print: prompt eval time =   91092.25 ms /   553 tokens (  164.72 ms per token,     6.07 tokens per second)
llama_perf_context_print:        eval time =   21499.21 ms /    89 runs   (  241.56 ms per token,     4.14 tokens per second)
llama_perf_context_print:        eval time =   21499.21 ms /    89 runs   (  241.56 ms per token,     4.14 tokens per second)
llama_perf_context_print:       total time =  114425.44 ms /   642 tokens
llama_perf_context_print:       total time =  114425.44 ms /   642 tokens
INFO 05/03/2025 10:40:10 PM UTC E-mail parsing finished: bfaae58b-6ba4-4785-be62-69983bfc3a70
INFO 05/03/2025 10:40:10 PM UTC E-mail parsing finished: bfaae58b-6ba4-4785-be62-69983bfc3a70
INFO 05/03/2025 10:40:10 PM UTC New e-mail: bce89be2-af48-492e-82e6-177af622ccf1
INFO 05/03/2025 10:40:10 PM UTC New e-mail: bce89be2-af48-492e-82e6-177af622ccf1
Llama.generate: 489 prefix-match hit, remaining 531 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 531 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time = 1182633.99 ms /  9406 tokens (  125.73 ms per token,     7.95 tokens per second)
llama_perf_context_print: prompt eval time = 1182633.99 ms /  9406 tokens (  125.73 ms per token,     7.95 tokens per second)
llama_perf_context_print:        eval time =     233.52 ms /     1 runs   (  233.52 ms per token,     4.28 tokens per second)
llama_perf_context_print:        eval time =     233.52 ms /     1 runs   (  233.52 ms per token,     4.28 tokens per second)
llama_perf_context_print:       total time = 1182946.08 ms /  9407 tokens
llama_perf_context_print:       total time = 1182946.08 ms /  9407 tokens
INFO 05/03/2025 10:41:19 PM UTC E-mail parsing finished: d79ad3e9-3285-4656-99cd-dee87b5ddf09
INFO 05/03/2025 10:41:19 PM UTC E-mail parsing finished: d79ad3e9-3285-4656-99cd-dee87b5ddf09
INFO 05/03/2025 10:41:19 PM UTC New e-mail: dad08d54-b8d2-4727-b4fc-0e22de721253
INFO 05/03/2025 10:41:19 PM UTC New e-mail: dad08d54-b8d2-4727-b4fc-0e22de721253
Llama.generate: 489 prefix-match hit, remaining 737 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 737 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   61655.00 ms /   531 tokens (  116.11 ms per token,     8.61 tokens per second)
llama_perf_context_print: prompt eval time =   61655.00 ms /   531 tokens (  116.11 ms per token,     8.61 tokens per second)
llama_perf_context_print:        eval time =   34619.51 ms /   153 runs   (  226.27 ms per token,     4.42 tokens per second)
llama_perf_context_print:        eval time =   34619.51 ms /   153 runs   (  226.27 ms per token,     4.42 tokens per second)
llama_perf_context_print:       total time =  100203.84 ms /   684 tokens
llama_perf_context_print:       total time =  100203.84 ms /   684 tokens
INFO 05/03/2025 10:41:51 PM UTC E-mail parsing finished: bce89be2-af48-492e-82e6-177af622ccf1
INFO 05/03/2025 10:41:51 PM UTC E-mail parsing finished: bce89be2-af48-492e-82e6-177af622ccf1
INFO 05/03/2025 10:41:51 PM UTC New e-mail: e25d1432-8afd-4f3c-ba07-8b9ae2fa1a0f
INFO 05/03/2025 10:41:51 PM UTC New e-mail: e25d1432-8afd-4f3c-ba07-8b9ae2fa1a0f
Llama.generate: 489 prefix-match hit, remaining 368 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 368 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   49424.74 ms /   368 tokens (  134.31 ms per token,     7.45 tokens per second)
llama_perf_context_print: prompt eval time =   49424.74 ms /   368 tokens (  134.31 ms per token,     7.45 tokens per second)
llama_perf_context_print:        eval time =   23861.39 ms /   108 runs   (  220.94 ms per token,     4.53 tokens per second)
llama_perf_context_print:        eval time =   23861.39 ms /   108 runs   (  220.94 ms per token,     4.53 tokens per second)
llama_perf_context_print:       total time =   75987.43 ms /   476 tokens
llama_perf_context_print:       total time =   75987.43 ms /   476 tokens
INFO 05/03/2025 10:43:07 PM UTC E-mail parsing finished: e25d1432-8afd-4f3c-ba07-8b9ae2fa1a0f
INFO 05/03/2025 10:43:07 PM UTC E-mail parsing finished: e25d1432-8afd-4f3c-ba07-8b9ae2fa1a0f
INFO 05/03/2025 10:43:07 PM UTC New e-mail: 08f2e579-ae15-421e-9ee4-0d5999e8963e
INFO 05/03/2025 10:43:07 PM UTC New e-mail: 08f2e579-ae15-421e-9ee4-0d5999e8963e
Llama.generate: 489 prefix-match hit, remaining 1910 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1910 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  118735.60 ms /   737 tokens (  161.11 ms per token,     6.21 tokens per second)
llama_perf_context_print: prompt eval time =  118735.60 ms /   737 tokens (  161.11 ms per token,     6.21 tokens per second)
llama_perf_context_print:        eval time =   62176.27 ms /   236 runs   (  263.46 ms per token,     3.80 tokens per second)
llama_perf_context_print:        eval time =   62176.27 ms /   236 runs   (  263.46 ms per token,     3.80 tokens per second)
llama_perf_context_print:       total time =  186331.63 ms /   973 tokens
llama_perf_context_print:       total time =  186331.63 ms /   973 tokens
INFO 05/03/2025 10:44:25 PM UTC E-mail parsing finished: dad08d54-b8d2-4727-b4fc-0e22de721253
INFO 05/03/2025 10:44:25 PM UTC E-mail parsing finished: dad08d54-b8d2-4727-b4fc-0e22de721253
INFO 05/03/2025 10:44:25 PM UTC New e-mail: 955ca93f-d370-4f6b-a40f-4f719c5ec27e
INFO 05/03/2025 10:44:25 PM UTC New e-mail: 955ca93f-d370-4f6b-a40f-4f719c5ec27e
Llama.generate: 489 prefix-match hit, remaining 432 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 432 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   53629.87 ms /   432 tokens (  124.14 ms per token,     8.06 tokens per second)
llama_perf_context_print: prompt eval time =   53629.87 ms /   432 tokens (  124.14 ms per token,     8.06 tokens per second)
llama_perf_context_print:        eval time =     314.23 ms /     1 runs   (  314.23 ms per token,     3.18 tokens per second)
llama_perf_context_print:        eval time =     314.23 ms /     1 runs   (  314.23 ms per token,     3.18 tokens per second)
llama_perf_context_print:       total time =   54026.81 ms /   433 tokens
llama_perf_context_print:       total time =   54026.81 ms /   433 tokens
INFO 05/03/2025 10:45:19 PM UTC E-mail parsing finished: 955ca93f-d370-4f6b-a40f-4f719c5ec27e
INFO 05/03/2025 10:45:19 PM UTC E-mail parsing finished: 955ca93f-d370-4f6b-a40f-4f719c5ec27e
INFO 05/03/2025 10:45:19 PM UTC New e-mail: 4d4b4042-36a2-4219-aefa-538d11c8fb43
INFO 05/03/2025 10:45:19 PM UTC New e-mail: 4d4b4042-36a2-4219-aefa-538d11c8fb43
Llama.generate: 492 prefix-match hit, remaining 496 prompt tokens to eval
Llama.generate: 492 prefix-match hit, remaining 496 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   53144.87 ms /   496 tokens (  107.15 ms per token,     9.33 tokens per second)
llama_perf_context_print: prompt eval time =   53144.87 ms /   496 tokens (  107.15 ms per token,     9.33 tokens per second)
llama_perf_context_print:        eval time =   70954.82 ms /   280 runs   (  253.41 ms per token,     3.95 tokens per second)
llama_perf_context_print:        eval time =   70954.82 ms /   280 runs   (  253.41 ms per token,     3.95 tokens per second)
llama_perf_context_print:       total time =  130749.89 ms /   776 tokens
llama_perf_context_print:       total time =  130749.89 ms /   776 tokens
INFO 05/03/2025 10:47:30 PM UTC E-mail parsing finished: 4d4b4042-36a2-4219-aefa-538d11c8fb43
INFO 05/03/2025 10:47:30 PM UTC E-mail parsing finished: 4d4b4042-36a2-4219-aefa-538d11c8fb43
INFO 05/03/2025 10:47:30 PM UTC New e-mail: 53085551-fb23-4a3b-b8a8-68d48f101730
INFO 05/03/2025 10:47:30 PM UTC New e-mail: 53085551-fb23-4a3b-b8a8-68d48f101730
Llama.generate: 538 prefix-match hit, remaining 402 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 402 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  271517.05 ms /  1910 tokens (  142.16 ms per token,     7.03 tokens per second)
llama_perf_context_print: prompt eval time =  271517.05 ms /  1910 tokens (  142.16 ms per token,     7.03 tokens per second)
llama_perf_context_print:        eval time =     236.83 ms /     1 runs   (  236.83 ms per token,     4.22 tokens per second)
llama_perf_context_print:        eval time =     236.83 ms /     1 runs   (  236.83 ms per token,     4.22 tokens per second)
llama_perf_context_print:       total time =  271817.54 ms /  1911 tokens
llama_perf_context_print:       total time =  271817.54 ms /  1911 tokens
INFO 05/03/2025 10:47:38 PM UTC E-mail parsing finished: 08f2e579-ae15-421e-9ee4-0d5999e8963e
INFO 05/03/2025 10:47:38 PM UTC E-mail parsing finished: 08f2e579-ae15-421e-9ee4-0d5999e8963e
INFO 05/03/2025 10:47:38 PM UTC New e-mail: 63287ca0-6c42-428c-b592-27ee88542cf9
INFO 05/03/2025 10:47:38 PM UTC New e-mail: 63287ca0-6c42-428c-b592-27ee88542cf9
Llama.generate: 489 prefix-match hit, remaining 463 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 463 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   43908.49 ms /   402 tokens (  109.23 ms per token,     9.16 tokens per second)
llama_perf_context_print: prompt eval time =   43908.49 ms /   402 tokens (  109.23 ms per token,     9.16 tokens per second)
llama_perf_context_print:        eval time =   17871.94 ms /    71 runs   (  251.72 ms per token,     3.97 tokens per second)
llama_perf_context_print:        eval time =   17871.94 ms /    71 runs   (  251.72 ms per token,     3.97 tokens per second)
llama_perf_context_print:       total time =   63393.51 ms /   473 tokens
llama_perf_context_print:       total time =   63393.51 ms /   473 tokens
INFO 05/03/2025 10:48:33 PM UTC E-mail parsing finished: 53085551-fb23-4a3b-b8a8-68d48f101730
INFO 05/03/2025 10:48:33 PM UTC E-mail parsing finished: 53085551-fb23-4a3b-b8a8-68d48f101730
INFO 05/03/2025 10:48:33 PM UTC New e-mail: 2ab7eb33-3d9d-447f-81ed-d0cee518b411
INFO 05/03/2025 10:48:33 PM UTC New e-mail: 2ab7eb33-3d9d-447f-81ed-d0cee518b411
Llama.generate: 489 prefix-match hit, remaining 98 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 98 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   59969.13 ms /   463 tokens (  129.52 ms per token,     7.72 tokens per second)
llama_perf_context_print: prompt eval time =   59969.13 ms /   463 tokens (  129.52 ms per token,     7.72 tokens per second)
llama_perf_context_print:        eval time =   26001.30 ms /   118 runs   (  220.35 ms per token,     4.54 tokens per second)
llama_perf_context_print:        eval time =   26001.30 ms /   118 runs   (  220.35 ms per token,     4.54 tokens per second)
llama_perf_context_print:       total time =   88652.76 ms /   581 tokens
llama_perf_context_print:       total time =   88652.76 ms /   581 tokens
INFO 05/03/2025 10:49:07 PM UTC E-mail parsing finished: 63287ca0-6c42-428c-b592-27ee88542cf9
INFO 05/03/2025 10:49:07 PM UTC E-mail parsing finished: 63287ca0-6c42-428c-b592-27ee88542cf9
WARNING 05/03/2025 10:49:07 PM UTC Events from an email rejected due to data validation errors
WARNING 05/03/2025 10:49:07 PM UTC Events from an email rejected due to data validation errors
Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 151, in _on_new_events
  File "/app/modules/validator.py", line 151, in _on_new_events
    data: NewEvents = NewEvents.model_validate_json(body)
    data: NewEvents = NewEvents.model_validate_json(body)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 2 validation errors for NewEvents
pydantic_core._pydantic_core.ValidationError: 2 validation errors for NewEvents
events.0.start_date
events.0.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
events.1.start_date
events.1.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
INFO 05/03/2025 10:49:07 PM UTC New e-mail: 760b01b0-174f-48c4-83c2-2f19920cace5
INFO 05/03/2025 10:49:07 PM UTC New e-mail: 760b01b0-174f-48c4-83c2-2f19920cace5
Llama.generate: 489 prefix-match hit, remaining 186 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 186 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   54368.48 ms /    98 tokens (  554.78 ms per token,     1.80 tokens per second)
llama_perf_context_print: prompt eval time =   54368.48 ms /    98 tokens (  554.78 ms per token,     1.80 tokens per second)
llama_perf_context_print:        eval time =     264.01 ms /     1 runs   (  264.01 ms per token,     3.79 tokens per second)
llama_perf_context_print:        eval time =     264.01 ms /     1 runs   (  264.01 ms per token,     3.79 tokens per second)
llama_perf_context_print:       total time =   54703.16 ms /    99 tokens
llama_perf_context_print:       total time =   54703.16 ms /    99 tokens
INFO 05/03/2025 10:49:28 PM UTC E-mail parsing finished: 2ab7eb33-3d9d-447f-81ed-d0cee518b411
INFO 05/03/2025 10:49:28 PM UTC E-mail parsing finished: 2ab7eb33-3d9d-447f-81ed-d0cee518b411
INFO 05/03/2025 10:49:28 PM UTC New e-mail: 417a5377-3e42-4b7e-803c-83346c8d99d8
INFO 05/03/2025 10:49:28 PM UTC New e-mail: 417a5377-3e42-4b7e-803c-83346c8d99d8
Llama.generate: 489 prefix-match hit, remaining 1773 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1773 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   44802.09 ms /   186 tokens (  240.87 ms per token,     4.15 tokens per second)
llama_perf_context_print: prompt eval time =   44802.09 ms /   186 tokens (  240.87 ms per token,     4.15 tokens per second)
llama_perf_context_print:        eval time =     229.69 ms /     1 runs   (  229.69 ms per token,     4.35 tokens per second)
llama_perf_context_print:        eval time =     229.69 ms /     1 runs   (  229.69 ms per token,     4.35 tokens per second)
llama_perf_context_print:       total time =   45078.51 ms /   187 tokens
llama_perf_context_print:       total time =   45078.51 ms /   187 tokens
INFO 05/03/2025 10:49:52 PM UTC E-mail parsing finished: 760b01b0-174f-48c4-83c2-2f19920cace5
INFO 05/03/2025 10:49:52 PM UTC E-mail parsing finished: 760b01b0-174f-48c4-83c2-2f19920cace5
INFO 05/03/2025 10:49:52 PM UTC New e-mail: c3641f09-cbaf-4e7f-aeb1-898974b2f5cb
INFO 05/03/2025 10:49:52 PM UTC New e-mail: c3641f09-cbaf-4e7f-aeb1-898974b2f5cb
Llama.generate: 489 prefix-match hit, remaining 10434 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 10434 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  202396.54 ms /  1773 tokens (  114.15 ms per token,     8.76 tokens per second)
llama_perf_context_print: prompt eval time =  202396.54 ms /  1773 tokens (  114.15 ms per token,     8.76 tokens per second)
llama_perf_context_print:        eval time =   27489.68 ms /    99 runs   (  277.67 ms per token,     3.60 tokens per second)
llama_perf_context_print:        eval time =   27489.68 ms /    99 runs   (  277.67 ms per token,     3.60 tokens per second)
llama_perf_context_print:       total time =  232260.79 ms /  1872 tokens
llama_perf_context_print:       total time =  232260.79 ms /  1872 tokens
INFO 05/03/2025 10:53:20 PM UTC E-mail parsing finished: 417a5377-3e42-4b7e-803c-83346c8d99d8
INFO 05/03/2025 10:53:20 PM UTC E-mail parsing finished: 417a5377-3e42-4b7e-803c-83346c8d99d8
INFO 05/03/2025 10:53:20 PM UTC New e-mail: 49ce2d91-24bc-4446-86fb-797ab9e111df
INFO 05/03/2025 10:53:20 PM UTC New e-mail: 49ce2d91-24bc-4446-86fb-797ab9e111df
Llama.generate: 489 prefix-match hit, remaining 379 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 379 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   47306.36 ms /   379 tokens (  124.82 ms per token,     8.01 tokens per second)
llama_perf_context_print: prompt eval time =   47306.36 ms /   379 tokens (  124.82 ms per token,     8.01 tokens per second)
llama_perf_context_print:        eval time =     295.93 ms /     1 runs   (  295.93 ms per token,     3.38 tokens per second)
llama_perf_context_print:        eval time =     295.93 ms /     1 runs   (  295.93 ms per token,     3.38 tokens per second)
llama_perf_context_print:       total time =   47648.67 ms /   380 tokens
llama_perf_context_print:       total time =   47648.67 ms /   380 tokens
INFO 05/03/2025 10:54:08 PM UTC E-mail parsing finished: 49ce2d91-24bc-4446-86fb-797ab9e111df
INFO 05/03/2025 10:54:08 PM UTC E-mail parsing finished: 49ce2d91-24bc-4446-86fb-797ab9e111df
INFO 05/03/2025 10:54:08 PM UTC New e-mail: d1e5fcaa-aa53-4e90-9fff-f47e35d71461
INFO 05/03/2025 10:54:08 PM UTC New e-mail: d1e5fcaa-aa53-4e90-9fff-f47e35d71461
Llama.generate: 489 prefix-match hit, remaining 10447 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 10447 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time = 1257503.03 ms / 10434 tokens (  120.52 ms per token,     8.30 tokens per second)
llama_perf_context_print: prompt eval time = 1257503.03 ms / 10434 tokens (  120.52 ms per token,     8.30 tokens per second)
llama_perf_context_print:        eval time =     333.66 ms /     1 runs   (  333.66 ms per token,     3.00 tokens per second)
llama_perf_context_print:        eval time =     333.66 ms /     1 runs   (  333.66 ms per token,     3.00 tokens per second)
llama_perf_context_print:       total time = 1257876.88 ms / 10435 tokens
llama_perf_context_print:       total time = 1257876.88 ms / 10435 tokens
INFO 05/03/2025 11:10:50 PM UTC E-mail parsing finished: c3641f09-cbaf-4e7f-aeb1-898974b2f5cb
INFO 05/03/2025 11:10:50 PM UTC E-mail parsing finished: c3641f09-cbaf-4e7f-aeb1-898974b2f5cb
INFO 05/03/2025 11:10:50 PM UTC New e-mail: b8a893d7-5514-4d88-8be2-b3ea831de12f
INFO 05/03/2025 11:10:50 PM UTC New e-mail: b8a893d7-5514-4d88-8be2-b3ea831de12f
Llama.generate: 489 prefix-match hit, remaining 1327 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1327 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  157901.01 ms /  1327 tokens (  118.99 ms per token,     8.40 tokens per second)
llama_perf_context_print: prompt eval time =  157901.01 ms /  1327 tokens (  118.99 ms per token,     8.40 tokens per second)
llama_perf_context_print:        eval time =   31862.91 ms /   130 runs   (  245.10 ms per token,     4.08 tokens per second)
llama_perf_context_print:        eval time =   31862.91 ms /   130 runs   (  245.10 ms per token,     4.08 tokens per second)
llama_perf_context_print:       total time =  192967.65 ms /  1457 tokens
llama_perf_context_print:       total time =  192967.65 ms /  1457 tokens
INFO 05/03/2025 11:14:03 PM UTC E-mail parsing finished: b8a893d7-5514-4d88-8be2-b3ea831de12f
INFO 05/03/2025 11:14:03 PM UTC E-mail parsing finished: b8a893d7-5514-4d88-8be2-b3ea831de12f
INFO 05/03/2025 11:14:03 PM UTC New e-mail: 12cd07f4-54b7-4194-8a38-567b4624ec85
INFO 05/03/2025 11:14:03 PM UTC New e-mail: 12cd07f4-54b7-4194-8a38-567b4624ec85
Llama.generate: 489 prefix-match hit, remaining 1223 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1223 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time = 1229391.76 ms / 10447 tokens (  117.68 ms per token,     8.50 tokens per second)
llama_perf_context_print: prompt eval time = 1229391.76 ms / 10447 tokens (  117.68 ms per token,     8.50 tokens per second)
llama_perf_context_print:        eval time =     357.30 ms /     1 runs   (  357.30 ms per token,     2.80 tokens per second)
llama_perf_context_print:        eval time =     357.30 ms /     1 runs   (  357.30 ms per token,     2.80 tokens per second)
llama_perf_context_print:       total time = 1229813.47 ms / 10448 tokens
llama_perf_context_print:       total time = 1229813.47 ms / 10448 tokens
INFO 05/03/2025 11:14:38 PM UTC E-mail parsing finished: d1e5fcaa-aa53-4e90-9fff-f47e35d71461
INFO 05/03/2025 11:14:38 PM UTC E-mail parsing finished: d1e5fcaa-aa53-4e90-9fff-f47e35d71461
INFO 05/03/2025 11:14:38 PM UTC New e-mail: 1ff4682a-7be5-4420-b02e-4eee87af0023
INFO 05/03/2025 11:14:38 PM UTC New e-mail: 1ff4682a-7be5-4420-b02e-4eee87af0023
Llama.generate: 489 prefix-match hit, remaining 568 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 568 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   86359.30 ms /   568 tokens (  152.04 ms per token,     6.58 tokens per second)
llama_perf_context_print: prompt eval time =   86359.30 ms /   568 tokens (  152.04 ms per token,     6.58 tokens per second)
llama_perf_context_print:        eval time =   21887.04 ms /    84 runs   (  260.56 ms per token,     3.84 tokens per second)
llama_perf_context_print:        eval time =   21887.04 ms /    84 runs   (  260.56 ms per token,     3.84 tokens per second)
llama_perf_context_print:       total time =  109981.37 ms /   652 tokens
llama_perf_context_print:       total time =  109981.37 ms /   652 tokens
INFO 05/03/2025 11:16:28 PM UTC E-mail parsing finished: 1ff4682a-7be5-4420-b02e-4eee87af0023
INFO 05/03/2025 11:16:28 PM UTC E-mail parsing finished: 1ff4682a-7be5-4420-b02e-4eee87af0023
INFO 05/03/2025 11:16:28 PM UTC New e-mail: 63974751-c0c9-45fb-87b0-cf86b3690ce4
INFO 05/03/2025 11:16:28 PM UTC New e-mail: 63974751-c0c9-45fb-87b0-cf86b3690ce4
Llama.generate: 489 prefix-match hit, remaining 5007 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 5007 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  164753.11 ms /  1223 tokens (  134.71 ms per token,     7.42 tokens per second)
llama_perf_context_print: prompt eval time =  164753.11 ms /  1223 tokens (  134.71 ms per token,     7.42 tokens per second)
llama_perf_context_print:        eval time =   28180.57 ms /   119 runs   (  236.81 ms per token,     4.22 tokens per second)
llama_perf_context_print:        eval time =   28180.57 ms /   119 runs   (  236.81 ms per token,     4.22 tokens per second)
llama_perf_context_print:       total time =  195870.35 ms /  1342 tokens
llama_perf_context_print:       total time =  195870.35 ms /  1342 tokens
INFO 05/03/2025 11:17:19 PM UTC E-mail parsing finished: 12cd07f4-54b7-4194-8a38-567b4624ec85
INFO 05/03/2025 11:17:19 PM UTC E-mail parsing finished: 12cd07f4-54b7-4194-8a38-567b4624ec85
INFO 05/03/2025 11:17:19 PM UTC New e-mail: fc98c298-1fbf-47fe-86bf-7d678c85f9da
INFO 05/03/2025 11:17:19 PM UTC New e-mail: fc98c298-1fbf-47fe-86bf-7d678c85f9da
Llama.generate: 489 prefix-match hit, remaining 305 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 305 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   46547.35 ms /   305 tokens (  152.61 ms per token,     6.55 tokens per second)
llama_perf_context_print: prompt eval time =   46547.35 ms /   305 tokens (  152.61 ms per token,     6.55 tokens per second)
llama_perf_context_print:        eval time =   20552.11 ms /    89 runs   (  230.92 ms per token,     4.33 tokens per second)
llama_perf_context_print:        eval time =   20552.11 ms /    89 runs   (  230.92 ms per token,     4.33 tokens per second)
llama_perf_context_print:       total time =   69192.37 ms /   394 tokens
llama_perf_context_print:       total time =   69192.37 ms /   394 tokens
INFO 05/03/2025 11:18:28 PM UTC E-mail parsing finished: fc98c298-1fbf-47fe-86bf-7d678c85f9da
INFO 05/03/2025 11:18:28 PM UTC E-mail parsing finished: fc98c298-1fbf-47fe-86bf-7d678c85f9da
INFO 05/03/2025 11:18:28 PM UTC New e-mail: 00636e97-56a4-41b3-ad7d-e4ebe28ba844
INFO 05/03/2025 11:18:28 PM UTC New e-mail: 00636e97-56a4-41b3-ad7d-e4ebe28ba844
Llama.generate: 536 prefix-match hit, remaining 333 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 333 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   51501.34 ms /   333 tokens (  154.66 ms per token,     6.47 tokens per second)
llama_perf_context_print: prompt eval time =   51501.34 ms /   333 tokens (  154.66 ms per token,     6.47 tokens per second)
llama_perf_context_print:        eval time =   17848.57 ms /    84 runs   (  212.48 ms per token,     4.71 tokens per second)
llama_perf_context_print:        eval time =   17848.57 ms /    84 runs   (  212.48 ms per token,     4.71 tokens per second)
llama_perf_context_print:       total time =   71365.10 ms /   417 tokens
llama_perf_context_print:       total time =   71365.10 ms /   417 tokens
INFO 05/03/2025 11:19:40 PM UTC E-mail parsing finished: 00636e97-56a4-41b3-ad7d-e4ebe28ba844
INFO 05/03/2025 11:19:40 PM UTC E-mail parsing finished: 00636e97-56a4-41b3-ad7d-e4ebe28ba844
INFO 05/03/2025 11:19:40 PM UTC New e-mail: 88ede30e-76b8-4499-bbab-45f5e4871519
INFO 05/03/2025 11:19:40 PM UTC New e-mail: 88ede30e-76b8-4499-bbab-45f5e4871519
Llama.generate: 489 prefix-match hit, remaining 250 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 250 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   47139.11 ms /   250 tokens (  188.56 ms per token,     5.30 tokens per second)
llama_perf_context_print: prompt eval time =   47139.11 ms /   250 tokens (  188.56 ms per token,     5.30 tokens per second)
llama_perf_context_print:        eval time =     228.91 ms /     1 runs   (  228.91 ms per token,     4.37 tokens per second)
llama_perf_context_print:        eval time =     228.91 ms /     1 runs   (  228.91 ms per token,     4.37 tokens per second)
llama_perf_context_print:       total time =   47420.79 ms /   251 tokens
llama_perf_context_print:       total time =   47420.79 ms /   251 tokens
INFO 05/03/2025 11:20:27 PM UTC E-mail parsing finished: 88ede30e-76b8-4499-bbab-45f5e4871519
INFO 05/03/2025 11:20:27 PM UTC E-mail parsing finished: 88ede30e-76b8-4499-bbab-45f5e4871519
INFO 05/03/2025 11:20:27 PM UTC New e-mail: 811f3e76-2dad-429e-b47a-cff8c5709421
INFO 05/03/2025 11:20:27 PM UTC New e-mail: 811f3e76-2dad-429e-b47a-cff8c5709421
Llama.generate: 489 prefix-match hit, remaining 168 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 168 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   43110.91 ms /   168 tokens (  256.61 ms per token,     3.90 tokens per second)
llama_perf_context_print: prompt eval time =   43110.91 ms /   168 tokens (  256.61 ms per token,     3.90 tokens per second)
llama_perf_context_print:        eval time =     213.97 ms /     1 runs   (  213.97 ms per token,     4.67 tokens per second)
llama_perf_context_print:        eval time =     213.97 ms /     1 runs   (  213.97 ms per token,     4.67 tokens per second)
llama_perf_context_print:       total time =   43372.51 ms /   169 tokens
llama_perf_context_print:       total time =   43372.51 ms /   169 tokens
INFO 05/03/2025 11:21:10 PM UTC E-mail parsing finished: 811f3e76-2dad-429e-b47a-cff8c5709421
INFO 05/03/2025 11:21:10 PM UTC E-mail parsing finished: 811f3e76-2dad-429e-b47a-cff8c5709421
INFO 05/03/2025 11:21:10 PM UTC New e-mail: 9569df9b-24ad-4ee6-b783-0089f2db42bc
INFO 05/03/2025 11:21:10 PM UTC New e-mail: 9569df9b-24ad-4ee6-b783-0089f2db42bc
Llama.generate: 489 prefix-match hit, remaining 772 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 772 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  100705.55 ms /   772 tokens (  130.45 ms per token,     7.67 tokens per second)
llama_perf_context_print: prompt eval time =  100705.55 ms /   772 tokens (  130.45 ms per token,     7.67 tokens per second)
llama_perf_context_print:        eval time =   61981.85 ms /   261 runs   (  237.48 ms per token,     4.21 tokens per second)
llama_perf_context_print:        eval time =   61981.85 ms /   261 runs   (  237.48 ms per token,     4.21 tokens per second)
llama_perf_context_print:       total time =  168967.27 ms /  1033 tokens
llama_perf_context_print:       total time =  168967.27 ms /  1033 tokens
INFO 05/03/2025 11:23:59 PM UTC E-mail parsing finished: 9569df9b-24ad-4ee6-b783-0089f2db42bc
INFO 05/03/2025 11:23:59 PM UTC E-mail parsing finished: 9569df9b-24ad-4ee6-b783-0089f2db42bc
INFO 05/03/2025 11:23:59 PM UTC New e-mail: 1418524d-ab6b-4c32-a53b-cf68476ef48b
INFO 05/03/2025 11:23:59 PM UTC New e-mail: 1418524d-ab6b-4c32-a53b-cf68476ef48b
Llama.generate: 489 prefix-match hit, remaining 960 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 960 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  105848.63 ms /   960 tokens (  110.26 ms per token,     9.07 tokens per second)
llama_perf_context_print: prompt eval time =  105848.63 ms /   960 tokens (  110.26 ms per token,     9.07 tokens per second)
llama_perf_context_print:        eval time =     301.22 ms /     1 runs   (  301.22 ms per token,     3.32 tokens per second)
llama_perf_context_print:        eval time =     301.22 ms /     1 runs   (  301.22 ms per token,     3.32 tokens per second)
llama_perf_context_print:       total time =  106188.64 ms /   961 tokens
llama_perf_context_print:       total time =  106188.64 ms /   961 tokens
INFO 05/03/2025 11:25:46 PM UTC E-mail parsing finished: 1418524d-ab6b-4c32-a53b-cf68476ef48b
INFO 05/03/2025 11:25:46 PM UTC E-mail parsing finished: 1418524d-ab6b-4c32-a53b-cf68476ef48b
INFO 05/03/2025 11:25:46 PM UTC New e-mail: 767665a2-0df4-4a41-ac95-4a318cb6cdcc
INFO 05/03/2025 11:25:46 PM UTC New e-mail: 767665a2-0df4-4a41-ac95-4a318cb6cdcc
Llama.generate: 489 prefix-match hit, remaining 845 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 845 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  581700.44 ms /  5007 tokens (  116.18 ms per token,     8.61 tokens per second)
llama_perf_context_print: prompt eval time =  581700.44 ms /  5007 tokens (  116.18 ms per token,     8.61 tokens per second)
llama_perf_context_print:        eval time =   63185.81 ms /   201 runs   (  314.36 ms per token,     3.18 tokens per second)
llama_perf_context_print:        eval time =   63185.81 ms /   201 runs   (  314.36 ms per token,     3.18 tokens per second)
llama_perf_context_print:       total time =  649594.16 ms /  5208 tokens
llama_perf_context_print:       total time =  649594.16 ms /  5208 tokens
INFO 05/03/2025 11:27:17 PM UTC E-mail parsing finished: 63974751-c0c9-45fb-87b0-cf86b3690ce4
INFO 05/03/2025 11:27:17 PM UTC E-mail parsing finished: 63974751-c0c9-45fb-87b0-cf86b3690ce4
INFO 05/03/2025 11:27:17 PM UTC New e-mail: c99bea1b-783d-43db-8f61-4207295b1732
INFO 05/03/2025 11:27:17 PM UTC New e-mail: c99bea1b-783d-43db-8f61-4207295b1732
Llama.generate: 489 prefix-match hit, remaining 304 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 304 prompt tokens to eval
ERROR 05/03/2025 11:27:17 PM UTC Unknown exception occurred
ERROR 05/03/2025 11:27:17 PM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '2003-3' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '2003-3' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 134, in add_events_to_db
  File "/app/modules/validator.py", line 134, in add_events_to_db
    event_row = self.validate_and_create_event_row(db_session, parsed_event, new_events.user_timezone)
    event_row = self.validate_and_create_event_row(db_session, parsed_event, new_events.user_timezone)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/modules/validator.py", line 116, in validate_and_create_event_row
  File "/app/modules/validator.py", line 116, in validate_and_create_event_row
    event_row.tags.append(self.get_or_create_tag(db_session, tag_name))
    event_row.tags.append(self.get_or_create_tag(db_session, tag_name))
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/modules/validator.py", line 72, in get_or_create_tag
  File "/app/modules/validator.py", line 72, in get_or_create_tag
    tag_row = db_session.execute(query).scalar_one_or_none()
    tag_row = db_session.execute(query).scalar_one_or_none()
              ^^^^^^^^^^^^^^^^^^^^^^^^^
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2362, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2362, in execute
    return self._execute_internal(
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2226, in _execute_internal
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2226, in _execute_internal
    ) = compile_state_cls.orm_pre_session_exec(
    ) = compile_state_cls.orm_pre_session_exec(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 561, in orm_pre_session_exec
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 561, in orm_pre_session_exec
    session._autoflush()
    session._autoflush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3061, in _autoflush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3061, in _autoflush
    raise e.with_traceback(sys.exc_info()[2])
    raise e.with_traceback(sys.exc_info()[2])
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3050, in _autoflush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3050, in _autoflush
    self.flush()
    self.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)
sqlalchemy.exc.IntegrityError: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)
(pymysql.err.IntegrityError) (1062, "Duplicate entry '2003-3' for key 'tags_to_events.PRIMARY'")
(pymysql.err.IntegrityError) (1062, "Duplicate entry '2003-3' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 2003, 'tag_id': 5}, {'event_id': 2003, 'tag_id': 7}, {'event_id': 2003, 'tag_id': 2}, {'event_id': 2003, 'tag_id': 3}, {'event_id': 2003, 'tag_id': 1}, {'event_id': 2003, 'tag_id': 4}, {'event_id': 2003, 'tag_id': 8}, {'event_id': 2003, 'tag_id': 6}, {'event_id': 2003, 'tag_id': 3}]]
[parameters: [{'event_id': 2003, 'tag_id': 5}, {'event_id': 2003, 'tag_id': 7}, {'event_id': 2003, 'tag_id': 2}, {'event_id': 2003, 'tag_id': 3}, {'event_id': 2003, 'tag_id': 1}, {'event_id': 2003, 'tag_id': 4}, {'event_id': 2003, 'tag_id': 8}, {'event_id': 2003, 'tag_id': 6}, {'event_id': 2003, 'tag_id': 3}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  129559.43 ms /   845 tokens (  153.32 ms per token,     6.52 tokens per second)
llama_perf_context_print: prompt eval time =  129559.43 ms /   845 tokens (  153.32 ms per token,     6.52 tokens per second)
llama_perf_context_print:        eval time =     196.65 ms /     1 runs   (  196.65 ms per token,     5.09 tokens per second)
llama_perf_context_print:        eval time =     196.65 ms /     1 runs   (  196.65 ms per token,     5.09 tokens per second)
llama_perf_context_print:       total time =  129851.90 ms /   846 tokens
llama_perf_context_print:       total time =  129851.90 ms /   846 tokens
INFO 05/03/2025 11:27:56 PM UTC E-mail parsing finished: 767665a2-0df4-4a41-ac95-4a318cb6cdcc
INFO 05/03/2025 11:27:56 PM UTC E-mail parsing finished: 767665a2-0df4-4a41-ac95-4a318cb6cdcc
INFO 05/03/2025 11:27:56 PM UTC New e-mail: 93cb690b-3cc2-4430-b9bd-69bc08c38293
INFO 05/03/2025 11:27:56 PM UTC New e-mail: 93cb690b-3cc2-4430-b9bd-69bc08c38293
Llama.generate: 489 prefix-match hit, remaining 289 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 289 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   49333.48 ms /   304 tokens (  162.28 ms per token,     6.16 tokens per second)
llama_perf_context_print: prompt eval time =   49333.48 ms /   304 tokens (  162.28 ms per token,     6.16 tokens per second)
llama_perf_context_print:        eval time =   39912.90 ms /   166 runs   (  240.44 ms per token,     4.16 tokens per second)
llama_perf_context_print:        eval time =   39912.90 ms /   166 runs   (  240.44 ms per token,     4.16 tokens per second)
llama_perf_context_print:       total time =   93209.13 ms /   470 tokens
llama_perf_context_print:       total time =   93209.13 ms /   470 tokens
INFO 05/03/2025 11:28:51 PM UTC E-mail parsing finished: c99bea1b-783d-43db-8f61-4207295b1732
INFO 05/03/2025 11:28:51 PM UTC E-mail parsing finished: c99bea1b-783d-43db-8f61-4207295b1732
INFO 05/03/2025 11:28:51 PM UTC New e-mail: 278f2c46-92b4-4bbe-af92-185769f01b90
INFO 05/03/2025 11:28:51 PM UTC New e-mail: 278f2c46-92b4-4bbe-af92-185769f01b90
Llama.generate: 489 prefix-match hit, remaining 562 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 562 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   69151.92 ms /   289 tokens (  239.28 ms per token,     4.18 tokens per second)
llama_perf_context_print: prompt eval time =   69151.92 ms /   289 tokens (  239.28 ms per token,     4.18 tokens per second)
llama_perf_context_print:        eval time =   54526.58 ms /   252 runs   (  216.38 ms per token,     4.62 tokens per second)
llama_perf_context_print:        eval time =   54526.58 ms /   252 runs   (  216.38 ms per token,     4.62 tokens per second)
llama_perf_context_print:       total time =  130183.64 ms /   541 tokens
llama_perf_context_print:       total time =  130183.64 ms /   541 tokens
INFO 05/03/2025 11:30:06 PM UTC E-mail parsing finished: 93cb690b-3cc2-4430-b9bd-69bc08c38293
INFO 05/03/2025 11:30:06 PM UTC E-mail parsing finished: 93cb690b-3cc2-4430-b9bd-69bc08c38293
INFO 05/03/2025 11:30:06 PM UTC New e-mail: b2c3ec54-f033-4e11-b4a7-ff32ea22b594
INFO 05/03/2025 11:30:06 PM UTC New e-mail: b2c3ec54-f033-4e11-b4a7-ff32ea22b594
Llama.generate: 489 prefix-match hit, remaining 523 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 523 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   85027.39 ms /   523 tokens (  162.58 ms per token,     6.15 tokens per second)
llama_perf_context_print: prompt eval time =   85027.39 ms /   523 tokens (  162.58 ms per token,     6.15 tokens per second)
llama_perf_context_print:        eval time =     173.77 ms /     1 runs   (  173.77 ms per token,     5.75 tokens per second)
llama_perf_context_print:        eval time =     173.77 ms /     1 runs   (  173.77 ms per token,     5.75 tokens per second)
llama_perf_context_print:       total time =   85251.57 ms /   524 tokens
llama_perf_context_print:       total time =   85251.57 ms /   524 tokens
INFO 05/03/2025 11:31:31 PM UTC E-mail parsing finished: b2c3ec54-f033-4e11-b4a7-ff32ea22b594
INFO 05/03/2025 11:31:31 PM UTC E-mail parsing finished: b2c3ec54-f033-4e11-b4a7-ff32ea22b594
INFO 05/03/2025 11:31:31 PM UTC New e-mail: 5b78f85c-0b2d-4119-b0d1-3f9ea7f2e60d
INFO 05/03/2025 11:31:31 PM UTC New e-mail: 5b78f85c-0b2d-4119-b0d1-3f9ea7f2e60d
Llama.generate: 538 prefix-match hit, remaining 450 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 450 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  110303.86 ms /   562 tokens (  196.27 ms per token,     5.10 tokens per second)
llama_perf_context_print: prompt eval time =  110303.86 ms /   562 tokens (  196.27 ms per token,     5.10 tokens per second)
llama_perf_context_print:        eval time =   74214.23 ms /   296 runs   (  250.72 ms per token,     3.99 tokens per second)
llama_perf_context_print:        eval time =   74214.23 ms /   296 runs   (  250.72 ms per token,     3.99 tokens per second)
llama_perf_context_print:       total time =  191189.20 ms /   858 tokens
llama_perf_context_print:       total time =  191189.20 ms /   858 tokens
INFO 05/03/2025 11:32:02 PM UTC E-mail parsing finished: 278f2c46-92b4-4bbe-af92-185769f01b90
INFO 05/03/2025 11:32:02 PM UTC E-mail parsing finished: 278f2c46-92b4-4bbe-af92-185769f01b90
INFO 05/03/2025 11:32:02 PM UTC New e-mail: 870719b5-7ef6-4bc7-b136-b0e9c861ce3d
INFO 05/03/2025 11:32:02 PM UTC New e-mail: 870719b5-7ef6-4bc7-b136-b0e9c861ce3d
Llama.generate: 489 prefix-match hit, remaining 373 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 373 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   64180.41 ms /   450 tokens (  142.62 ms per token,     7.01 tokens per second)
llama_perf_context_print: prompt eval time =   64180.41 ms /   450 tokens (  142.62 ms per token,     7.01 tokens per second)
llama_perf_context_print:        eval time =     226.38 ms /     1 runs   (  226.38 ms per token,     4.42 tokens per second)
llama_perf_context_print:        eval time =     226.38 ms /     1 runs   (  226.38 ms per token,     4.42 tokens per second)
llama_perf_context_print:       total time =   64456.94 ms /   451 tokens
llama_perf_context_print:       total time =   64456.94 ms /   451 tokens
INFO 05/03/2025 11:32:35 PM UTC E-mail parsing finished: 5b78f85c-0b2d-4119-b0d1-3f9ea7f2e60d
INFO 05/03/2025 11:32:35 PM UTC E-mail parsing finished: 5b78f85c-0b2d-4119-b0d1-3f9ea7f2e60d
INFO 05/03/2025 11:32:35 PM UTC New e-mail: e84fcda2-3d80-47f4-aee0-89cf74d7bc03
INFO 05/03/2025 11:32:35 PM UTC New e-mail: e84fcda2-3d80-47f4-aee0-89cf74d7bc03
Llama.generate: 489 prefix-match hit, remaining 153 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 153 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   48523.91 ms /   373 tokens (  130.09 ms per token,     7.69 tokens per second)
llama_perf_context_print: prompt eval time =   48523.91 ms /   373 tokens (  130.09 ms per token,     7.69 tokens per second)
llama_perf_context_print:        eval time =     280.21 ms /     1 runs   (  280.21 ms per token,     3.57 tokens per second)
llama_perf_context_print:        eval time =     280.21 ms /     1 runs   (  280.21 ms per token,     3.57 tokens per second)
llama_perf_context_print:       total time =   48846.71 ms /   374 tokens
llama_perf_context_print:       total time =   48846.71 ms /   374 tokens
INFO 05/03/2025 11:32:51 PM UTC E-mail parsing finished: 870719b5-7ef6-4bc7-b136-b0e9c861ce3d
INFO 05/03/2025 11:32:51 PM UTC E-mail parsing finished: 870719b5-7ef6-4bc7-b136-b0e9c861ce3d
INFO 05/03/2025 11:32:51 PM UTC New e-mail: a967bd3d-8833-4966-91b7-9f9c2ac9426b
INFO 05/03/2025 11:32:51 PM UTC New e-mail: a967bd3d-8833-4966-91b7-9f9c2ac9426b
Llama.generate: 519 prefix-match hit, remaining 123 prompt tokens to eval
Llama.generate: 519 prefix-match hit, remaining 123 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   43198.78 ms /   153 tokens (  282.34 ms per token,     3.54 tokens per second)
llama_perf_context_print: prompt eval time =   43198.78 ms /   153 tokens (  282.34 ms per token,     3.54 tokens per second)
llama_perf_context_print:        eval time =     215.83 ms /     1 runs   (  215.83 ms per token,     4.63 tokens per second)
llama_perf_context_print:        eval time =     215.83 ms /     1 runs   (  215.83 ms per token,     4.63 tokens per second)
llama_perf_context_print:       total time =   43459.31 ms /   154 tokens
llama_perf_context_print:       total time =   43459.31 ms /   154 tokens
INFO 05/03/2025 11:33:19 PM UTC E-mail parsing finished: e84fcda2-3d80-47f4-aee0-89cf74d7bc03
INFO 05/03/2025 11:33:19 PM UTC E-mail parsing finished: e84fcda2-3d80-47f4-aee0-89cf74d7bc03
INFO 05/03/2025 11:33:19 PM UTC New e-mail: 73de52f1-df11-4d59-a800-44b50223e954
INFO 05/03/2025 11:33:19 PM UTC New e-mail: 73de52f1-df11-4d59-a800-44b50223e954
Llama.generate: 489 prefix-match hit, remaining 251 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 251 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   40342.84 ms /   123 tokens (  327.99 ms per token,     3.05 tokens per second)
llama_perf_context_print: prompt eval time =   40342.84 ms /   123 tokens (  327.99 ms per token,     3.05 tokens per second)
llama_perf_context_print:        eval time =     250.37 ms /     1 runs   (  250.37 ms per token,     3.99 tokens per second)
llama_perf_context_print:        eval time =     250.37 ms /     1 runs   (  250.37 ms per token,     3.99 tokens per second)
llama_perf_context_print:       total time =   40662.16 ms /   124 tokens
llama_perf_context_print:       total time =   40662.16 ms /   124 tokens
INFO 05/03/2025 11:33:31 PM UTC E-mail parsing finished: a967bd3d-8833-4966-91b7-9f9c2ac9426b
INFO 05/03/2025 11:33:31 PM UTC E-mail parsing finished: a967bd3d-8833-4966-91b7-9f9c2ac9426b
INFO 05/03/2025 11:33:31 PM UTC New e-mail: 6fbdd1ea-a4ed-4f8c-993e-e1ad178e1fe8
INFO 05/03/2025 11:33:31 PM UTC New e-mail: 6fbdd1ea-a4ed-4f8c-993e-e1ad178e1fe8
Llama.generate: 519 prefix-match hit, remaining 154 prompt tokens to eval
Llama.generate: 519 prefix-match hit, remaining 154 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   46514.71 ms /   251 tokens (  185.32 ms per token,     5.40 tokens per second)
llama_perf_context_print: prompt eval time =   46514.71 ms /   251 tokens (  185.32 ms per token,     5.40 tokens per second)
llama_perf_context_print:        eval time =     172.14 ms /     1 runs   (  172.14 ms per token,     5.81 tokens per second)
llama_perf_context_print:        eval time =     172.14 ms /     1 runs   (  172.14 ms per token,     5.81 tokens per second)
llama_perf_context_print:       total time =   46755.31 ms /   252 tokens
llama_perf_context_print:       total time =   46755.31 ms /   252 tokens
INFO 05/03/2025 11:34:06 PM UTC E-mail parsing finished: 73de52f1-df11-4d59-a800-44b50223e954
INFO 05/03/2025 11:34:06 PM UTC E-mail parsing finished: 73de52f1-df11-4d59-a800-44b50223e954
INFO 05/03/2025 11:34:06 PM UTC New e-mail: 2b91e698-d89c-41a3-932d-6b73a9a8e63f
INFO 05/03/2025 11:34:06 PM UTC New e-mail: 2b91e698-d89c-41a3-932d-6b73a9a8e63f
Llama.generate: 499 prefix-match hit, remaining 29 prompt tokens to eval
Llama.generate: 499 prefix-match hit, remaining 29 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   41195.41 ms /   154 tokens (  267.50 ms per token,     3.74 tokens per second)
llama_perf_context_print: prompt eval time =   41195.41 ms /   154 tokens (  267.50 ms per token,     3.74 tokens per second)
llama_perf_context_print:        eval time =     244.21 ms /     1 runs   (  244.21 ms per token,     4.09 tokens per second)
llama_perf_context_print:        eval time =     244.21 ms /     1 runs   (  244.21 ms per token,     4.09 tokens per second)
llama_perf_context_print:       total time =   41504.13 ms /   155 tokens
llama_perf_context_print:       total time =   41504.13 ms /   155 tokens
INFO 05/03/2025 11:34:13 PM UTC E-mail parsing finished: 6fbdd1ea-a4ed-4f8c-993e-e1ad178e1fe8
INFO 05/03/2025 11:34:13 PM UTC E-mail parsing finished: 6fbdd1ea-a4ed-4f8c-993e-e1ad178e1fe8
INFO 05/03/2025 11:34:13 PM UTC New e-mail: adda05c2-69c3-4f52-86a3-1b6fe8d26710
INFO 05/03/2025 11:34:13 PM UTC New e-mail: adda05c2-69c3-4f52-86a3-1b6fe8d26710
Llama.generate: 489 prefix-match hit, remaining 8625 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 8625 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =    9453.34 ms /    29 tokens (  325.98 ms per token,     3.07 tokens per second)
llama_perf_context_print: prompt eval time =    9453.34 ms /    29 tokens (  325.98 ms per token,     3.07 tokens per second)
llama_perf_context_print:        eval time =     238.85 ms /     1 runs   (  238.85 ms per token,     4.19 tokens per second)
llama_perf_context_print:        eval time =     238.85 ms /     1 runs   (  238.85 ms per token,     4.19 tokens per second)
llama_perf_context_print:       total time =    9733.72 ms /    30 tokens
llama_perf_context_print:       total time =    9733.72 ms /    30 tokens
INFO 05/03/2025 11:34:15 PM UTC E-mail parsing finished: 2b91e698-d89c-41a3-932d-6b73a9a8e63f
INFO 05/03/2025 11:34:15 PM UTC E-mail parsing finished: 2b91e698-d89c-41a3-932d-6b73a9a8e63f
INFO 05/03/2025 11:34:15 PM UTC New e-mail: 7eb2fa0c-f895-4324-a087-044f6a28db20
INFO 05/03/2025 11:34:15 PM UTC New e-mail: 7eb2fa0c-f895-4324-a087-044f6a28db20
Llama.generate: 489 prefix-match hit, remaining 899 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 899 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   98852.46 ms /   899 tokens (  109.96 ms per token,     9.09 tokens per second)
llama_perf_context_print: prompt eval time =   98852.46 ms /   899 tokens (  109.96 ms per token,     9.09 tokens per second)
llama_perf_context_print:        eval time =   52972.42 ms /   227 runs   (  233.36 ms per token,     4.29 tokens per second)
llama_perf_context_print:        eval time =   52972.42 ms /   227 runs   (  233.36 ms per token,     4.29 tokens per second)
llama_perf_context_print:       total time =  156940.96 ms /  1126 tokens
llama_perf_context_print:       total time =  156940.96 ms /  1126 tokens
INFO 05/03/2025 11:36:52 PM UTC E-mail parsing finished: 7eb2fa0c-f895-4324-a087-044f6a28db20
INFO 05/03/2025 11:36:52 PM UTC E-mail parsing finished: 7eb2fa0c-f895-4324-a087-044f6a28db20
INFO 05/03/2025 11:36:52 PM UTC New e-mail: db1de43b-436b-4b7b-b0ec-a7a64a9bcf79
INFO 05/03/2025 11:36:52 PM UTC New e-mail: db1de43b-436b-4b7b-b0ec-a7a64a9bcf79
Llama.generate: 538 prefix-match hit, remaining 423 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 423 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   50189.34 ms /   423 tokens (  118.65 ms per token,     8.43 tokens per second)
llama_perf_context_print: prompt eval time =   50189.34 ms /   423 tokens (  118.65 ms per token,     8.43 tokens per second)
llama_perf_context_print:        eval time =   20033.39 ms /    89 runs   (  225.09 ms per token,     4.44 tokens per second)
llama_perf_context_print:        eval time =   20033.39 ms /    89 runs   (  225.09 ms per token,     4.44 tokens per second)
llama_perf_context_print:       total time =   72469.98 ms /   512 tokens
llama_perf_context_print:       total time =   72469.98 ms /   512 tokens
INFO 05/03/2025 11:38:05 PM UTC E-mail parsing finished: db1de43b-436b-4b7b-b0ec-a7a64a9bcf79
INFO 05/03/2025 11:38:05 PM UTC E-mail parsing finished: db1de43b-436b-4b7b-b0ec-a7a64a9bcf79
INFO 05/03/2025 11:38:05 PM UTC New e-mail: 351d1ee9-e127-4564-95ae-44c9eb783dd7
INFO 05/03/2025 11:38:05 PM UTC New e-mail: 351d1ee9-e127-4564-95ae-44c9eb783dd7
Llama.generate: 538 prefix-match hit, remaining 494 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 494 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   54173.93 ms /   494 tokens (  109.66 ms per token,     9.12 tokens per second)
llama_perf_context_print: prompt eval time =   54173.93 ms /   494 tokens (  109.66 ms per token,     9.12 tokens per second)
llama_perf_context_print:        eval time =   16252.13 ms /    80 runs   (  203.15 ms per token,     4.92 tokens per second)
llama_perf_context_print:        eval time =   16252.13 ms /    80 runs   (  203.15 ms per token,     4.92 tokens per second)
llama_perf_context_print:       total time =   72301.88 ms /   574 tokens
llama_perf_context_print:       total time =   72301.88 ms /   574 tokens
INFO 05/03/2025 11:39:17 PM UTC E-mail parsing finished: 351d1ee9-e127-4564-95ae-44c9eb783dd7
INFO 05/03/2025 11:39:17 PM UTC E-mail parsing finished: 351d1ee9-e127-4564-95ae-44c9eb783dd7
INFO 05/03/2025 11:39:17 PM UTC New e-mail: 8c662d51-12b4-4cf2-bd92-9e82874f5a75
INFO 05/03/2025 11:39:17 PM UTC New e-mail: 8c662d51-12b4-4cf2-bd92-9e82874f5a75
Llama.generate: 489 prefix-match hit, remaining 1210 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1210 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  150758.91 ms /  1210 tokens (  124.59 ms per token,     8.03 tokens per second)
llama_perf_context_print: prompt eval time =  150758.91 ms /  1210 tokens (  124.59 ms per token,     8.03 tokens per second)
llama_perf_context_print:        eval time =     215.10 ms /     1 runs   (  215.10 ms per token,     4.65 tokens per second)
llama_perf_context_print:        eval time =     215.10 ms /     1 runs   (  215.10 ms per token,     4.65 tokens per second)
llama_perf_context_print:       total time =  151022.82 ms /  1211 tokens
llama_perf_context_print:       total time =  151022.82 ms /  1211 tokens
INFO 05/03/2025 11:41:48 PM UTC E-mail parsing finished: 8c662d51-12b4-4cf2-bd92-9e82874f5a75
INFO 05/03/2025 11:41:48 PM UTC E-mail parsing finished: 8c662d51-12b4-4cf2-bd92-9e82874f5a75
INFO 05/03/2025 11:41:48 PM UTC New e-mail: fd97b525-e954-4f90-9293-3215f5d875bb
INFO 05/03/2025 11:41:48 PM UTC New e-mail: fd97b525-e954-4f90-9293-3215f5d875bb
Llama.generate: 489 prefix-match hit, remaining 306 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 306 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   49013.51 ms /   306 tokens (  160.17 ms per token,     6.24 tokens per second)
llama_perf_context_print: prompt eval time =   49013.51 ms /   306 tokens (  160.17 ms per token,     6.24 tokens per second)
llama_perf_context_print:        eval time =     217.37 ms /     1 runs   (  217.37 ms per token,     4.60 tokens per second)
llama_perf_context_print:        eval time =     217.37 ms /     1 runs   (  217.37 ms per token,     4.60 tokens per second)
llama_perf_context_print:       total time =   49277.97 ms /   307 tokens
llama_perf_context_print:       total time =   49277.97 ms /   307 tokens
INFO 05/03/2025 11:42:38 PM UTC E-mail parsing finished: fd97b525-e954-4f90-9293-3215f5d875bb
INFO 05/03/2025 11:42:38 PM UTC E-mail parsing finished: fd97b525-e954-4f90-9293-3215f5d875bb
INFO 05/03/2025 11:42:38 PM UTC New e-mail: 2ac9332b-df57-4eb2-a0aa-06ed2223bce5
INFO 05/03/2025 11:42:38 PM UTC New e-mail: 2ac9332b-df57-4eb2-a0aa-06ed2223bce5
Llama.generate: 489 prefix-match hit, remaining 1419 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1419 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  154729.65 ms /  1419 tokens (  109.04 ms per token,     9.17 tokens per second)
llama_perf_context_print: prompt eval time =  154729.65 ms /  1419 tokens (  109.04 ms per token,     9.17 tokens per second)
llama_perf_context_print:        eval time =   17820.39 ms /    71 runs   (  250.99 ms per token,     3.98 tokens per second)
llama_perf_context_print:        eval time =   17820.39 ms /    71 runs   (  250.99 ms per token,     3.98 tokens per second)
llama_perf_context_print:       total time =  174099.38 ms /  1490 tokens
llama_perf_context_print:       total time =  174099.38 ms /  1490 tokens
INFO 05/03/2025 11:45:32 PM UTC E-mail parsing finished: 2ac9332b-df57-4eb2-a0aa-06ed2223bce5
INFO 05/03/2025 11:45:32 PM UTC E-mail parsing finished: 2ac9332b-df57-4eb2-a0aa-06ed2223bce5
INFO 05/03/2025 11:45:32 PM UTC New e-mail: 112cbe75-128d-4aa9-9a69-300bbde82533
INFO 05/03/2025 11:45:32 PM UTC New e-mail: 112cbe75-128d-4aa9-9a69-300bbde82533
Llama.generate: 489 prefix-match hit, remaining 1368 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1368 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  154185.61 ms /  1368 tokens (  112.71 ms per token,     8.87 tokens per second)
llama_perf_context_print: prompt eval time =  154185.61 ms /  1368 tokens (  112.71 ms per token,     8.87 tokens per second)
llama_perf_context_print:        eval time =   15854.24 ms /    71 runs   (  223.30 ms per token,     4.48 tokens per second)
llama_perf_context_print:        eval time =   15854.24 ms /    71 runs   (  223.30 ms per token,     4.48 tokens per second)
llama_perf_context_print:       total time =  171612.42 ms /  1439 tokens
llama_perf_context_print:       total time =  171612.42 ms /  1439 tokens
INFO 05/03/2025 11:48:23 PM UTC E-mail parsing finished: 112cbe75-128d-4aa9-9a69-300bbde82533
INFO 05/03/2025 11:48:23 PM UTC E-mail parsing finished: 112cbe75-128d-4aa9-9a69-300bbde82533
INFO 05/03/2025 11:48:23 PM UTC New e-mail: 18ea0c89-e059-4d72-8b20-83c8ad96e0ee
INFO 05/03/2025 11:48:23 PM UTC New e-mail: 18ea0c89-e059-4d72-8b20-83c8ad96e0ee
Llama.generate: 489 prefix-match hit, remaining 1314 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1314 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time = 1000835.84 ms /  8625 tokens (  116.04 ms per token,     8.62 tokens per second)
llama_perf_context_print: prompt eval time = 1000835.84 ms /  8625 tokens (  116.04 ms per token,     8.62 tokens per second)
llama_perf_context_print:        eval time =     359.66 ms /     1 runs   (  359.66 ms per token,     2.78 tokens per second)
llama_perf_context_print:        eval time =     359.66 ms /     1 runs   (  359.66 ms per token,     2.78 tokens per second)
llama_perf_context_print:       total time = 1001246.98 ms /  8626 tokens
llama_perf_context_print:       total time = 1001246.98 ms /  8626 tokens
INFO 05/03/2025 11:50:54 PM UTC E-mail parsing finished: adda05c2-69c3-4f52-86a3-1b6fe8d26710
INFO 05/03/2025 11:50:54 PM UTC E-mail parsing finished: adda05c2-69c3-4f52-86a3-1b6fe8d26710
INFO 05/03/2025 11:50:54 PM UTC New e-mail: 2460a225-efcb-4a9f-a46c-64759c9e80e4
INFO 05/03/2025 11:50:54 PM UTC New e-mail: 2460a225-efcb-4a9f-a46c-64759c9e80e4
Llama.generate: 489 prefix-match hit, remaining 534 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 534 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  155160.60 ms /  1314 tokens (  118.08 ms per token,     8.47 tokens per second)
llama_perf_context_print: prompt eval time =  155160.60 ms /  1314 tokens (  118.08 ms per token,     8.47 tokens per second)
llama_perf_context_print:        eval time =     238.14 ms /     1 runs   (  238.14 ms per token,     4.20 tokens per second)
llama_perf_context_print:        eval time =     238.14 ms /     1 runs   (  238.14 ms per token,     4.20 tokens per second)
llama_perf_context_print:       total time =  155440.72 ms /  1315 tokens
llama_perf_context_print:       total time =  155440.72 ms /  1315 tokens
INFO 05/03/2025 11:50:59 PM UTC E-mail parsing finished: 18ea0c89-e059-4d72-8b20-83c8ad96e0ee
INFO 05/03/2025 11:50:59 PM UTC E-mail parsing finished: 18ea0c89-e059-4d72-8b20-83c8ad96e0ee
INFO 05/03/2025 11:50:59 PM UTC New e-mail: 2eb94c8a-a0d3-4d42-ad30-a90713b411ba
INFO 05/03/2025 11:50:59 PM UTC New e-mail: 2eb94c8a-a0d3-4d42-ad30-a90713b411ba
Llama.generate: 489 prefix-match hit, remaining 333 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 333 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   48363.94 ms /   534 tokens (   90.57 ms per token,    11.04 tokens per second)
llama_perf_context_print: prompt eval time =   48363.94 ms /   534 tokens (   90.57 ms per token,    11.04 tokens per second)
llama_perf_context_print:        eval time =     298.86 ms /     1 runs   (  298.86 ms per token,     3.35 tokens per second)
llama_perf_context_print:        eval time =     298.86 ms /     1 runs   (  298.86 ms per token,     3.35 tokens per second)
llama_perf_context_print:       total time =   48728.11 ms /   535 tokens
llama_perf_context_print:       total time =   48728.11 ms /   535 tokens
INFO 05/03/2025 11:51:43 PM UTC E-mail parsing finished: 2460a225-efcb-4a9f-a46c-64759c9e80e4
INFO 05/03/2025 11:51:43 PM UTC E-mail parsing finished: 2460a225-efcb-4a9f-a46c-64759c9e80e4
INFO 05/03/2025 11:51:43 PM UTC New e-mail: 75f9992d-b43d-4714-b845-b25055f5b708
INFO 05/03/2025 11:51:43 PM UTC New e-mail: 75f9992d-b43d-4714-b845-b25055f5b708
Llama.generate: 489 prefix-match hit, remaining 994 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 994 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   48251.70 ms /   333 tokens (  144.90 ms per token,     6.90 tokens per second)
llama_perf_context_print: prompt eval time =   48251.70 ms /   333 tokens (  144.90 ms per token,     6.90 tokens per second)
llama_perf_context_print:        eval time =   16519.65 ms /    75 runs   (  220.26 ms per token,     4.54 tokens per second)
llama_perf_context_print:        eval time =   16519.65 ms /    75 runs   (  220.26 ms per token,     4.54 tokens per second)
llama_perf_context_print:       total time =   66641.65 ms /   408 tokens
llama_perf_context_print:       total time =   66641.65 ms /   408 tokens
INFO 05/03/2025 11:52:05 PM UTC E-mail parsing finished: 2eb94c8a-a0d3-4d42-ad30-a90713b411ba
INFO 05/03/2025 11:52:05 PM UTC E-mail parsing finished: 2eb94c8a-a0d3-4d42-ad30-a90713b411ba
INFO 05/03/2025 11:52:05 PM UTC New e-mail: 1bcec1f8-11bb-4941-b925-fbf05475a95e
INFO 05/03/2025 11:52:05 PM UTC New e-mail: 1bcec1f8-11bb-4941-b925-fbf05475a95e
Llama.generate: 536 prefix-match hit, remaining 258 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 258 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   47196.05 ms /   258 tokens (  182.93 ms per token,     5.47 tokens per second)
llama_perf_context_print: prompt eval time =   47196.05 ms /   258 tokens (  182.93 ms per token,     5.47 tokens per second)
llama_perf_context_print:        eval time =   17531.75 ms /    86 runs   (  203.86 ms per token,     4.91 tokens per second)
llama_perf_context_print:        eval time =   17531.75 ms /    86 runs   (  203.86 ms per token,     4.91 tokens per second)
llama_perf_context_print:       total time =   66979.72 ms /   344 tokens
llama_perf_context_print:       total time =   66979.72 ms /   344 tokens
INFO 05/03/2025 11:53:12 PM UTC E-mail parsing finished: 1bcec1f8-11bb-4941-b925-fbf05475a95e
INFO 05/03/2025 11:53:12 PM UTC E-mail parsing finished: 1bcec1f8-11bb-4941-b925-fbf05475a95e
INFO 05/03/2025 11:53:12 PM UTC New e-mail: 50b02d79-b9fe-476a-a936-dd58133b93e0
INFO 05/03/2025 11:53:12 PM UTC New e-mail: 50b02d79-b9fe-476a-a936-dd58133b93e0
Llama.generate: 538 prefix-match hit, remaining 469 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 469 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  120026.70 ms /   994 tokens (  120.75 ms per token,     8.28 tokens per second)
llama_perf_context_print: prompt eval time =  120026.70 ms /   994 tokens (  120.75 ms per token,     8.28 tokens per second)
llama_perf_context_print:        eval time =   22592.84 ms /    89 runs   (  253.85 ms per token,     3.94 tokens per second)
llama_perf_context_print:        eval time =   22592.84 ms /    89 runs   (  253.85 ms per token,     3.94 tokens per second)
llama_perf_context_print:       total time =  144614.30 ms /  1083 tokens
llama_perf_context_print:       total time =  144614.30 ms /  1083 tokens
INFO 05/03/2025 11:54:07 PM UTC E-mail parsing finished: 75f9992d-b43d-4714-b845-b25055f5b708
INFO 05/03/2025 11:54:07 PM UTC E-mail parsing finished: 75f9992d-b43d-4714-b845-b25055f5b708
INFO 05/03/2025 11:54:07 PM UTC New e-mail: 06631dcf-9977-4b83-bf68-da485b3a6e61
INFO 05/03/2025 11:54:07 PM UTC New e-mail: 06631dcf-9977-4b83-bf68-da485b3a6e61
Llama.generate: 489 prefix-match hit, remaining 838 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 838 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   63958.46 ms /   469 tokens (  136.37 ms per token,     7.33 tokens per second)
llama_perf_context_print: prompt eval time =   63958.46 ms /   469 tokens (  136.37 ms per token,     7.33 tokens per second)
llama_perf_context_print:        eval time =   29346.76 ms /   136 runs   (  215.78 ms per token,     4.63 tokens per second)
llama_perf_context_print:        eval time =   29346.76 ms /   136 runs   (  215.78 ms per token,     4.63 tokens per second)
llama_perf_context_print:       total time =   96621.60 ms /   605 tokens
llama_perf_context_print:       total time =   96621.60 ms /   605 tokens
INFO 05/03/2025 11:54:49 PM UTC E-mail parsing finished: 50b02d79-b9fe-476a-a936-dd58133b93e0
INFO 05/03/2025 11:54:49 PM UTC E-mail parsing finished: 50b02d79-b9fe-476a-a936-dd58133b93e0
INFO 05/03/2025 11:54:49 PM UTC New e-mail: 8239b1a5-60b9-464f-9495-1710fd74eceb
INFO 05/03/2025 11:54:49 PM UTC New e-mail: 8239b1a5-60b9-464f-9495-1710fd74eceb
Llama.generate: 489 prefix-match hit, remaining 780 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 780 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  115128.92 ms /   838 tokens (  137.39 ms per token,     7.28 tokens per second)
llama_perf_context_print: prompt eval time =  115128.92 ms /   838 tokens (  137.39 ms per token,     7.28 tokens per second)
llama_perf_context_print:        eval time =   36050.85 ms /   145 runs   (  248.63 ms per token,     4.02 tokens per second)
llama_perf_context_print:        eval time =   36050.85 ms /   145 runs   (  248.63 ms per token,     4.02 tokens per second)
llama_perf_context_print:       total time =  154538.99 ms /   983 tokens
llama_perf_context_print:       total time =  154538.99 ms /   983 tokens
INFO 05/03/2025 11:56:42 PM UTC E-mail parsing finished: 06631dcf-9977-4b83-bf68-da485b3a6e61
INFO 05/03/2025 11:56:42 PM UTC E-mail parsing finished: 06631dcf-9977-4b83-bf68-da485b3a6e61
INFO 05/03/2025 11:56:42 PM UTC New e-mail: 02101a04-7dc9-425b-937f-69371523a3e1
INFO 05/03/2025 11:56:42 PM UTC New e-mail: 02101a04-7dc9-425b-937f-69371523a3e1
Llama.generate: 557 prefix-match hit, remaining 680 prompt tokens to eval
Llama.generate: 557 prefix-match hit, remaining 680 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  118420.47 ms /   780 tokens (  151.82 ms per token,     6.59 tokens per second)
llama_perf_context_print: prompt eval time =  118420.47 ms /   780 tokens (  151.82 ms per token,     6.59 tokens per second)
llama_perf_context_print:        eval time =     222.80 ms /     1 runs   (  222.80 ms per token,     4.49 tokens per second)
llama_perf_context_print:        eval time =     222.80 ms /     1 runs   (  222.80 ms per token,     4.49 tokens per second)
llama_perf_context_print:       total time =  118689.87 ms /   781 tokens
llama_perf_context_print:       total time =  118689.87 ms /   781 tokens
INFO 05/03/2025 11:56:48 PM UTC E-mail parsing finished: 8239b1a5-60b9-464f-9495-1710fd74eceb
INFO 05/03/2025 11:56:48 PM UTC E-mail parsing finished: 8239b1a5-60b9-464f-9495-1710fd74eceb
INFO 05/03/2025 11:56:48 PM UTC New e-mail: 0c38374f-078f-4a4c-8bbf-2d01bfe680ff
INFO 05/03/2025 11:56:48 PM UTC New e-mail: 0c38374f-078f-4a4c-8bbf-2d01bfe680ff
Llama.generate: 489 prefix-match hit, remaining 521 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 521 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   58350.72 ms /   521 tokens (  112.00 ms per token,     8.93 tokens per second)
llama_perf_context_print: prompt eval time =   58350.72 ms /   521 tokens (  112.00 ms per token,     8.93 tokens per second)
llama_perf_context_print:        eval time =     199.45 ms /     1 runs   (  199.45 ms per token,     5.01 tokens per second)
llama_perf_context_print:        eval time =     199.45 ms /     1 runs   (  199.45 ms per token,     5.01 tokens per second)
llama_perf_context_print:       total time =   58638.75 ms /   522 tokens
llama_perf_context_print:       total time =   58638.75 ms /   522 tokens
INFO 05/03/2025 11:57:46 PM UTC E-mail parsing finished: 0c38374f-078f-4a4c-8bbf-2d01bfe680ff
INFO 05/03/2025 11:57:46 PM UTC E-mail parsing finished: 0c38374f-078f-4a4c-8bbf-2d01bfe680ff
INFO 05/03/2025 11:57:46 PM UTC New e-mail: 45359ad9-1661-4787-a123-d6f97cc14206
INFO 05/03/2025 11:57:46 PM UTC New e-mail: 45359ad9-1661-4787-a123-d6f97cc14206
Llama.generate: 489 prefix-match hit, remaining 428 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 428 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   95672.15 ms /   680 tokens (  140.69 ms per token,     7.11 tokens per second)
llama_perf_context_print: prompt eval time =   95672.15 ms /   680 tokens (  140.69 ms per token,     7.11 tokens per second)
llama_perf_context_print:        eval time =     253.22 ms /     1 runs   (  253.22 ms per token,     3.95 tokens per second)
llama_perf_context_print:        eval time =     253.22 ms /     1 runs   (  253.22 ms per token,     3.95 tokens per second)
llama_perf_context_print:       total time =   95999.74 ms /   681 tokens
llama_perf_context_print:       total time =   95999.74 ms /   681 tokens
INFO 05/03/2025 11:58:18 PM UTC E-mail parsing finished: 02101a04-7dc9-425b-937f-69371523a3e1
INFO 05/03/2025 11:58:18 PM UTC E-mail parsing finished: 02101a04-7dc9-425b-937f-69371523a3e1
INFO 05/03/2025 11:58:18 PM UTC New e-mail: bb8966a5-e2c6-4667-a488-d99fb28d0415
INFO 05/03/2025 11:58:18 PM UTC New e-mail: bb8966a5-e2c6-4667-a488-d99fb28d0415
Llama.generate: 489 prefix-match hit, remaining 385 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 385 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   49567.60 ms /   428 tokens (  115.81 ms per token,     8.63 tokens per second)
llama_perf_context_print: prompt eval time =   49567.60 ms /   428 tokens (  115.81 ms per token,     8.63 tokens per second)
llama_perf_context_print:        eval time =   43955.05 ms /   216 runs   (  203.50 ms per token,     4.91 tokens per second)
llama_perf_context_print:        eval time =   43955.05 ms /   216 runs   (  203.50 ms per token,     4.91 tokens per second)
llama_perf_context_print:       total time =   98978.32 ms /   644 tokens
llama_perf_context_print:       total time =   98978.32 ms /   644 tokens
INFO 05/03/2025 11:59:25 PM UTC E-mail parsing finished: 45359ad9-1661-4787-a123-d6f97cc14206
INFO 05/03/2025 11:59:25 PM UTC E-mail parsing finished: 45359ad9-1661-4787-a123-d6f97cc14206
INFO 05/03/2025 11:59:25 PM UTC New e-mail: 000138e5-06f4-4db7-86d3-1f75b0a5e90f
INFO 05/03/2025 11:59:25 PM UTC New e-mail: 000138e5-06f4-4db7-86d3-1f75b0a5e90f
Llama.generate: 489 prefix-match hit, remaining 417 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 417 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   61962.95 ms /   385 tokens (  160.94 ms per token,     6.21 tokens per second)
llama_perf_context_print: prompt eval time =   61962.95 ms /   385 tokens (  160.94 ms per token,     6.21 tokens per second)
llama_perf_context_print:        eval time =   22189.26 ms /    99 runs   (  224.13 ms per token,     4.46 tokens per second)
llama_perf_context_print:        eval time =   22189.26 ms /    99 runs   (  224.13 ms per token,     4.46 tokens per second)
llama_perf_context_print:       total time =   86272.72 ms /   484 tokens
llama_perf_context_print:       total time =   86272.72 ms /   484 tokens
INFO 05/03/2025 11:59:44 PM UTC E-mail parsing finished: bb8966a5-e2c6-4667-a488-d99fb28d0415
INFO 05/03/2025 11:59:44 PM UTC E-mail parsing finished: bb8966a5-e2c6-4667-a488-d99fb28d0415
INFO 05/03/2025 11:59:44 PM UTC New e-mail: fe47f780-9087-43aa-938e-7d707f85523e
INFO 05/03/2025 11:59:44 PM UTC New e-mail: fe47f780-9087-43aa-938e-7d707f85523e
Llama.generate: 489 prefix-match hit, remaining 319 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 319 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   60095.47 ms /   417 tokens (  144.11 ms per token,     6.94 tokens per second)
llama_perf_context_print: prompt eval time =   60095.47 ms /   417 tokens (  144.11 ms per token,     6.94 tokens per second)
llama_perf_context_print:        eval time =     257.67 ms /     1 runs   (  257.67 ms per token,     3.88 tokens per second)
llama_perf_context_print:        eval time =     257.67 ms /     1 runs   (  257.67 ms per token,     3.88 tokens per second)
llama_perf_context_print:       total time =   60397.87 ms /   418 tokens
llama_perf_context_print:       total time =   60397.87 ms /   418 tokens
INFO 05/04/2025 12:00:26 AM UTC E-mail parsing finished: 000138e5-06f4-4db7-86d3-1f75b0a5e90f
INFO 05/04/2025 12:00:26 AM UTC E-mail parsing finished: 000138e5-06f4-4db7-86d3-1f75b0a5e90f
INFO 05/04/2025 12:00:26 AM UTC New e-mail: 595b3048-9005-4b9a-b4ab-40565e2e26fd
INFO 05/04/2025 12:00:26 AM UTC New e-mail: 595b3048-9005-4b9a-b4ab-40565e2e26fd
Llama.generate: 489 prefix-match hit, remaining 447 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 447 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   47103.94 ms /   319 tokens (  147.66 ms per token,     6.77 tokens per second)
llama_perf_context_print: prompt eval time =   47103.94 ms /   319 tokens (  147.66 ms per token,     6.77 tokens per second)
llama_perf_context_print:        eval time =   10289.78 ms /    50 runs   (  205.80 ms per token,     4.86 tokens per second)
llama_perf_context_print:        eval time =   10289.78 ms /    50 runs   (  205.80 ms per token,     4.86 tokens per second)
llama_perf_context_print:       total time =   58561.89 ms /   369 tokens
llama_perf_context_print:       total time =   58561.89 ms /   369 tokens
INFO 05/04/2025 12:00:43 AM UTC E-mail parsing finished: fe47f780-9087-43aa-938e-7d707f85523e
INFO 05/04/2025 12:00:43 AM UTC E-mail parsing finished: fe47f780-9087-43aa-938e-7d707f85523e
WARNING 05/04/2025 12:00:43 AM UTC Events from an email rejected due to data validation errors
WARNING 05/04/2025 12:00:43 AM UTC Events from an email rejected due to data validation errors
Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 151, in _on_new_events
  File "/app/modules/validator.py", line 151, in _on_new_events
    data: NewEvents = NewEvents.model_validate_json(body)
    data: NewEvents = NewEvents.model_validate_json(body)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
events.0.start_date
events.0.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
INFO 05/04/2025 12:00:43 AM UTC New e-mail: 7ecbadf3-6299-4199-834a-71aabc39e451
INFO 05/04/2025 12:00:43 AM UTC New e-mail: 7ecbadf3-6299-4199-834a-71aabc39e451
Llama.generate: 489 prefix-match hit, remaining 298 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 298 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   54665.03 ms /   447 tokens (  122.29 ms per token,     8.18 tokens per second)
llama_perf_context_print: prompt eval time =   54665.03 ms /   447 tokens (  122.29 ms per token,     8.18 tokens per second)
llama_perf_context_print:        eval time =     224.12 ms /     1 runs   (  224.12 ms per token,     4.46 tokens per second)
llama_perf_context_print:        eval time =     224.12 ms /     1 runs   (  224.12 ms per token,     4.46 tokens per second)
llama_perf_context_print:       total time =   54927.17 ms /   448 tokens
llama_perf_context_print:       total time =   54927.17 ms /   448 tokens
INFO 05/04/2025 12:01:21 AM UTC E-mail parsing finished: 595b3048-9005-4b9a-b4ab-40565e2e26fd
INFO 05/04/2025 12:01:21 AM UTC E-mail parsing finished: 595b3048-9005-4b9a-b4ab-40565e2e26fd
INFO 05/04/2025 12:01:21 AM UTC New e-mail: 4a02f1f0-5259-4f46-8942-f5b4cc0c13a2
INFO 05/04/2025 12:01:21 AM UTC New e-mail: 4a02f1f0-5259-4f46-8942-f5b4cc0c13a2
Llama.generate: 489 prefix-match hit, remaining 341 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 341 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   46505.27 ms /   298 tokens (  156.06 ms per token,     6.41 tokens per second)
llama_perf_context_print: prompt eval time =   46505.27 ms /   298 tokens (  156.06 ms per token,     6.41 tokens per second)
llama_perf_context_print:        eval time =   22200.69 ms /    97 runs   (  228.87 ms per token,     4.37 tokens per second)
llama_perf_context_print:        eval time =   22200.69 ms /    97 runs   (  228.87 ms per token,     4.37 tokens per second)
llama_perf_context_print:       total time =   70957.46 ms /   395 tokens
llama_perf_context_print:       total time =   70957.46 ms /   395 tokens
INFO 05/04/2025 12:01:54 AM UTC E-mail parsing finished: 7ecbadf3-6299-4199-834a-71aabc39e451
INFO 05/04/2025 12:01:54 AM UTC E-mail parsing finished: 7ecbadf3-6299-4199-834a-71aabc39e451
INFO 05/04/2025 12:01:54 AM UTC New e-mail: 1123b3e0-523c-4a44-9e9c-3a6a13b70508
INFO 05/04/2025 12:01:54 AM UTC New e-mail: 1123b3e0-523c-4a44-9e9c-3a6a13b70508
Llama.generate: 489 prefix-match hit, remaining 109 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 109 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   61913.93 ms /   341 tokens (  181.57 ms per token,     5.51 tokens per second)
llama_perf_context_print: prompt eval time =   61913.93 ms /   341 tokens (  181.57 ms per token,     5.51 tokens per second)
llama_perf_context_print:        eval time =     223.42 ms /     1 runs   (  223.42 ms per token,     4.48 tokens per second)
llama_perf_context_print:        eval time =     223.42 ms /     1 runs   (  223.42 ms per token,     4.48 tokens per second)
llama_perf_context_print:       total time =   62177.20 ms /   342 tokens
llama_perf_context_print:       total time =   62177.20 ms /   342 tokens
INFO 05/04/2025 12:02:23 AM UTC E-mail parsing finished: 4a02f1f0-5259-4f46-8942-f5b4cc0c13a2
INFO 05/04/2025 12:02:23 AM UTC E-mail parsing finished: 4a02f1f0-5259-4f46-8942-f5b4cc0c13a2
INFO 05/04/2025 12:02:23 AM UTC New e-mail: fd3b75d6-6a93-4fc6-b05f-91ae86674b66
INFO 05/04/2025 12:02:23 AM UTC New e-mail: fd3b75d6-6a93-4fc6-b05f-91ae86674b66
Llama.generate: 489 prefix-match hit, remaining 533 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 533 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   43103.42 ms /   109 tokens (  395.44 ms per token,     2.53 tokens per second)
llama_perf_context_print: prompt eval time =   43103.42 ms /   109 tokens (  395.44 ms per token,     2.53 tokens per second)
llama_perf_context_print:        eval time =     268.56 ms /     1 runs   (  268.56 ms per token,     3.72 tokens per second)
llama_perf_context_print:        eval time =     268.56 ms /     1 runs   (  268.56 ms per token,     3.72 tokens per second)
llama_perf_context_print:       total time =   43439.27 ms /   110 tokens
llama_perf_context_print:       total time =   43439.27 ms /   110 tokens
INFO 05/04/2025 12:02:37 AM UTC E-mail parsing finished: 1123b3e0-523c-4a44-9e9c-3a6a13b70508
INFO 05/04/2025 12:02:37 AM UTC E-mail parsing finished: 1123b3e0-523c-4a44-9e9c-3a6a13b70508
INFO 05/04/2025 12:02:37 AM UTC New e-mail: 5ca02a05-0a83-4007-bff0-3d9a2d86db5a
INFO 05/04/2025 12:02:37 AM UTC New e-mail: 5ca02a05-0a83-4007-bff0-3d9a2d86db5a
Llama.generate: 489 prefix-match hit, remaining 387 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 387 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   61013.03 ms /   533 tokens (  114.47 ms per token,     8.74 tokens per second)
llama_perf_context_print: prompt eval time =   61013.03 ms /   533 tokens (  114.47 ms per token,     8.74 tokens per second)
llama_perf_context_print:        eval time =     205.56 ms /     1 runs   (  205.56 ms per token,     4.86 tokens per second)
llama_perf_context_print:        eval time =     205.56 ms /     1 runs   (  205.56 ms per token,     4.86 tokens per second)
llama_perf_context_print:       total time =   61256.00 ms /   534 tokens
llama_perf_context_print:       total time =   61256.00 ms /   534 tokens
INFO 05/04/2025 12:03:24 AM UTC E-mail parsing finished: fd3b75d6-6a93-4fc6-b05f-91ae86674b66
INFO 05/04/2025 12:03:24 AM UTC E-mail parsing finished: fd3b75d6-6a93-4fc6-b05f-91ae86674b66
INFO 05/04/2025 12:03:24 AM UTC New e-mail: d93b69b8-67c9-4eea-a9d8-191a2f0b5940
INFO 05/04/2025 12:03:24 AM UTC New e-mail: d93b69b8-67c9-4eea-a9d8-191a2f0b5940
Llama.generate: 538 prefix-match hit, remaining 462 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 462 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   45477.31 ms /   387 tokens (  117.51 ms per token,     8.51 tokens per second)
llama_perf_context_print: prompt eval time =   45477.31 ms /   387 tokens (  117.51 ms per token,     8.51 tokens per second)
llama_perf_context_print:        eval time =   18373.49 ms /    77 runs   (  238.62 ms per token,     4.19 tokens per second)
llama_perf_context_print:        eval time =   18373.49 ms /    77 runs   (  238.62 ms per token,     4.19 tokens per second)
llama_perf_context_print:       total time =   65683.67 ms /   464 tokens
llama_perf_context_print:       total time =   65683.67 ms /   464 tokens
INFO 05/04/2025 12:03:43 AM UTC E-mail parsing finished: 5ca02a05-0a83-4007-bff0-3d9a2d86db5a
INFO 05/04/2025 12:03:43 AM UTC E-mail parsing finished: 5ca02a05-0a83-4007-bff0-3d9a2d86db5a
INFO 05/04/2025 12:03:43 AM UTC New e-mail: f369aad8-9ca8-4c4f-b3ba-59df814fa2ed
INFO 05/04/2025 12:03:43 AM UTC New e-mail: f369aad8-9ca8-4c4f-b3ba-59df814fa2ed
Llama.generate: 489 prefix-match hit, remaining 302 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 302 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   59154.21 ms /   462 tokens (  128.04 ms per token,     7.81 tokens per second)
llama_perf_context_print: prompt eval time =   59154.21 ms /   462 tokens (  128.04 ms per token,     7.81 tokens per second)
llama_perf_context_print:        eval time =     220.53 ms /     1 runs   (  220.53 ms per token,     4.53 tokens per second)
llama_perf_context_print:        eval time =     220.53 ms /     1 runs   (  220.53 ms per token,     4.53 tokens per second)
llama_perf_context_print:       total time =   59419.94 ms /   463 tokens
llama_perf_context_print:       total time =   59419.94 ms /   463 tokens
INFO 05/04/2025 12:04:24 AM UTC E-mail parsing finished: d93b69b8-67c9-4eea-a9d8-191a2f0b5940
INFO 05/04/2025 12:04:24 AM UTC E-mail parsing finished: d93b69b8-67c9-4eea-a9d8-191a2f0b5940
INFO 05/04/2025 12:04:24 AM UTC New e-mail: a29957e0-456c-4160-985c-ed34dd4ddcaa
INFO 05/04/2025 12:04:24 AM UTC New e-mail: a29957e0-456c-4160-985c-ed34dd4ddcaa
Llama.generate: 489 prefix-match hit, remaining 388 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 388 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   47829.09 ms /   302 tokens (  158.37 ms per token,     6.31 tokens per second)
llama_perf_context_print: prompt eval time =   47829.09 ms /   302 tokens (  158.37 ms per token,     6.31 tokens per second)
llama_perf_context_print:        eval time =   19621.51 ms /    85 runs   (  230.84 ms per token,     4.33 tokens per second)
llama_perf_context_print:        eval time =   19621.51 ms /    85 runs   (  230.84 ms per token,     4.33 tokens per second)
llama_perf_context_print:       total time =   69437.30 ms /   387 tokens
llama_perf_context_print:       total time =   69437.30 ms /   387 tokens
INFO 05/04/2025 12:04:52 AM UTC E-mail parsing finished: f369aad8-9ca8-4c4f-b3ba-59df814fa2ed
INFO 05/04/2025 12:04:52 AM UTC E-mail parsing finished: f369aad8-9ca8-4c4f-b3ba-59df814fa2ed
INFO 05/04/2025 12:04:52 AM UTC New e-mail: d8d7efae-95fb-473f-b7ed-c3a5f46ec4c6
INFO 05/04/2025 12:04:52 AM UTC New e-mail: d8d7efae-95fb-473f-b7ed-c3a5f46ec4c6
Llama.generate: 489 prefix-match hit, remaining 855 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 855 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   57912.95 ms /   388 tokens (  149.26 ms per token,     6.70 tokens per second)
llama_perf_context_print: prompt eval time =   57912.95 ms /   388 tokens (  149.26 ms per token,     6.70 tokens per second)
llama_perf_context_print:        eval time =   22273.77 ms /   106 runs   (  210.13 ms per token,     4.76 tokens per second)
llama_perf_context_print:        eval time =   22273.77 ms /   106 runs   (  210.13 ms per token,     4.76 tokens per second)
llama_perf_context_print:       total time =   82909.34 ms /   494 tokens
llama_perf_context_print:       total time =   82909.34 ms /   494 tokens
INFO 05/04/2025 12:05:47 AM UTC E-mail parsing finished: a29957e0-456c-4160-985c-ed34dd4ddcaa
INFO 05/04/2025 12:05:47 AM UTC E-mail parsing finished: a29957e0-456c-4160-985c-ed34dd4ddcaa
INFO 05/04/2025 12:05:47 AM UTC New e-mail: 60ec7c20-67fc-409d-bc24-6aeed8e2531c
INFO 05/04/2025 12:05:47 AM UTC New e-mail: 60ec7c20-67fc-409d-bc24-6aeed8e2531c
Llama.generate: 489 prefix-match hit, remaining 745 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 745 prompt tokens to eval
ERROR 05/04/2025 12:05:47 AM UTC Unknown exception occurred
ERROR 05/04/2025 12:05:47 AM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '2031-5' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '2031-5' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '2031-5' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '2031-5' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 2031, 'tag_id': 5}, {'event_id': 2031, 'tag_id': 6}, {'event_id': 2031, 'tag_id': 1}, {'event_id': 2031, 'tag_id': 5}]]
[parameters: [{'event_id': 2031, 'tag_id': 5}, {'event_id': 2031, 'tag_id': 6}, {'event_id': 2031, 'tag_id': 1}, {'event_id': 2031, 'tag_id': 5}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  107221.87 ms /   855 tokens (  125.41 ms per token,     7.97 tokens per second)
llama_perf_context_print: prompt eval time =  107221.87 ms /   855 tokens (  125.41 ms per token,     7.97 tokens per second)
llama_perf_context_print:        eval time =     203.31 ms /     1 runs   (  203.31 ms per token,     4.92 tokens per second)
llama_perf_context_print:        eval time =     203.31 ms /     1 runs   (  203.31 ms per token,     4.92 tokens per second)
llama_perf_context_print:       total time =  107530.29 ms /   856 tokens
llama_perf_context_print:       total time =  107530.29 ms /   856 tokens
INFO 05/04/2025 12:06:40 AM UTC E-mail parsing finished: d8d7efae-95fb-473f-b7ed-c3a5f46ec4c6
INFO 05/04/2025 12:06:40 AM UTC E-mail parsing finished: d8d7efae-95fb-473f-b7ed-c3a5f46ec4c6
INFO 05/04/2025 12:06:40 AM UTC New e-mail: 4a0688e5-b7d1-4f9d-a0ec-f475ef1527f4
INFO 05/04/2025 12:06:40 AM UTC New e-mail: 4a0688e5-b7d1-4f9d-a0ec-f475ef1527f4
Llama.generate: 534 prefix-match hit, remaining 456 prompt tokens to eval
Llama.generate: 534 prefix-match hit, remaining 456 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   99065.44 ms /   745 tokens (  132.97 ms per token,     7.52 tokens per second)
llama_perf_context_print: prompt eval time =   99065.44 ms /   745 tokens (  132.97 ms per token,     7.52 tokens per second)
llama_perf_context_print:        eval time =     191.17 ms /     1 runs   (  191.17 ms per token,     5.23 tokens per second)
llama_perf_context_print:        eval time =     191.17 ms /     1 runs   (  191.17 ms per token,     5.23 tokens per second)
llama_perf_context_print:       total time =   99314.53 ms /   746 tokens
llama_perf_context_print:       total time =   99314.53 ms /   746 tokens
INFO 05/04/2025 12:07:26 AM UTC E-mail parsing finished: 60ec7c20-67fc-409d-bc24-6aeed8e2531c
INFO 05/04/2025 12:07:26 AM UTC E-mail parsing finished: 60ec7c20-67fc-409d-bc24-6aeed8e2531c
INFO 05/04/2025 12:07:26 AM UTC New e-mail: 0a112284-4511-4b92-950c-4e01bc951f28
INFO 05/04/2025 12:07:26 AM UTC New e-mail: 0a112284-4511-4b92-950c-4e01bc951f28
Llama.generate: 489 prefix-match hit, remaining 252 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 252 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   49128.48 ms /   456 tokens (  107.74 ms per token,     9.28 tokens per second)
llama_perf_context_print: prompt eval time =   49128.48 ms /   456 tokens (  107.74 ms per token,     9.28 tokens per second)
llama_perf_context_print:        eval time =     297.31 ms /     1 runs   (  297.31 ms per token,     3.36 tokens per second)
llama_perf_context_print:        eval time =     297.31 ms /     1 runs   (  297.31 ms per token,     3.36 tokens per second)
llama_perf_context_print:       total time =   49488.65 ms /   457 tokens
llama_perf_context_print:       total time =   49488.65 ms /   457 tokens
INFO 05/04/2025 12:07:30 AM UTC E-mail parsing finished: 4a0688e5-b7d1-4f9d-a0ec-f475ef1527f4
INFO 05/04/2025 12:07:30 AM UTC E-mail parsing finished: 4a0688e5-b7d1-4f9d-a0ec-f475ef1527f4
INFO 05/04/2025 12:07:30 AM UTC New e-mail: 96d25c53-9dde-4371-8b79-1ec570566bbc
INFO 05/04/2025 12:07:30 AM UTC New e-mail: 96d25c53-9dde-4371-8b79-1ec570566bbc
Llama.generate: 489 prefix-match hit, remaining 545 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 545 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   44378.83 ms /   252 tokens (  176.11 ms per token,     5.68 tokens per second)
llama_perf_context_print: prompt eval time =   44378.83 ms /   252 tokens (  176.11 ms per token,     5.68 tokens per second)
llama_perf_context_print:        eval time =     243.67 ms /     1 runs   (  243.67 ms per token,     4.10 tokens per second)
llama_perf_context_print:        eval time =     243.67 ms /     1 runs   (  243.67 ms per token,     4.10 tokens per second)
llama_perf_context_print:       total time =   44667.51 ms /   253 tokens
llama_perf_context_print:       total time =   44667.51 ms /   253 tokens
INFO 05/04/2025 12:08:11 AM UTC E-mail parsing finished: 0a112284-4511-4b92-950c-4e01bc951f28
INFO 05/04/2025 12:08:11 AM UTC E-mail parsing finished: 0a112284-4511-4b92-950c-4e01bc951f28
INFO 05/04/2025 12:08:11 AM UTC New e-mail: dae28d2a-39c4-462a-9b70-f75017bf8469
INFO 05/04/2025 12:08:11 AM UTC New e-mail: dae28d2a-39c4-462a-9b70-f75017bf8469
Llama.generate: 489 prefix-match hit, remaining 9483 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 9483 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   83283.12 ms /   545 tokens (  152.81 ms per token,     6.54 tokens per second)
llama_perf_context_print: prompt eval time =   83283.12 ms /   545 tokens (  152.81 ms per token,     6.54 tokens per second)
llama_perf_context_print:        eval time =   23326.96 ms /    99 runs   (  235.63 ms per token,     4.24 tokens per second)
llama_perf_context_print:        eval time =   23326.96 ms /    99 runs   (  235.63 ms per token,     4.24 tokens per second)
llama_perf_context_print:       total time =  108945.47 ms /   644 tokens
llama_perf_context_print:       total time =  108945.47 ms /   644 tokens
INFO 05/04/2025 12:09:18 AM UTC E-mail parsing finished: 96d25c53-9dde-4371-8b79-1ec570566bbc
INFO 05/04/2025 12:09:18 AM UTC E-mail parsing finished: 96d25c53-9dde-4371-8b79-1ec570566bbc
INFO 05/04/2025 12:09:18 AM UTC New e-mail: 136374d9-2a05-4907-a0ae-45d512364565
INFO 05/04/2025 12:09:18 AM UTC New e-mail: 136374d9-2a05-4907-a0ae-45d512364565
Llama.generate: 489 prefix-match hit, remaining 403 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 403 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   50302.37 ms /   403 tokens (  124.82 ms per token,     8.01 tokens per second)
llama_perf_context_print: prompt eval time =   50302.37 ms /   403 tokens (  124.82 ms per token,     8.01 tokens per second)
llama_perf_context_print:        eval time =     224.05 ms /     1 runs   (  224.05 ms per token,     4.46 tokens per second)
llama_perf_context_print:        eval time =     224.05 ms /     1 runs   (  224.05 ms per token,     4.46 tokens per second)
llama_perf_context_print:       total time =   50608.95 ms /   404 tokens
llama_perf_context_print:       total time =   50608.95 ms /   404 tokens
INFO 05/04/2025 12:10:09 AM UTC E-mail parsing finished: 136374d9-2a05-4907-a0ae-45d512364565
INFO 05/04/2025 12:10:09 AM UTC E-mail parsing finished: 136374d9-2a05-4907-a0ae-45d512364565
INFO 05/04/2025 12:10:09 AM UTC New e-mail: 7f696a4e-4d35-4e43-9546-bdd433fe3c8f
INFO 05/04/2025 12:10:09 AM UTC New e-mail: 7f696a4e-4d35-4e43-9546-bdd433fe3c8f
Llama.generate: 489 prefix-match hit, remaining 314 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 314 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   45751.63 ms /   314 tokens (  145.71 ms per token,     6.86 tokens per second)
llama_perf_context_print: prompt eval time =   45751.63 ms /   314 tokens (  145.71 ms per token,     6.86 tokens per second)
llama_perf_context_print:        eval time =     268.96 ms /     1 runs   (  268.96 ms per token,     3.72 tokens per second)
llama_perf_context_print:        eval time =     268.96 ms /     1 runs   (  268.96 ms per token,     3.72 tokens per second)
llama_perf_context_print:       total time =   46095.02 ms /   315 tokens
llama_perf_context_print:       total time =   46095.02 ms /   315 tokens
INFO 05/04/2025 12:10:55 AM UTC E-mail parsing finished: 7f696a4e-4d35-4e43-9546-bdd433fe3c8f
INFO 05/04/2025 12:10:55 AM UTC E-mail parsing finished: 7f696a4e-4d35-4e43-9546-bdd433fe3c8f
INFO 05/04/2025 12:10:55 AM UTC New e-mail: be114a0b-5d46-45ae-b6df-2933979cecf1
INFO 05/04/2025 12:10:55 AM UTC New e-mail: be114a0b-5d46-45ae-b6df-2933979cecf1
Llama.generate: 489 prefix-match hit, remaining 177 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 177 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   44040.56 ms /   177 tokens (  248.82 ms per token,     4.02 tokens per second)
llama_perf_context_print: prompt eval time =   44040.56 ms /   177 tokens (  248.82 ms per token,     4.02 tokens per second)
llama_perf_context_print:        eval time =     268.34 ms /     1 runs   (  268.34 ms per token,     3.73 tokens per second)
llama_perf_context_print:        eval time =     268.34 ms /     1 runs   (  268.34 ms per token,     3.73 tokens per second)
llama_perf_context_print:       total time =   44374.26 ms /   178 tokens
llama_perf_context_print:       total time =   44374.26 ms /   178 tokens
INFO 05/04/2025 12:11:40 AM UTC E-mail parsing finished: be114a0b-5d46-45ae-b6df-2933979cecf1
INFO 05/04/2025 12:11:40 AM UTC E-mail parsing finished: be114a0b-5d46-45ae-b6df-2933979cecf1
INFO 05/04/2025 12:11:40 AM UTC New e-mail: 1f5f398d-25c8-4047-9337-3636c1431003
INFO 05/04/2025 12:11:40 AM UTC New e-mail: 1f5f398d-25c8-4047-9337-3636c1431003
Llama.generate: 489 prefix-match hit, remaining 198 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 198 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   41891.30 ms /   198 tokens (  211.57 ms per token,     4.73 tokens per second)
llama_perf_context_print: prompt eval time =   41891.30 ms /   198 tokens (  211.57 ms per token,     4.73 tokens per second)
llama_perf_context_print:        eval time =     301.75 ms /     1 runs   (  301.75 ms per token,     3.31 tokens per second)
llama_perf_context_print:        eval time =     301.75 ms /     1 runs   (  301.75 ms per token,     3.31 tokens per second)
llama_perf_context_print:       total time =   42265.92 ms /   199 tokens
llama_perf_context_print:       total time =   42265.92 ms /   199 tokens
INFO 05/04/2025 12:12:22 AM UTC E-mail parsing finished: 1f5f398d-25c8-4047-9337-3636c1431003
INFO 05/04/2025 12:12:22 AM UTC E-mail parsing finished: 1f5f398d-25c8-4047-9337-3636c1431003
INFO 05/04/2025 12:12:22 AM UTC New e-mail: 7c34b291-f800-4765-9e57-61809fab32a7
INFO 05/04/2025 12:12:22 AM UTC New e-mail: 7c34b291-f800-4765-9e57-61809fab32a7
Llama.generate: 489 prefix-match hit, remaining 584 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 584 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   91967.73 ms /   584 tokens (  157.48 ms per token,     6.35 tokens per second)
llama_perf_context_print: prompt eval time =   91967.73 ms /   584 tokens (  157.48 ms per token,     6.35 tokens per second)
llama_perf_context_print:        eval time =   66363.78 ms /   246 runs   (  269.77 ms per token,     3.71 tokens per second)
llama_perf_context_print:        eval time =   66363.78 ms /   246 runs   (  269.77 ms per token,     3.71 tokens per second)
llama_perf_context_print:       total time =  163495.69 ms /   830 tokens
llama_perf_context_print:       total time =  163495.69 ms /   830 tokens
INFO 05/04/2025 12:15:05 AM UTC E-mail parsing finished: 7c34b291-f800-4765-9e57-61809fab32a7
INFO 05/04/2025 12:15:05 AM UTC E-mail parsing finished: 7c34b291-f800-4765-9e57-61809fab32a7
INFO 05/04/2025 12:15:05 AM UTC New e-mail: 1c6fce93-2352-490d-beef-16135f283c6e
INFO 05/04/2025 12:15:05 AM UTC New e-mail: 1c6fce93-2352-490d-beef-16135f283c6e
Llama.generate: 538 prefix-match hit, remaining 278 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 278 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   47188.80 ms /   278 tokens (  169.74 ms per token,     5.89 tokens per second)
llama_perf_context_print: prompt eval time =   47188.80 ms /   278 tokens (  169.74 ms per token,     5.89 tokens per second)
llama_perf_context_print:        eval time =     264.24 ms /     1 runs   (  264.24 ms per token,     3.78 tokens per second)
llama_perf_context_print:        eval time =     264.24 ms /     1 runs   (  264.24 ms per token,     3.78 tokens per second)
llama_perf_context_print:       total time =   47515.42 ms /   279 tokens
llama_perf_context_print:       total time =   47515.42 ms /   279 tokens
INFO 05/04/2025 12:15:53 AM UTC E-mail parsing finished: 1c6fce93-2352-490d-beef-16135f283c6e
INFO 05/04/2025 12:15:53 AM UTC E-mail parsing finished: 1c6fce93-2352-490d-beef-16135f283c6e
INFO 05/04/2025 12:15:53 AM UTC New e-mail: 251fe82e-08d3-4cdf-9e52-9c933b17496c
INFO 05/04/2025 12:15:53 AM UTC New e-mail: 251fe82e-08d3-4cdf-9e52-9c933b17496c
Llama.generate: 489 prefix-match hit, remaining 198 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 198 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   46228.86 ms /   198 tokens (  233.48 ms per token,     4.28 tokens per second)
llama_perf_context_print: prompt eval time =   46228.86 ms /   198 tokens (  233.48 ms per token,     4.28 tokens per second)
llama_perf_context_print:        eval time =   22959.47 ms /   106 runs   (  216.60 ms per token,     4.62 tokens per second)
llama_perf_context_print:        eval time =   22959.47 ms /   106 runs   (  216.60 ms per token,     4.62 tokens per second)
llama_perf_context_print:       total time =   72064.38 ms /   304 tokens
llama_perf_context_print:       total time =   72064.38 ms /   304 tokens
INFO 05/04/2025 12:17:05 AM UTC E-mail parsing finished: 251fe82e-08d3-4cdf-9e52-9c933b17496c
INFO 05/04/2025 12:17:05 AM UTC E-mail parsing finished: 251fe82e-08d3-4cdf-9e52-9c933b17496c
INFO 05/04/2025 12:17:05 AM UTC New e-mail: 35bb0d2e-ce88-4432-9731-87150bef1d94
INFO 05/04/2025 12:17:05 AM UTC New e-mail: 35bb0d2e-ce88-4432-9731-87150bef1d94
Llama.generate: 489 prefix-match hit, remaining 303 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 303 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   47153.11 ms /   303 tokens (  155.62 ms per token,     6.43 tokens per second)
llama_perf_context_print: prompt eval time =   47153.11 ms /   303 tokens (  155.62 ms per token,     6.43 tokens per second)
llama_perf_context_print:        eval time =   22788.69 ms /    94 runs   (  242.43 ms per token,     4.12 tokens per second)
llama_perf_context_print:        eval time =   22788.69 ms /    94 runs   (  242.43 ms per token,     4.12 tokens per second)
llama_perf_context_print:       total time =   72132.08 ms /   397 tokens
llama_perf_context_print:       total time =   72132.08 ms /   397 tokens
INFO 05/04/2025 12:18:17 AM UTC E-mail parsing finished: 35bb0d2e-ce88-4432-9731-87150bef1d94
INFO 05/04/2025 12:18:17 AM UTC E-mail parsing finished: 35bb0d2e-ce88-4432-9731-87150bef1d94
INFO 05/04/2025 12:18:17 AM UTC New e-mail: 0d7017e5-cbfe-45d2-bad4-44df5eea21b9
INFO 05/04/2025 12:18:17 AM UTC New e-mail: 0d7017e5-cbfe-45d2-bad4-44df5eea21b9
Llama.generate: 536 prefix-match hit, remaining 298 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 298 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   46226.14 ms /   298 tokens (  155.12 ms per token,     6.45 tokens per second)
llama_perf_context_print: prompt eval time =   46226.14 ms /   298 tokens (  155.12 ms per token,     6.45 tokens per second)
llama_perf_context_print:        eval time =   23778.03 ms /    95 runs   (  250.30 ms per token,     4.00 tokens per second)
llama_perf_context_print:        eval time =   23778.03 ms /    95 runs   (  250.30 ms per token,     4.00 tokens per second)
llama_perf_context_print:       total time =   72091.26 ms /   393 tokens
llama_perf_context_print:       total time =   72091.26 ms /   393 tokens
INFO 05/04/2025 12:19:29 AM UTC E-mail parsing finished: 0d7017e5-cbfe-45d2-bad4-44df5eea21b9
INFO 05/04/2025 12:19:29 AM UTC E-mail parsing finished: 0d7017e5-cbfe-45d2-bad4-44df5eea21b9
INFO 05/04/2025 12:19:29 AM UTC New e-mail: 65c85106-e74d-4710-9af5-4136eaec9177
INFO 05/04/2025 12:19:29 AM UTC New e-mail: 65c85106-e74d-4710-9af5-4136eaec9177
Llama.generate: 536 prefix-match hit, remaining 255 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 255 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   45319.15 ms /   255 tokens (  177.72 ms per token,     5.63 tokens per second)
llama_perf_context_print: prompt eval time =   45319.15 ms /   255 tokens (  177.72 ms per token,     5.63 tokens per second)
llama_perf_context_print:        eval time =   21291.29 ms /    84 runs   (  253.47 ms per token,     3.95 tokens per second)
llama_perf_context_print:        eval time =   21291.29 ms /    84 runs   (  253.47 ms per token,     3.95 tokens per second)
llama_perf_context_print:       total time =   68489.54 ms /   339 tokens
llama_perf_context_print:       total time =   68489.54 ms /   339 tokens
INFO 05/04/2025 12:20:38 AM UTC E-mail parsing finished: 65c85106-e74d-4710-9af5-4136eaec9177
INFO 05/04/2025 12:20:38 AM UTC E-mail parsing finished: 65c85106-e74d-4710-9af5-4136eaec9177
INFO 05/04/2025 12:20:38 AM UTC New e-mail: aa71c418-161d-4c42-85a0-3c3ddd808302
INFO 05/04/2025 12:20:38 AM UTC New e-mail: aa71c418-161d-4c42-85a0-3c3ddd808302
Llama.generate: 489 prefix-match hit, remaining 394 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 394 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   46627.13 ms /   394 tokens (  118.34 ms per token,     8.45 tokens per second)
llama_perf_context_print: prompt eval time =   46627.13 ms /   394 tokens (  118.34 ms per token,     8.45 tokens per second)
llama_perf_context_print:        eval time =   18274.61 ms /    72 runs   (  253.81 ms per token,     3.94 tokens per second)
llama_perf_context_print:        eval time =   18274.61 ms /    72 runs   (  253.81 ms per token,     3.94 tokens per second)
llama_perf_context_print:       total time =   66722.65 ms /   466 tokens
llama_perf_context_print:       total time =   66722.65 ms /   466 tokens
INFO 05/04/2025 12:21:45 AM UTC E-mail parsing finished: aa71c418-161d-4c42-85a0-3c3ddd808302
INFO 05/04/2025 12:21:45 AM UTC E-mail parsing finished: aa71c418-161d-4c42-85a0-3c3ddd808302
INFO 05/04/2025 12:21:45 AM UTC New e-mail: 90bdd1fb-9f52-4eeb-ab72-7fbe7cd2b4ec
INFO 05/04/2025 12:21:45 AM UTC New e-mail: 90bdd1fb-9f52-4eeb-ab72-7fbe7cd2b4ec
Llama.generate: 538 prefix-match hit, remaining 370 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 370 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   48585.37 ms /   370 tokens (  131.31 ms per token,     7.62 tokens per second)
llama_perf_context_print: prompt eval time =   48585.37 ms /   370 tokens (  131.31 ms per token,     7.62 tokens per second)
llama_perf_context_print:        eval time =   22992.71 ms /    86 runs   (  267.36 ms per token,     3.74 tokens per second)
llama_perf_context_print:        eval time =   22992.71 ms /    86 runs   (  267.36 ms per token,     3.74 tokens per second)
llama_perf_context_print:       total time =   73560.21 ms /   456 tokens
llama_perf_context_print:       total time =   73560.21 ms /   456 tokens
INFO 05/04/2025 12:22:58 AM UTC E-mail parsing finished: 90bdd1fb-9f52-4eeb-ab72-7fbe7cd2b4ec
INFO 05/04/2025 12:22:58 AM UTC E-mail parsing finished: 90bdd1fb-9f52-4eeb-ab72-7fbe7cd2b4ec
INFO 05/04/2025 12:22:58 AM UTC New e-mail: eb4bdb0a-eb56-4fb3-b4fe-7a04f2f04b3b
INFO 05/04/2025 12:22:58 AM UTC New e-mail: eb4bdb0a-eb56-4fb3-b4fe-7a04f2f04b3b
Llama.generate: 489 prefix-match hit, remaining 596 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 596 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   89154.37 ms /   596 tokens (  149.59 ms per token,     6.69 tokens per second)
llama_perf_context_print: prompt eval time =   89154.37 ms /   596 tokens (  149.59 ms per token,     6.69 tokens per second)
llama_perf_context_print:        eval time =   22952.51 ms /    88 runs   (  260.82 ms per token,     3.83 tokens per second)
llama_perf_context_print:        eval time =   22952.51 ms /    88 runs   (  260.82 ms per token,     3.83 tokens per second)
llama_perf_context_print:       total time =  114056.91 ms /   684 tokens
llama_perf_context_print:       total time =  114056.91 ms /   684 tokens
INFO 05/04/2025 12:24:52 AM UTC E-mail parsing finished: eb4bdb0a-eb56-4fb3-b4fe-7a04f2f04b3b
INFO 05/04/2025 12:24:52 AM UTC E-mail parsing finished: eb4bdb0a-eb56-4fb3-b4fe-7a04f2f04b3b
INFO 05/04/2025 12:24:52 AM UTC New e-mail: ff727dcf-c167-4257-a11f-1c54af66629d
INFO 05/04/2025 12:24:52 AM UTC New e-mail: ff727dcf-c167-4257-a11f-1c54af66629d
Llama.generate: 489 prefix-match hit, remaining 12382 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 12382 prompt tokens to eval
ERROR 05/04/2025 12:24:52 AM UTC Unknown exception occurred
ERROR 05/04/2025 12:24:52 AM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '2042-6' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '2042-6' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '2042-6' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '2042-6' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 2042, 'tag_id': 6}, {'event_id': 2042, 'tag_id': 5}, {'event_id': 2042, 'tag_id': 2}, {'event_id': 2042, 'tag_id': 1}, {'event_id': 2042, 'tag_id': 6}]]
[parameters: [{'event_id': 2042, 'tag_id': 6}, {'event_id': 2042, 'tag_id': 5}, {'event_id': 2042, 'tag_id': 2}, {'event_id': 2042, 'tag_id': 1}, {'event_id': 2042, 'tag_id': 6}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time = 1207162.47 ms /  9483 tokens (  127.30 ms per token,     7.86 tokens per second)
llama_perf_context_print: prompt eval time = 1207162.47 ms /  9483 tokens (  127.30 ms per token,     7.86 tokens per second)
llama_perf_context_print:        eval time =     331.41 ms /     1 runs   (  331.41 ms per token,     3.02 tokens per second)
llama_perf_context_print:        eval time =     331.41 ms /     1 runs   (  331.41 ms per token,     3.02 tokens per second)
llama_perf_context_print:       total time = 1207554.24 ms /  9484 tokens
llama_perf_context_print:       total time = 1207554.24 ms /  9484 tokens
INFO 05/04/2025 12:28:18 AM UTC E-mail parsing finished: dae28d2a-39c4-462a-9b70-f75017bf8469
INFO 05/04/2025 12:28:18 AM UTC E-mail parsing finished: dae28d2a-39c4-462a-9b70-f75017bf8469
INFO 05/04/2025 12:28:18 AM UTC New e-mail: 72c6332e-30d5-4a37-92c6-763721e4c8cd
INFO 05/04/2025 12:28:18 AM UTC New e-mail: 72c6332e-30d5-4a37-92c6-763721e4c8cd
Llama.generate: 489 prefix-match hit, remaining 131 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 131 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   42600.61 ms /   131 tokens (  325.20 ms per token,     3.08 tokens per second)
llama_perf_context_print: prompt eval time =   42600.61 ms /   131 tokens (  325.20 ms per token,     3.08 tokens per second)
llama_perf_context_print:        eval time =     213.11 ms /     1 runs   (  213.11 ms per token,     4.69 tokens per second)
llama_perf_context_print:        eval time =     213.11 ms /     1 runs   (  213.11 ms per token,     4.69 tokens per second)
llama_perf_context_print:       total time =   42856.93 ms /   132 tokens
llama_perf_context_print:       total time =   42856.93 ms /   132 tokens
INFO 05/04/2025 12:29:01 AM UTC E-mail parsing finished: 72c6332e-30d5-4a37-92c6-763721e4c8cd
INFO 05/04/2025 12:29:01 AM UTC E-mail parsing finished: 72c6332e-30d5-4a37-92c6-763721e4c8cd
INFO 05/04/2025 12:29:01 AM UTC New e-mail: 20920dce-0a60-4c3f-acda-4ae461f39f40
INFO 05/04/2025 12:29:01 AM UTC New e-mail: 20920dce-0a60-4c3f-acda-4ae461f39f40
Llama.generate: 489 prefix-match hit, remaining 760 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 760 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   97620.35 ms /   760 tokens (  128.45 ms per token,     7.79 tokens per second)
llama_perf_context_print: prompt eval time =   97620.35 ms /   760 tokens (  128.45 ms per token,     7.79 tokens per second)
llama_perf_context_print:        eval time =   20675.00 ms /    87 runs   (  237.64 ms per token,     4.21 tokens per second)
llama_perf_context_print:        eval time =   20675.00 ms /    87 runs   (  237.64 ms per token,     4.21 tokens per second)
llama_perf_context_print:       total time =  120238.18 ms /   847 tokens
llama_perf_context_print:       total time =  120238.18 ms /   847 tokens
INFO 05/04/2025 12:31:01 AM UTC E-mail parsing finished: 20920dce-0a60-4c3f-acda-4ae461f39f40
INFO 05/04/2025 12:31:01 AM UTC E-mail parsing finished: 20920dce-0a60-4c3f-acda-4ae461f39f40
INFO 05/04/2025 12:31:01 AM UTC New e-mail: 3d3ad3d9-53ca-412d-9789-d3fbebfb9b39
INFO 05/04/2025 12:31:01 AM UTC New e-mail: 3d3ad3d9-53ca-412d-9789-d3fbebfb9b39
Llama.generate: 536 prefix-match hit, remaining 1068 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 1068 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  146052.81 ms /  1068 tokens (  136.75 ms per token,     7.31 tokens per second)
llama_perf_context_print: prompt eval time =  146052.81 ms /  1068 tokens (  136.75 ms per token,     7.31 tokens per second)
llama_perf_context_print:        eval time =     232.68 ms /     1 runs   (  232.68 ms per token,     4.30 tokens per second)
llama_perf_context_print:        eval time =     232.68 ms /     1 runs   (  232.68 ms per token,     4.30 tokens per second)
llama_perf_context_print:       total time =  146328.86 ms /  1069 tokens
llama_perf_context_print:       total time =  146328.86 ms /  1069 tokens
INFO 05/04/2025 12:33:28 AM UTC E-mail parsing finished: 3d3ad3d9-53ca-412d-9789-d3fbebfb9b39
INFO 05/04/2025 12:33:28 AM UTC E-mail parsing finished: 3d3ad3d9-53ca-412d-9789-d3fbebfb9b39
INFO 05/04/2025 12:33:28 AM UTC New e-mail: 30448d7d-730d-4c88-aa24-adf95cc0de8c
INFO 05/04/2025 12:33:28 AM UTC New e-mail: 30448d7d-730d-4c88-aa24-adf95cc0de8c
Llama.generate: 489 prefix-match hit, remaining 2683 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 2683 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  319204.24 ms /  2683 tokens (  118.97 ms per token,     8.41 tokens per second)
llama_perf_context_print: prompt eval time =  319204.24 ms /  2683 tokens (  118.97 ms per token,     8.41 tokens per second)
llama_perf_context_print:        eval time =   19660.44 ms /    74 runs   (  265.68 ms per token,     3.76 tokens per second)
llama_perf_context_print:        eval time =   19660.44 ms /    74 runs   (  265.68 ms per token,     3.76 tokens per second)
llama_perf_context_print:       total time =  340378.70 ms /  2757 tokens
llama_perf_context_print:       total time =  340378.70 ms /  2757 tokens
INFO 05/04/2025 12:39:08 AM UTC E-mail parsing finished: 30448d7d-730d-4c88-aa24-adf95cc0de8c
INFO 05/04/2025 12:39:08 AM UTC E-mail parsing finished: 30448d7d-730d-4c88-aa24-adf95cc0de8c
INFO 05/04/2025 12:39:08 AM UTC New e-mail: 2e4c4c94-a51e-4227-b227-5226b0b48cde
INFO 05/04/2025 12:39:08 AM UTC New e-mail: 2e4c4c94-a51e-4227-b227-5226b0b48cde
Llama.generate: 489 prefix-match hit, remaining 59 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 59 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   42324.93 ms /    59 tokens (  717.37 ms per token,     1.39 tokens per second)
llama_perf_context_print: prompt eval time =   42324.93 ms /    59 tokens (  717.37 ms per token,     1.39 tokens per second)
llama_perf_context_print:        eval time =     229.72 ms /     1 runs   (  229.72 ms per token,     4.35 tokens per second)
llama_perf_context_print:        eval time =     229.72 ms /     1 runs   (  229.72 ms per token,     4.35 tokens per second)
llama_perf_context_print:       total time =   42605.36 ms /    60 tokens
llama_perf_context_print:       total time =   42605.36 ms /    60 tokens
INFO 05/04/2025 12:39:51 AM UTC E-mail parsing finished: 2e4c4c94-a51e-4227-b227-5226b0b48cde
INFO 05/04/2025 12:39:51 AM UTC E-mail parsing finished: 2e4c4c94-a51e-4227-b227-5226b0b48cde
INFO 05/04/2025 12:39:51 AM UTC New e-mail: 48e83299-3faf-4809-9cd7-a5b60b3ea770
INFO 05/04/2025 12:39:51 AM UTC New e-mail: 48e83299-3faf-4809-9cd7-a5b60b3ea770
Llama.generate: 489 prefix-match hit, remaining 2687 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 2687 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  325497.12 ms /  2687 tokens (  121.14 ms per token,     8.26 tokens per second)
llama_perf_context_print: prompt eval time =  325497.12 ms /  2687 tokens (  121.14 ms per token,     8.26 tokens per second)
llama_perf_context_print:        eval time =   26148.87 ms /    97 runs   (  269.58 ms per token,     3.71 tokens per second)
llama_perf_context_print:        eval time =   26148.87 ms /    97 runs   (  269.58 ms per token,     3.71 tokens per second)
llama_perf_context_print:       total time =  353686.34 ms /  2784 tokens
llama_perf_context_print:       total time =  353686.34 ms /  2784 tokens
INFO 05/04/2025 12:45:44 AM UTC E-mail parsing finished: 48e83299-3faf-4809-9cd7-a5b60b3ea770
INFO 05/04/2025 12:45:44 AM UTC E-mail parsing finished: 48e83299-3faf-4809-9cd7-a5b60b3ea770
INFO 05/04/2025 12:45:44 AM UTC New e-mail: e869ddf1-4c6e-44be-a742-41fbbcb41083
INFO 05/04/2025 12:45:44 AM UTC New e-mail: e869ddf1-4c6e-44be-a742-41fbbcb41083
Llama.generate: 576 prefix-match hit, remaining 2626 prompt tokens to eval
Llama.generate: 576 prefix-match hit, remaining 2626 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time = 1517964.78 ms / 12382 tokens (  122.59 ms per token,     8.16 tokens per second)
llama_perf_context_print: prompt eval time = 1517964.78 ms / 12382 tokens (  122.59 ms per token,     8.16 tokens per second)
llama_perf_context_print:        eval time =     387.06 ms /     1 runs   (  387.06 ms per token,     2.58 tokens per second)
llama_perf_context_print:        eval time =     387.06 ms /     1 runs   (  387.06 ms per token,     2.58 tokens per second)
llama_perf_context_print:       total time = 1518413.17 ms / 12383 tokens
llama_perf_context_print:       total time = 1518413.17 ms / 12383 tokens
INFO 05/04/2025 12:50:11 AM UTC E-mail parsing finished: ff727dcf-c167-4257-a11f-1c54af66629d
INFO 05/04/2025 12:50:11 AM UTC E-mail parsing finished: ff727dcf-c167-4257-a11f-1c54af66629d
INFO 05/04/2025 12:50:11 AM UTC New e-mail: 3caade69-ae5a-4c74-853c-fd988a1a295b
INFO 05/04/2025 12:50:11 AM UTC New e-mail: 3caade69-ae5a-4c74-853c-fd988a1a295b
Llama.generate: 489 prefix-match hit, remaining 356 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 356 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  319382.40 ms /  2626 tokens (  121.62 ms per token,     8.22 tokens per second)
llama_perf_context_print: prompt eval time =  319382.40 ms /  2626 tokens (  121.62 ms per token,     8.22 tokens per second)
llama_perf_context_print:        eval time =   13563.87 ms /    72 runs   (  188.39 ms per token,     5.31 tokens per second)
llama_perf_context_print:        eval time =   13563.87 ms /    72 runs   (  188.39 ms per token,     5.31 tokens per second)
llama_perf_context_print:       total time =  334456.64 ms /  2698 tokens
llama_perf_context_print:       total time =  334456.64 ms /  2698 tokens
INFO 05/04/2025 12:51:19 AM UTC E-mail parsing finished: e869ddf1-4c6e-44be-a742-41fbbcb41083
INFO 05/04/2025 12:51:19 AM UTC E-mail parsing finished: e869ddf1-4c6e-44be-a742-41fbbcb41083
INFO 05/04/2025 12:51:19 AM UTC New e-mail: 979ab4da-d4b3-457e-9e49-215b973d85a3
INFO 05/04/2025 12:51:19 AM UTC New e-mail: 979ab4da-d4b3-457e-9e49-215b973d85a3
Llama.generate: 489 prefix-match hit, remaining 339 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 339 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   48626.19 ms /   356 tokens (  136.59 ms per token,     7.32 tokens per second)
llama_perf_context_print: prompt eval time =   48626.19 ms /   356 tokens (  136.59 ms per token,     7.32 tokens per second)
llama_perf_context_print:        eval time =   64022.01 ms /   285 runs   (  224.64 ms per token,     4.45 tokens per second)
llama_perf_context_print:        eval time =   64022.01 ms /   285 runs   (  224.64 ms per token,     4.45 tokens per second)
llama_perf_context_print:       total time =  119368.52 ms /   641 tokens
llama_perf_context_print:       total time =  119368.52 ms /   641 tokens
INFO 05/04/2025 12:52:10 AM UTC E-mail parsing finished: 3caade69-ae5a-4c74-853c-fd988a1a295b
INFO 05/04/2025 12:52:10 AM UTC E-mail parsing finished: 3caade69-ae5a-4c74-853c-fd988a1a295b
INFO 05/04/2025 12:52:10 AM UTC New e-mail: e1da5805-acdb-4bc1-990f-d454d938aa11
INFO 05/04/2025 12:52:10 AM UTC New e-mail: e1da5805-acdb-4bc1-990f-d454d938aa11
Llama.generate: 536 prefix-match hit, remaining 258 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 258 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   72119.77 ms /   339 tokens (  212.74 ms per token,     4.70 tokens per second)
llama_perf_context_print: prompt eval time =   72119.77 ms /   339 tokens (  212.74 ms per token,     4.70 tokens per second)
llama_perf_context_print:        eval time =   32763.64 ms /   145 runs   (  225.96 ms per token,     4.43 tokens per second)
llama_perf_context_print:        eval time =   32763.64 ms /   145 runs   (  225.96 ms per token,     4.43 tokens per second)
llama_perf_context_print:       total time =  108149.61 ms /   484 tokens
llama_perf_context_print:       total time =  108149.61 ms /   484 tokens
INFO 05/04/2025 12:53:07 AM UTC E-mail parsing finished: 979ab4da-d4b3-457e-9e49-215b973d85a3
INFO 05/04/2025 12:53:07 AM UTC E-mail parsing finished: 979ab4da-d4b3-457e-9e49-215b973d85a3
INFO 05/04/2025 12:53:07 AM UTC New e-mail: 3386a205-2a2b-4b5e-b64c-15df853c5220
INFO 05/04/2025 12:53:07 AM UTC New e-mail: 3386a205-2a2b-4b5e-b64c-15df853c5220
Llama.generate: 536 prefix-match hit, remaining 258 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 258 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   61173.99 ms /   258 tokens (  237.11 ms per token,     4.22 tokens per second)
llama_perf_context_print: prompt eval time =   61173.99 ms /   258 tokens (  237.11 ms per token,     4.22 tokens per second)
llama_perf_context_print:        eval time =   19002.85 ms /    74 runs   (  256.80 ms per token,     3.89 tokens per second)
llama_perf_context_print:        eval time =   19002.85 ms /    74 runs   (  256.80 ms per token,     3.89 tokens per second)
llama_perf_context_print:       total time =   81827.54 ms /   332 tokens
llama_perf_context_print:       total time =   81827.54 ms /   332 tokens
INFO 05/04/2025 12:53:32 AM UTC E-mail parsing finished: e1da5805-acdb-4bc1-990f-d454d938aa11
INFO 05/04/2025 12:53:32 AM UTC E-mail parsing finished: e1da5805-acdb-4bc1-990f-d454d938aa11
INFO 05/04/2025 12:53:32 AM UTC New e-mail: 348275fc-3586-40d9-8a88-95971938f1e6
INFO 05/04/2025 12:53:32 AM UTC New e-mail: 348275fc-3586-40d9-8a88-95971938f1e6
Llama.generate: 489 prefix-match hit, remaining 206 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 206 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   55181.57 ms /   258 tokens (  213.88 ms per token,     4.68 tokens per second)
llama_perf_context_print: prompt eval time =   55181.57 ms /   258 tokens (  213.88 ms per token,     4.68 tokens per second)
llama_perf_context_print:        eval time =   16360.70 ms /    76 runs   (  215.27 ms per token,     4.65 tokens per second)
llama_perf_context_print:        eval time =   16360.70 ms /    76 runs   (  215.27 ms per token,     4.65 tokens per second)
llama_perf_context_print:       total time =   73288.74 ms /   334 tokens
llama_perf_context_print:       total time =   73288.74 ms /   334 tokens
INFO 05/04/2025 12:54:20 AM UTC E-mail parsing finished: 3386a205-2a2b-4b5e-b64c-15df853c5220
INFO 05/04/2025 12:54:20 AM UTC E-mail parsing finished: 3386a205-2a2b-4b5e-b64c-15df853c5220
INFO 05/04/2025 12:54:20 AM UTC New e-mail: bf4c5179-513d-4d87-8e75-0bf5b971fe06
INFO 05/04/2025 12:54:20 AM UTC New e-mail: bf4c5179-513d-4d87-8e75-0bf5b971fe06
Llama.generate: 489 prefix-match hit, remaining 717 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 717 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   53758.02 ms /   206 tokens (  260.96 ms per token,     3.83 tokens per second)
llama_perf_context_print: prompt eval time =   53758.02 ms /   206 tokens (  260.96 ms per token,     3.83 tokens per second)
llama_perf_context_print:        eval time =     285.58 ms /     1 runs   (  285.58 ms per token,     3.50 tokens per second)
llama_perf_context_print:        eval time =     285.58 ms /     1 runs   (  285.58 ms per token,     3.50 tokens per second)
llama_perf_context_print:       total time =   54114.66 ms /   207 tokens
llama_perf_context_print:       total time =   54114.66 ms /   207 tokens
INFO 05/04/2025 12:54:26 AM UTC E-mail parsing finished: 348275fc-3586-40d9-8a88-95971938f1e6
INFO 05/04/2025 12:54:26 AM UTC E-mail parsing finished: 348275fc-3586-40d9-8a88-95971938f1e6
INFO 05/04/2025 12:54:26 AM UTC New e-mail: b4830cd0-d604-488d-af22-7554301a93e3
INFO 05/04/2025 12:54:26 AM UTC New e-mail: b4830cd0-d604-488d-af22-7554301a93e3
Llama.generate: 489 prefix-match hit, remaining 359 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 359 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   47170.38 ms /   359 tokens (  131.39 ms per token,     7.61 tokens per second)
llama_perf_context_print: prompt eval time =   47170.38 ms /   359 tokens (  131.39 ms per token,     7.61 tokens per second)
llama_perf_context_print:        eval time =     263.81 ms /     1 runs   (  263.81 ms per token,     3.79 tokens per second)
llama_perf_context_print:        eval time =     263.81 ms /     1 runs   (  263.81 ms per token,     3.79 tokens per second)
llama_perf_context_print:       total time =   47493.62 ms /   360 tokens
llama_perf_context_print:       total time =   47493.62 ms /   360 tokens
INFO 05/04/2025 12:55:13 AM UTC E-mail parsing finished: b4830cd0-d604-488d-af22-7554301a93e3
INFO 05/04/2025 12:55:13 AM UTC E-mail parsing finished: b4830cd0-d604-488d-af22-7554301a93e3
INFO 05/04/2025 12:55:13 AM UTC New e-mail: 4fa133b4-9833-4f31-aa59-f7eff36e5c9a
INFO 05/04/2025 12:55:13 AM UTC New e-mail: 4fa133b4-9833-4f31-aa59-f7eff36e5c9a
Llama.generate: 489 prefix-match hit, remaining 265 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 265 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   50560.07 ms /   265 tokens (  190.79 ms per token,     5.24 tokens per second)
llama_perf_context_print: prompt eval time =   50560.07 ms /   265 tokens (  190.79 ms per token,     5.24 tokens per second)
llama_perf_context_print:        eval time =     193.43 ms /     1 runs   (  193.43 ms per token,     5.17 tokens per second)
llama_perf_context_print:        eval time =     193.43 ms /     1 runs   (  193.43 ms per token,     5.17 tokens per second)
llama_perf_context_print:       total time =   50793.70 ms /   266 tokens
llama_perf_context_print:       total time =   50793.70 ms /   266 tokens
INFO 05/04/2025 12:56:04 AM UTC E-mail parsing finished: 4fa133b4-9833-4f31-aa59-f7eff36e5c9a
INFO 05/04/2025 12:56:04 AM UTC E-mail parsing finished: 4fa133b4-9833-4f31-aa59-f7eff36e5c9a
INFO 05/04/2025 12:56:04 AM UTC New e-mail: eced9b3e-b05e-4d71-94a1-a4b9bf635c2b
INFO 05/04/2025 12:56:04 AM UTC New e-mail: eced9b3e-b05e-4d71-94a1-a4b9bf635c2b
Llama.generate: 489 prefix-match hit, remaining 302 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 302 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   95649.86 ms /   717 tokens (  133.40 ms per token,     7.50 tokens per second)
llama_perf_context_print: prompt eval time =   95649.86 ms /   717 tokens (  133.40 ms per token,     7.50 tokens per second)
llama_perf_context_print:        eval time =   25660.47 ms /   114 runs   (  225.09 ms per token,     4.44 tokens per second)
llama_perf_context_print:        eval time =   25660.47 ms /   114 runs   (  225.09 ms per token,     4.44 tokens per second)
llama_perf_context_print:       total time =  124007.80 ms /   831 tokens
llama_perf_context_print:       total time =  124007.80 ms /   831 tokens
INFO 05/04/2025 12:56:24 AM UTC E-mail parsing finished: bf4c5179-513d-4d87-8e75-0bf5b971fe06
INFO 05/04/2025 12:56:24 AM UTC E-mail parsing finished: bf4c5179-513d-4d87-8e75-0bf5b971fe06
INFO 05/04/2025 12:56:24 AM UTC New e-mail: 0ff8154f-2c25-407e-af20-a059fcdb292e
INFO 05/04/2025 12:56:24 AM UTC New e-mail: 0ff8154f-2c25-407e-af20-a059fcdb292e
Llama.generate: 531 prefix-match hit, remaining 722 prompt tokens to eval
Llama.generate: 531 prefix-match hit, remaining 722 prompt tokens to eval
ERROR 05/04/2025 12:56:24 AM UTC Unknown exception occurred
ERROR 05/04/2025 12:56:24 AM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '2054-5' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '2054-5' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '2054-5' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '2054-5' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 2054, 'tag_id': 5}, {'event_id': 2054, 'tag_id': 2}, {'event_id': 2054, 'tag_id': 1}, {'event_id': 2054, 'tag_id': 6}, {'event_id': 2054, 'tag_id': 5}]]
[parameters: [{'event_id': 2054, 'tag_id': 5}, {'event_id': 2054, 'tag_id': 2}, {'event_id': 2054, 'tag_id': 1}, {'event_id': 2054, 'tag_id': 6}, {'event_id': 2054, 'tag_id': 5}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   53079.61 ms /   302 tokens (  175.76 ms per token,     5.69 tokens per second)
llama_perf_context_print: prompt eval time =   53079.61 ms /   302 tokens (  175.76 ms per token,     5.69 tokens per second)
llama_perf_context_print:        eval time =   22822.73 ms /    85 runs   (  268.50 ms per token,     3.72 tokens per second)
llama_perf_context_print:        eval time =   22822.73 ms /    85 runs   (  268.50 ms per token,     3.72 tokens per second)
llama_perf_context_print:       total time =   77733.78 ms /   387 tokens
llama_perf_context_print:       total time =   77733.78 ms /   387 tokens
INFO 05/04/2025 12:57:22 AM UTC E-mail parsing finished: eced9b3e-b05e-4d71-94a1-a4b9bf635c2b
INFO 05/04/2025 12:57:22 AM UTC E-mail parsing finished: eced9b3e-b05e-4d71-94a1-a4b9bf635c2b
INFO 05/04/2025 12:57:22 AM UTC New e-mail: 4f7418d2-cd3a-4648-bf22-2ae26ec063b4
INFO 05/04/2025 12:57:22 AM UTC New e-mail: 4f7418d2-cd3a-4648-bf22-2ae26ec063b4
Llama.generate: 489 prefix-match hit, remaining 171 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 171 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   42619.17 ms /   171 tokens (  249.23 ms per token,     4.01 tokens per second)
llama_perf_context_print: prompt eval time =   42619.17 ms /   171 tokens (  249.23 ms per token,     4.01 tokens per second)
llama_perf_context_print:        eval time =     256.78 ms /     1 runs   (  256.78 ms per token,     3.89 tokens per second)
llama_perf_context_print:        eval time =     256.78 ms /     1 runs   (  256.78 ms per token,     3.89 tokens per second)
llama_perf_context_print:       total time =   42946.09 ms /   172 tokens
llama_perf_context_print:       total time =   42946.09 ms /   172 tokens
INFO 05/04/2025 12:58:05 AM UTC E-mail parsing finished: 4f7418d2-cd3a-4648-bf22-2ae26ec063b4
INFO 05/04/2025 12:58:05 AM UTC E-mail parsing finished: 4f7418d2-cd3a-4648-bf22-2ae26ec063b4
INFO 05/04/2025 12:58:05 AM UTC New e-mail: 56dfd294-c2a4-4d89-9918-3289a8e47a9c
INFO 05/04/2025 12:58:05 AM UTC New e-mail: 56dfd294-c2a4-4d89-9918-3289a8e47a9c
Llama.generate: 489 prefix-match hit, remaining 9400 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 9400 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  110159.06 ms /   722 tokens (  152.57 ms per token,     6.55 tokens per second)
llama_perf_context_print: prompt eval time =  110159.06 ms /   722 tokens (  152.57 ms per token,     6.55 tokens per second)
llama_perf_context_print:        eval time =   19610.29 ms /    85 runs   (  230.71 ms per token,     4.33 tokens per second)
llama_perf_context_print:        eval time =   19610.29 ms /    85 runs   (  230.71 ms per token,     4.33 tokens per second)
llama_perf_context_print:       total time =  131771.41 ms /   807 tokens
llama_perf_context_print:       total time =  131771.41 ms /   807 tokens
INFO 05/04/2025 12:58:36 AM UTC E-mail parsing finished: 0ff8154f-2c25-407e-af20-a059fcdb292e
INFO 05/04/2025 12:58:36 AM UTC E-mail parsing finished: 0ff8154f-2c25-407e-af20-a059fcdb292e
INFO 05/04/2025 12:58:36 AM UTC New e-mail: 0685acff-b14e-45d8-ba84-5cf26497783e
INFO 05/04/2025 12:58:36 AM UTC New e-mail: 0685acff-b14e-45d8-ba84-5cf26497783e
Llama.generate: 489 prefix-match hit, remaining 352 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 352 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   51629.07 ms /   352 tokens (  146.67 ms per token,     6.82 tokens per second)
llama_perf_context_print: prompt eval time =   51629.07 ms /   352 tokens (  146.67 ms per token,     6.82 tokens per second)
llama_perf_context_print:        eval time =     243.48 ms /     1 runs   (  243.48 ms per token,     4.11 tokens per second)
llama_perf_context_print:        eval time =     243.48 ms /     1 runs   (  243.48 ms per token,     4.11 tokens per second)
llama_perf_context_print:       total time =   51924.99 ms /   353 tokens
llama_perf_context_print:       total time =   51924.99 ms /   353 tokens
INFO 05/04/2025 12:59:28 AM UTC E-mail parsing finished: 0685acff-b14e-45d8-ba84-5cf26497783e
INFO 05/04/2025 12:59:28 AM UTC E-mail parsing finished: 0685acff-b14e-45d8-ba84-5cf26497783e
INFO 05/04/2025 12:59:28 AM UTC New e-mail: 772669dc-0ba9-4ec7-8ce4-314244642cb4
INFO 05/04/2025 12:59:28 AM UTC New e-mail: 772669dc-0ba9-4ec7-8ce4-314244642cb4
Llama.generate: 489 prefix-match hit, remaining 794 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 794 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   98378.30 ms /   794 tokens (  123.90 ms per token,     8.07 tokens per second)
llama_perf_context_print: prompt eval time =   98378.30 ms /   794 tokens (  123.90 ms per token,     8.07 tokens per second)
llama_perf_context_print:        eval time =   22155.84 ms /    96 runs   (  230.79 ms per token,     4.33 tokens per second)
llama_perf_context_print:        eval time =   22155.84 ms /    96 runs   (  230.79 ms per token,     4.33 tokens per second)
llama_perf_context_print:       total time =  122732.39 ms /   890 tokens
llama_perf_context_print:       total time =  122732.39 ms /   890 tokens
INFO 05/04/2025 01:01:31 AM UTC E-mail parsing finished: 772669dc-0ba9-4ec7-8ce4-314244642cb4
INFO 05/04/2025 01:01:31 AM UTC E-mail parsing finished: 772669dc-0ba9-4ec7-8ce4-314244642cb4
INFO 05/04/2025 01:01:31 AM UTC New e-mail: 6022c1ab-43c0-4582-94f0-8d581a6e7d78
INFO 05/04/2025 01:01:31 AM UTC New e-mail: 6022c1ab-43c0-4582-94f0-8d581a6e7d78
Llama.generate: 529 prefix-match hit, remaining 713 prompt tokens to eval
Llama.generate: 529 prefix-match hit, remaining 713 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  100450.03 ms /   713 tokens (  140.88 ms per token,     7.10 tokens per second)
llama_perf_context_print: prompt eval time =  100450.03 ms /   713 tokens (  140.88 ms per token,     7.10 tokens per second)
llama_perf_context_print:        eval time =   22603.23 ms /    95 runs   (  237.93 ms per token,     4.20 tokens per second)
llama_perf_context_print:        eval time =   22603.23 ms /    95 runs   (  237.93 ms per token,     4.20 tokens per second)
llama_perf_context_print:       total time =  125367.06 ms /   808 tokens
llama_perf_context_print:       total time =  125367.06 ms /   808 tokens
INFO 05/04/2025 01:03:36 AM UTC E-mail parsing finished: 6022c1ab-43c0-4582-94f0-8d581a6e7d78
INFO 05/04/2025 01:03:36 AM UTC E-mail parsing finished: 6022c1ab-43c0-4582-94f0-8d581a6e7d78
INFO 05/04/2025 01:03:36 AM UTC New e-mail: d864c480-d0b0-4f9e-b2fb-ba471754723b
INFO 05/04/2025 01:03:36 AM UTC New e-mail: d864c480-d0b0-4f9e-b2fb-ba471754723b
Llama.generate: 489 prefix-match hit, remaining 715 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 715 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   98836.56 ms /   715 tokens (  138.23 ms per token,     7.23 tokens per second)
llama_perf_context_print: prompt eval time =   98836.56 ms /   715 tokens (  138.23 ms per token,     7.23 tokens per second)
llama_perf_context_print:        eval time =   19516.08 ms /    83 runs   (  235.13 ms per token,     4.25 tokens per second)
llama_perf_context_print:        eval time =   19516.08 ms /    83 runs   (  235.13 ms per token,     4.25 tokens per second)
llama_perf_context_print:       total time =  120268.54 ms /   798 tokens
llama_perf_context_print:       total time =  120268.54 ms /   798 tokens
INFO 05/04/2025 01:05:36 AM UTC E-mail parsing finished: d864c480-d0b0-4f9e-b2fb-ba471754723b
INFO 05/04/2025 01:05:36 AM UTC E-mail parsing finished: d864c480-d0b0-4f9e-b2fb-ba471754723b
INFO 05/04/2025 01:05:37 AM UTC New e-mail: f24ca517-0232-4d08-b5c1-c3b5907e25e3
INFO 05/04/2025 01:05:37 AM UTC New e-mail: f24ca517-0232-4d08-b5c1-c3b5907e25e3
Llama.generate: 489 prefix-match hit, remaining 1751 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 1751 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  211045.70 ms /  1751 tokens (  120.53 ms per token,     8.30 tokens per second)
llama_perf_context_print: prompt eval time =  211045.70 ms /  1751 tokens (  120.53 ms per token,     8.30 tokens per second)
llama_perf_context_print:        eval time =   12419.44 ms /    50 runs   (  248.39 ms per token,     4.03 tokens per second)
llama_perf_context_print:        eval time =   12419.44 ms /    50 runs   (  248.39 ms per token,     4.03 tokens per second)
llama_perf_context_print:       total time =  224431.59 ms /  1801 tokens
llama_perf_context_print:       total time =  224431.59 ms /  1801 tokens
INFO 05/04/2025 01:09:21 AM UTC E-mail parsing finished: f24ca517-0232-4d08-b5c1-c3b5907e25e3
INFO 05/04/2025 01:09:21 AM UTC E-mail parsing finished: f24ca517-0232-4d08-b5c1-c3b5907e25e3
WARNING 05/04/2025 01:09:21 AM UTC Events from an email rejected due to data validation errors
WARNING 05/04/2025 01:09:21 AM UTC Events from an email rejected due to data validation errors
Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 151, in _on_new_events
  File "/app/modules/validator.py", line 151, in _on_new_events
    data: NewEvents = NewEvents.model_validate_json(body)
    data: NewEvents = NewEvents.model_validate_json(body)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
events.0.start_date
events.0.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
INFO 05/04/2025 01:09:21 AM UTC New e-mail: 707819f7-ccec-475b-8053-9bb0eba51a73
INFO 05/04/2025 01:09:21 AM UTC New e-mail: 707819f7-ccec-475b-8053-9bb0eba51a73
Llama.generate: 489 prefix-match hit, remaining 328 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 328 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   49701.05 ms /   328 tokens (  151.53 ms per token,     6.60 tokens per second)
llama_perf_context_print: prompt eval time =   49701.05 ms /   328 tokens (  151.53 ms per token,     6.60 tokens per second)
llama_perf_context_print:        eval time =   18099.94 ms /    79 runs   (  229.11 ms per token,     4.36 tokens per second)
llama_perf_context_print:        eval time =   18099.94 ms /    79 runs   (  229.11 ms per token,     4.36 tokens per second)
llama_perf_context_print:       total time =   69657.82 ms /   407 tokens
llama_perf_context_print:       total time =   69657.82 ms /   407 tokens
INFO 05/04/2025 01:10:31 AM UTC E-mail parsing finished: 707819f7-ccec-475b-8053-9bb0eba51a73
INFO 05/04/2025 01:10:31 AM UTC E-mail parsing finished: 707819f7-ccec-475b-8053-9bb0eba51a73
INFO 05/04/2025 01:10:31 AM UTC New e-mail: 48550655-cc6f-45e4-a168-3558949b16e4
INFO 05/04/2025 01:10:31 AM UTC New e-mail: 48550655-cc6f-45e4-a168-3558949b16e4
Llama.generate: 536 prefix-match hit, remaining 258 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 258 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   46946.53 ms /   258 tokens (  181.96 ms per token,     5.50 tokens per second)
llama_perf_context_print: prompt eval time =   46946.53 ms /   258 tokens (  181.96 ms per token,     5.50 tokens per second)
llama_perf_context_print:        eval time =   16927.22 ms /    74 runs   (  228.75 ms per token,     4.37 tokens per second)
llama_perf_context_print:        eval time =   16927.22 ms /    74 runs   (  228.75 ms per token,     4.37 tokens per second)
llama_perf_context_print:       total time =   65595.10 ms /   332 tokens
llama_perf_context_print:       total time =   65595.10 ms /   332 tokens
INFO 05/04/2025 01:11:36 AM UTC E-mail parsing finished: 48550655-cc6f-45e4-a168-3558949b16e4
INFO 05/04/2025 01:11:36 AM UTC E-mail parsing finished: 48550655-cc6f-45e4-a168-3558949b16e4
INFO 05/04/2025 01:11:36 AM UTC New e-mail: 1cef1334-57b0-43f8-9fbd-78e0a1b46450
INFO 05/04/2025 01:11:36 AM UTC New e-mail: 1cef1334-57b0-43f8-9fbd-78e0a1b46450
Llama.generate: 542 prefix-match hit, remaining 252 prompt tokens to eval
Llama.generate: 542 prefix-match hit, remaining 252 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   45747.36 ms /   252 tokens (  181.54 ms per token,     5.51 tokens per second)
llama_perf_context_print: prompt eval time =   45747.36 ms /   252 tokens (  181.54 ms per token,     5.51 tokens per second)
llama_perf_context_print:        eval time =   17931.19 ms /    80 runs   (  224.14 ms per token,     4.46 tokens per second)
llama_perf_context_print:        eval time =   17931.19 ms /    80 runs   (  224.14 ms per token,     4.46 tokens per second)
llama_perf_context_print:       total time =   65519.04 ms /   332 tokens
llama_perf_context_print:       total time =   65519.04 ms /   332 tokens
INFO 05/04/2025 01:12:42 AM UTC E-mail parsing finished: 1cef1334-57b0-43f8-9fbd-78e0a1b46450
INFO 05/04/2025 01:12:42 AM UTC E-mail parsing finished: 1cef1334-57b0-43f8-9fbd-78e0a1b46450
INFO 05/04/2025 01:12:42 AM UTC New e-mail: 323f3963-8e7c-400d-a708-362847032423
INFO 05/04/2025 01:12:42 AM UTC New e-mail: 323f3963-8e7c-400d-a708-362847032423
Llama.generate: 538 prefix-match hit, remaining 203 prompt tokens to eval
Llama.generate: 538 prefix-match hit, remaining 203 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   47397.84 ms /   203 tokens (  233.49 ms per token,     4.28 tokens per second)
llama_perf_context_print: prompt eval time =   47397.84 ms /   203 tokens (  233.49 ms per token,     4.28 tokens per second)
llama_perf_context_print:        eval time =     211.62 ms /     1 runs   (  211.62 ms per token,     4.73 tokens per second)
llama_perf_context_print:        eval time =     211.62 ms /     1 runs   (  211.62 ms per token,     4.73 tokens per second)
llama_perf_context_print:       total time =   47651.79 ms /   204 tokens
llama_perf_context_print:       total time =   47651.79 ms /   204 tokens
INFO 05/04/2025 01:13:29 AM UTC E-mail parsing finished: 323f3963-8e7c-400d-a708-362847032423
INFO 05/04/2025 01:13:29 AM UTC E-mail parsing finished: 323f3963-8e7c-400d-a708-362847032423
INFO 05/04/2025 01:13:29 AM UTC New e-mail: 9e8f979b-4257-4310-bfee-def9bebd3157
INFO 05/04/2025 01:13:29 AM UTC New e-mail: 9e8f979b-4257-4310-bfee-def9bebd3157
Llama.generate: 489 prefix-match hit, remaining 241 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 241 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   48224.10 ms /   241 tokens (  200.10 ms per token,     5.00 tokens per second)
llama_perf_context_print: prompt eval time =   48224.10 ms /   241 tokens (  200.10 ms per token,     5.00 tokens per second)
llama_perf_context_print:        eval time =   20362.41 ms /    88 runs   (  231.39 ms per token,     4.32 tokens per second)
llama_perf_context_print:        eval time =   20362.41 ms /    88 runs   (  231.39 ms per token,     4.32 tokens per second)
llama_perf_context_print:       total time =   70512.77 ms /   329 tokens
llama_perf_context_print:       total time =   70512.77 ms /   329 tokens
INFO 05/04/2025 01:14:40 AM UTC E-mail parsing finished: 9e8f979b-4257-4310-bfee-def9bebd3157
INFO 05/04/2025 01:14:40 AM UTC E-mail parsing finished: 9e8f979b-4257-4310-bfee-def9bebd3157
INFO 05/04/2025 01:14:40 AM UTC New e-mail: ce8e87e9-feba-49e7-b307-2edeeb0e750e
INFO 05/04/2025 01:14:40 AM UTC New e-mail: ce8e87e9-feba-49e7-b307-2edeeb0e750e
Llama.generate: 489 prefix-match hit, remaining 64 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 64 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   40383.45 ms /    64 tokens (  630.99 ms per token,     1.58 tokens per second)
llama_perf_context_print: prompt eval time =   40383.45 ms /    64 tokens (  630.99 ms per token,     1.58 tokens per second)
llama_perf_context_print:        eval time =     217.31 ms /     1 runs   (  217.31 ms per token,     4.60 tokens per second)
llama_perf_context_print:        eval time =     217.31 ms /     1 runs   (  217.31 ms per token,     4.60 tokens per second)
llama_perf_context_print:       total time =   40643.62 ms /    65 tokens
llama_perf_context_print:       total time =   40643.62 ms /    65 tokens
INFO 05/04/2025 01:15:21 AM UTC E-mail parsing finished: ce8e87e9-feba-49e7-b307-2edeeb0e750e
INFO 05/04/2025 01:15:21 AM UTC E-mail parsing finished: ce8e87e9-feba-49e7-b307-2edeeb0e750e
INFO 05/04/2025 01:15:21 AM UTC New e-mail: f2227d39-7291-4436-9967-a228212cc669
INFO 05/04/2025 01:15:21 AM UTC New e-mail: f2227d39-7291-4436-9967-a228212cc669
Llama.generate: 489 prefix-match hit, remaining 659 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 659 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time = 1147836.20 ms /  9400 tokens (  122.11 ms per token,     8.19 tokens per second)
llama_perf_context_print: prompt eval time = 1147836.20 ms /  9400 tokens (  122.11 ms per token,     8.19 tokens per second)
llama_perf_context_print:        eval time =     248.13 ms /     1 runs   (  248.13 ms per token,     4.03 tokens per second)
llama_perf_context_print:        eval time =     248.13 ms /     1 runs   (  248.13 ms per token,     4.03 tokens per second)
llama_perf_context_print:       total time = 1148152.32 ms /  9401 tokens
llama_perf_context_print:       total time = 1148152.32 ms /  9401 tokens
INFO 05/04/2025 01:17:13 AM UTC E-mail parsing finished: 56dfd294-c2a4-4d89-9918-3289a8e47a9c
INFO 05/04/2025 01:17:13 AM UTC E-mail parsing finished: 56dfd294-c2a4-4d89-9918-3289a8e47a9c
INFO 05/04/2025 01:17:13 AM UTC New e-mail: e99197de-29ae-4ff9-9a63-bc2a5450efcd
INFO 05/04/2025 01:17:13 AM UTC New e-mail: e99197de-29ae-4ff9-9a63-bc2a5450efcd
Llama.generate: 489 prefix-match hit, remaining 515 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 515 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   97234.20 ms /   659 tokens (  147.55 ms per token,     6.78 tokens per second)
llama_perf_context_print: prompt eval time =   97234.20 ms /   659 tokens (  147.55 ms per token,     6.78 tokens per second)
llama_perf_context_print:        eval time =   24254.38 ms /   109 runs   (  222.52 ms per token,     4.49 tokens per second)
llama_perf_context_print:        eval time =   24254.38 ms /   109 runs   (  222.52 ms per token,     4.49 tokens per second)
llama_perf_context_print:       total time =  124130.58 ms /   768 tokens
llama_perf_context_print:       total time =  124130.58 ms /   768 tokens
INFO 05/04/2025 01:17:25 AM UTC E-mail parsing finished: f2227d39-7291-4436-9967-a228212cc669
INFO 05/04/2025 01:17:25 AM UTC E-mail parsing finished: f2227d39-7291-4436-9967-a228212cc669
INFO 05/04/2025 01:17:25 AM UTC New e-mail: 1589373d-555a-4c86-a948-acb5e2f8b024
INFO 05/04/2025 01:17:25 AM UTC New e-mail: 1589373d-555a-4c86-a948-acb5e2f8b024
Llama.generate: 489 prefix-match hit, remaining 518 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 518 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   52475.69 ms /   515 tokens (  101.89 ms per token,     9.81 tokens per second)
llama_perf_context_print: prompt eval time =   52475.69 ms /   515 tokens (  101.89 ms per token,     9.81 tokens per second)
llama_perf_context_print:        eval time =     295.25 ms /     1 runs   (  295.25 ms per token,     3.39 tokens per second)
llama_perf_context_print:        eval time =     295.25 ms /     1 runs   (  295.25 ms per token,     3.39 tokens per second)
llama_perf_context_print:       total time =   52833.86 ms /   516 tokens
llama_perf_context_print:       total time =   52833.86 ms /   516 tokens
INFO 05/04/2025 01:18:06 AM UTC E-mail parsing finished: e99197de-29ae-4ff9-9a63-bc2a5450efcd
INFO 05/04/2025 01:18:06 AM UTC E-mail parsing finished: e99197de-29ae-4ff9-9a63-bc2a5450efcd
INFO 05/04/2025 01:18:06 AM UTC New e-mail: b9c7e3ea-d178-4e1e-acd6-449e25bc3f12
INFO 05/04/2025 01:18:06 AM UTC New e-mail: b9c7e3ea-d178-4e1e-acd6-449e25bc3f12
Llama.generate: 489 prefix-match hit, remaining 201 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 201 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   57128.21 ms /   518 tokens (  110.29 ms per token,     9.07 tokens per second)
llama_perf_context_print: prompt eval time =   57128.21 ms /   518 tokens (  110.29 ms per token,     9.07 tokens per second)
llama_perf_context_print:        eval time =   31465.91 ms /   135 runs   (  233.08 ms per token,     4.29 tokens per second)
llama_perf_context_print:        eval time =   31465.91 ms /   135 runs   (  233.08 ms per token,     4.29 tokens per second)
llama_perf_context_print:       total time =   91544.90 ms /   653 tokens
llama_perf_context_print:       total time =   91544.90 ms /   653 tokens
INFO 05/04/2025 01:18:56 AM UTC E-mail parsing finished: 1589373d-555a-4c86-a948-acb5e2f8b024
INFO 05/04/2025 01:18:56 AM UTC E-mail parsing finished: 1589373d-555a-4c86-a948-acb5e2f8b024
INFO 05/04/2025 01:18:56 AM UTC New e-mail: 398093a4-578e-4221-97ec-fae95a6b9556
INFO 05/04/2025 01:18:56 AM UTC New e-mail: 398093a4-578e-4221-97ec-fae95a6b9556
Llama.generate: 489 prefix-match hit, remaining 4465 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 4465 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   60781.68 ms /   201 tokens (  302.40 ms per token,     3.31 tokens per second)
llama_perf_context_print: prompt eval time =   60781.68 ms /   201 tokens (  302.40 ms per token,     3.31 tokens per second)
llama_perf_context_print:        eval time =   16109.30 ms /    70 runs   (  230.13 ms per token,     4.35 tokens per second)
llama_perf_context_print:        eval time =   16109.30 ms /    70 runs   (  230.13 ms per token,     4.35 tokens per second)
llama_perf_context_print:       total time =   78636.95 ms /   271 tokens
llama_perf_context_print:       total time =   78636.95 ms /   271 tokens
INFO 05/04/2025 01:19:25 AM UTC E-mail parsing finished: b9c7e3ea-d178-4e1e-acd6-449e25bc3f12
INFO 05/04/2025 01:19:25 AM UTC E-mail parsing finished: b9c7e3ea-d178-4e1e-acd6-449e25bc3f12
INFO 05/04/2025 01:19:25 AM UTC New e-mail: 71ff3976-22fb-4d3c-9418-eda1c8f81456
INFO 05/04/2025 01:19:25 AM UTC New e-mail: 71ff3976-22fb-4d3c-9418-eda1c8f81456
Llama.generate: 489 prefix-match hit, remaining 603 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 603 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   87220.05 ms /   603 tokens (  144.64 ms per token,     6.91 tokens per second)
llama_perf_context_print: prompt eval time =   87220.05 ms /   603 tokens (  144.64 ms per token,     6.91 tokens per second)
llama_perf_context_print:        eval time =   53261.01 ms /   209 runs   (  254.84 ms per token,     3.92 tokens per second)
llama_perf_context_print:        eval time =   53261.01 ms /   209 runs   (  254.84 ms per token,     3.92 tokens per second)
llama_perf_context_print:       total time =  145379.21 ms /   812 tokens
llama_perf_context_print:       total time =  145379.21 ms /   812 tokens
INFO 05/04/2025 01:21:50 AM UTC E-mail parsing finished: 71ff3976-22fb-4d3c-9418-eda1c8f81456
INFO 05/04/2025 01:21:50 AM UTC E-mail parsing finished: 71ff3976-22fb-4d3c-9418-eda1c8f81456
INFO 05/04/2025 01:21:50 AM UTC New e-mail: c92a9594-0d67-4aa0-a936-b163f2b4239b
INFO 05/04/2025 01:21:50 AM UTC New e-mail: c92a9594-0d67-4aa0-a936-b163f2b4239b
Llama.generate: 536 prefix-match hit, remaining 1015 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 1015 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   98267.96 ms /  1015 tokens (   96.82 ms per token,    10.33 tokens per second)
llama_perf_context_print: prompt eval time =   98267.96 ms /  1015 tokens (   96.82 ms per token,    10.33 tokens per second)
llama_perf_context_print:        eval time =   28378.61 ms /   103 runs   (  275.52 ms per token,     3.63 tokens per second)
llama_perf_context_print:        eval time =   28378.61 ms /   103 runs   (  275.52 ms per token,     3.63 tokens per second)
llama_perf_context_print:       total time =  128879.00 ms /  1118 tokens
llama_perf_context_print:       total time =  128879.00 ms /  1118 tokens
INFO 05/04/2025 01:23:59 AM UTC E-mail parsing finished: c92a9594-0d67-4aa0-a936-b163f2b4239b
INFO 05/04/2025 01:23:59 AM UTC E-mail parsing finished: c92a9594-0d67-4aa0-a936-b163f2b4239b
INFO 05/04/2025 01:23:59 AM UTC New e-mail: 551836d5-2b96-4625-a159-5f096c2e57c6
INFO 05/04/2025 01:23:59 AM UTC New e-mail: 551836d5-2b96-4625-a159-5f096c2e57c6
Llama.generate: 489 prefix-match hit, remaining 722 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 722 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   93904.17 ms /   722 tokens (  130.06 ms per token,     7.69 tokens per second)
llama_perf_context_print: prompt eval time =   93904.17 ms /   722 tokens (  130.06 ms per token,     7.69 tokens per second)
llama_perf_context_print:        eval time =   17537.17 ms /    64 runs   (  274.02 ms per token,     3.65 tokens per second)
llama_perf_context_print:        eval time =   17537.17 ms /    64 runs   (  274.02 ms per token,     3.65 tokens per second)
llama_perf_context_print:       total time =  112882.73 ms /   786 tokens
llama_perf_context_print:       total time =  112882.73 ms /   786 tokens
INFO 05/04/2025 01:25:52 AM UTC E-mail parsing finished: 551836d5-2b96-4625-a159-5f096c2e57c6
INFO 05/04/2025 01:25:52 AM UTC E-mail parsing finished: 551836d5-2b96-4625-a159-5f096c2e57c6
INFO 05/04/2025 01:25:52 AM UTC New e-mail: 557a55a4-8935-438c-8b2b-84a36a880686
INFO 05/04/2025 01:25:52 AM UTC New e-mail: 557a55a4-8935-438c-8b2b-84a36a880686
Llama.generate: 540 prefix-match hit, remaining 720 prompt tokens to eval
Llama.generate: 540 prefix-match hit, remaining 720 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   98473.01 ms /   720 tokens (  136.77 ms per token,     7.31 tokens per second)
llama_perf_context_print: prompt eval time =   98473.01 ms /   720 tokens (  136.77 ms per token,     7.31 tokens per second)
llama_perf_context_print:        eval time =   20440.41 ms /    75 runs   (  272.54 ms per token,     3.67 tokens per second)
llama_perf_context_print:        eval time =   20440.41 ms /    75 runs   (  272.54 ms per token,     3.67 tokens per second)
llama_perf_context_print:       total time =  120523.39 ms /   795 tokens
llama_perf_context_print:       total time =  120523.39 ms /   795 tokens
INFO 05/04/2025 01:27:52 AM UTC E-mail parsing finished: 557a55a4-8935-438c-8b2b-84a36a880686
INFO 05/04/2025 01:27:52 AM UTC E-mail parsing finished: 557a55a4-8935-438c-8b2b-84a36a880686
WARNING 05/04/2025 01:27:52 AM UTC Events from an email rejected due to data validation errors
WARNING 05/04/2025 01:27:52 AM UTC Events from an email rejected due to data validation errors
Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 151, in _on_new_events
  File "/app/modules/validator.py", line 151, in _on_new_events
    data: NewEvents = NewEvents.model_validate_json(body)
    data: NewEvents = NewEvents.model_validate_json(body)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
events.0.start_date
events.0.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
INFO 05/04/2025 01:27:52 AM UTC New e-mail: 5d2361b1-8c01-43a2-8d80-011d5b93989d
INFO 05/04/2025 01:27:52 AM UTC New e-mail: 5d2361b1-8c01-43a2-8d80-011d5b93989d
Llama.generate: 540 prefix-match hit, remaining 722 prompt tokens to eval
Llama.generate: 540 prefix-match hit, remaining 722 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  553247.94 ms /  4465 tokens (  123.91 ms per token,     8.07 tokens per second)
llama_perf_context_print: prompt eval time =  553247.94 ms /  4465 tokens (  123.91 ms per token,     8.07 tokens per second)
llama_perf_context_print:        eval time =   63373.36 ms /   227 runs   (  279.18 ms per token,     3.58 tokens per second)
llama_perf_context_print:        eval time =   63373.36 ms /   227 runs   (  279.18 ms per token,     3.58 tokens per second)
llama_perf_context_print:       total time =  621391.91 ms /  4692 tokens
llama_perf_context_print:       total time =  621391.91 ms /  4692 tokens
INFO 05/04/2025 01:29:18 AM UTC E-mail parsing finished: 398093a4-578e-4221-97ec-fae95a6b9556
INFO 05/04/2025 01:29:18 AM UTC E-mail parsing finished: 398093a4-578e-4221-97ec-fae95a6b9556
INFO 05/04/2025 01:29:18 AM UTC New e-mail: 6360105a-bd22-410d-96a1-7e1ef00ee522
INFO 05/04/2025 01:29:18 AM UTC New e-mail: 6360105a-bd22-410d-96a1-7e1ef00ee522
Llama.generate: 489 prefix-match hit, remaining 721 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 721 prompt tokens to eval
ERROR 05/04/2025 01:29:18 AM UTC Unknown exception occurred
ERROR 05/04/2025 01:29:18 AM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '2074-6' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '2074-6' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '2074-6' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '2074-6' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 2074, 'tag_id': 6}, {'event_id': 2074, 'tag_id': 6}, {'event_id': 2074, 'tag_id': 6}]]
[parameters: [{'event_id': 2074, 'tag_id': 6}, {'event_id': 2074, 'tag_id': 6}, {'event_id': 2074, 'tag_id': 6}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  119550.06 ms /   722 tokens (  165.58 ms per token,     6.04 tokens per second)
llama_perf_context_print: prompt eval time =  119550.06 ms /   722 tokens (  165.58 ms per token,     6.04 tokens per second)
llama_perf_context_print:        eval time =   22224.12 ms /    93 runs   (  238.97 ms per token,     4.18 tokens per second)
llama_perf_context_print:        eval time =   22224.12 ms /    93 runs   (  238.97 ms per token,     4.18 tokens per second)
llama_perf_context_print:       total time =  143951.19 ms /   815 tokens
llama_perf_context_print:       total time =  143951.19 ms /   815 tokens
INFO 05/04/2025 01:30:16 AM UTC E-mail parsing finished: 5d2361b1-8c01-43a2-8d80-011d5b93989d
INFO 05/04/2025 01:30:16 AM UTC E-mail parsing finished: 5d2361b1-8c01-43a2-8d80-011d5b93989d
INFO 05/04/2025 01:30:16 AM UTC New e-mail: ed54876e-6f3b-4ace-b9c0-a2c8d114cf88
INFO 05/04/2025 01:30:16 AM UTC New e-mail: ed54876e-6f3b-4ace-b9c0-a2c8d114cf88
Llama.generate: 540 prefix-match hit, remaining 737 prompt tokens to eval
Llama.generate: 540 prefix-match hit, remaining 737 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  109291.58 ms /   721 tokens (  151.58 ms per token,     6.60 tokens per second)
llama_perf_context_print: prompt eval time =  109291.58 ms /   721 tokens (  151.58 ms per token,     6.60 tokens per second)
llama_perf_context_print:        eval time =   12152.20 ms /    54 runs   (  225.04 ms per token,     4.44 tokens per second)
llama_perf_context_print:        eval time =   12152.20 ms /    54 runs   (  225.04 ms per token,     4.44 tokens per second)
llama_perf_context_print:       total time =  122626.78 ms /   775 tokens
llama_perf_context_print:       total time =  122626.78 ms /   775 tokens
INFO 05/04/2025 01:31:20 AM UTC E-mail parsing finished: 6360105a-bd22-410d-96a1-7e1ef00ee522
INFO 05/04/2025 01:31:20 AM UTC E-mail parsing finished: 6360105a-bd22-410d-96a1-7e1ef00ee522
INFO 05/04/2025 01:31:20 AM UTC New e-mail: 57039773-1adf-41c9-811c-5ca3c6da9b1a
INFO 05/04/2025 01:31:20 AM UTC New e-mail: 57039773-1adf-41c9-811c-5ca3c6da9b1a
Llama.generate: 540 prefix-match hit, remaining 667 prompt tokens to eval
Llama.generate: 540 prefix-match hit, remaining 667 prompt tokens to eval
WARNING 05/04/2025 01:31:20 AM UTC Events from an email rejected due to data validation errors
WARNING 05/04/2025 01:31:20 AM UTC Events from an email rejected due to data validation errors
Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 151, in _on_new_events
  File "/app/modules/validator.py", line 151, in _on_new_events
    data: NewEvents = NewEvents.model_validate_json(body)
    data: NewEvents = NewEvents.model_validate_json(body)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
events.0.start_date
events.0.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =  100213.76 ms /   737 tokens (  135.98 ms per token,     7.35 tokens per second)
llama_perf_context_print: prompt eval time =  100213.76 ms /   737 tokens (  135.98 ms per token,     7.35 tokens per second)
llama_perf_context_print:        eval time =   17951.22 ms /    76 runs   (  236.20 ms per token,     4.23 tokens per second)
llama_perf_context_print:        eval time =   17951.22 ms /    76 runs   (  236.20 ms per token,     4.23 tokens per second)
llama_perf_context_print:       total time =  120011.47 ms /   813 tokens
llama_perf_context_print:       total time =  120011.47 ms /   813 tokens
INFO 05/04/2025 01:32:16 AM UTC E-mail parsing finished: ed54876e-6f3b-4ace-b9c0-a2c8d114cf88
INFO 05/04/2025 01:32:16 AM UTC E-mail parsing finished: ed54876e-6f3b-4ace-b9c0-a2c8d114cf88
INFO 05/04/2025 01:32:16 AM UTC New e-mail: 1ab71280-c3ef-41a3-b2b5-6d1b6472af2f
INFO 05/04/2025 01:32:16 AM UTC New e-mail: 1ab71280-c3ef-41a3-b2b5-6d1b6472af2f
Llama.generate: 540 prefix-match hit, remaining 721 prompt tokens to eval
Llama.generate: 540 prefix-match hit, remaining 721 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  107078.50 ms /   667 tokens (  160.54 ms per token,     6.23 tokens per second)
llama_perf_context_print: prompt eval time =  107078.50 ms /   667 tokens (  160.54 ms per token,     6.23 tokens per second)
llama_perf_context_print:        eval time =     214.70 ms /     1 runs   (  214.70 ms per token,     4.66 tokens per second)
llama_perf_context_print:        eval time =     214.70 ms /     1 runs   (  214.70 ms per token,     4.66 tokens per second)
llama_perf_context_print:       total time =  107339.91 ms /   668 tokens
llama_perf_context_print:       total time =  107339.91 ms /   668 tokens
INFO 05/04/2025 01:33:08 AM UTC E-mail parsing finished: 57039773-1adf-41c9-811c-5ca3c6da9b1a
INFO 05/04/2025 01:33:08 AM UTC E-mail parsing finished: 57039773-1adf-41c9-811c-5ca3c6da9b1a
INFO 05/04/2025 01:33:08 AM UTC New e-mail: e07c9e35-7a7b-40aa-af34-c5ca71ddb16f
INFO 05/04/2025 01:33:08 AM UTC New e-mail: e07c9e35-7a7b-40aa-af34-c5ca71ddb16f
Llama.generate: 489 prefix-match hit, remaining 262 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 262 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   47204.33 ms /   262 tokens (  180.17 ms per token,     5.55 tokens per second)
llama_perf_context_print: prompt eval time =   47204.33 ms /   262 tokens (  180.17 ms per token,     5.55 tokens per second)
llama_perf_context_print:        eval time =     226.70 ms /     1 runs   (  226.70 ms per token,     4.41 tokens per second)
llama_perf_context_print:        eval time =     226.70 ms /     1 runs   (  226.70 ms per token,     4.41 tokens per second)
llama_perf_context_print:       total time =   47503.13 ms /   263 tokens
llama_perf_context_print:       total time =   47503.13 ms /   263 tokens
INFO 05/04/2025 01:33:55 AM UTC E-mail parsing finished: e07c9e35-7a7b-40aa-af34-c5ca71ddb16f
INFO 05/04/2025 01:33:55 AM UTC E-mail parsing finished: e07c9e35-7a7b-40aa-af34-c5ca71ddb16f
INFO 05/04/2025 01:33:55 AM UTC New e-mail: 8f638bed-ff20-4c4f-bdad-3923bdd176e2
INFO 05/04/2025 01:33:55 AM UTC New e-mail: 8f638bed-ff20-4c4f-bdad-3923bdd176e2
Llama.generate: 540 prefix-match hit, remaining 57 prompt tokens to eval
Llama.generate: 540 prefix-match hit, remaining 57 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   92947.33 ms /   721 tokens (  128.91 ms per token,     7.76 tokens per second)
llama_perf_context_print: prompt eval time =   92947.33 ms /   721 tokens (  128.91 ms per token,     7.76 tokens per second)
llama_perf_context_print:        eval time =   18119.01 ms /    71 runs   (  255.20 ms per token,     3.92 tokens per second)
llama_perf_context_print:        eval time =   18119.01 ms /    71 runs   (  255.20 ms per token,     3.92 tokens per second)
llama_perf_context_print:       total time =  112633.97 ms /   792 tokens
llama_perf_context_print:       total time =  112633.97 ms /   792 tokens
INFO 05/04/2025 01:34:09 AM UTC E-mail parsing finished: 1ab71280-c3ef-41a3-b2b5-6d1b6472af2f
INFO 05/04/2025 01:34:09 AM UTC E-mail parsing finished: 1ab71280-c3ef-41a3-b2b5-6d1b6472af2f
WARNING 05/04/2025 01:34:09 AM UTC Events from an email rejected due to data validation errors
WARNING 05/04/2025 01:34:09 AM UTC Events from an email rejected due to data validation errors
Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 151, in _on_new_events
  File "/app/modules/validator.py", line 151, in _on_new_events
    data: NewEvents = NewEvents.model_validate_json(body)
    data: NewEvents = NewEvents.model_validate_json(body)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
  File "/usr/local/lib/python3.12/site-packages/pydantic/main.py", line 656, in model_validate_json
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
pydantic_core._pydantic_core.ValidationError: 1 validation error for NewEvents
events.0.start_date
events.0.start_date
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value='', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing
INFO 05/04/2025 01:34:09 AM UTC New e-mail: 377cc415-503b-40f5-ba3b-fc70f80353f2
INFO 05/04/2025 01:34:09 AM UTC New e-mail: 377cc415-503b-40f5-ba3b-fc70f80353f2
Llama.generate: 489 prefix-match hit, remaining 302 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 302 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   46985.98 ms /    57 tokens (  824.32 ms per token,     1.21 tokens per second)
llama_perf_context_print: prompt eval time =   46985.98 ms /    57 tokens (  824.32 ms per token,     1.21 tokens per second)
llama_perf_context_print:        eval time =     215.38 ms /     1 runs   (  215.38 ms per token,     4.64 tokens per second)
llama_perf_context_print:        eval time =     215.38 ms /     1 runs   (  215.38 ms per token,     4.64 tokens per second)
llama_perf_context_print:       total time =   47251.04 ms /    58 tokens
llama_perf_context_print:       total time =   47251.04 ms /    58 tokens
INFO 05/04/2025 01:34:43 AM UTC E-mail parsing finished: 8f638bed-ff20-4c4f-bdad-3923bdd176e2
INFO 05/04/2025 01:34:43 AM UTC E-mail parsing finished: 8f638bed-ff20-4c4f-bdad-3923bdd176e2
INFO 05/04/2025 01:34:43 AM UTC New e-mail: 5ec79cc7-5902-4bc3-8e09-442bd4429996
INFO 05/04/2025 01:34:43 AM UTC New e-mail: 5ec79cc7-5902-4bc3-8e09-442bd4429996
Llama.generate: 489 prefix-match hit, remaining 305 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 305 prompt tokens to eval
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time =   46793.81 ms /   302 tokens (  154.95 ms per token,     6.45 tokens per second)
llama_perf_context_print: prompt eval time =   46793.81 ms /   302 tokens (  154.95 ms per token,     6.45 tokens per second)
llama_perf_context_print:        eval time =   19847.98 ms /    85 runs   (  233.51 ms per token,     4.28 tokens per second)
llama_perf_context_print:        eval time =   19847.98 ms /    85 runs   (  233.51 ms per token,     4.28 tokens per second)
llama_perf_context_print:       total time =   68616.85 ms /   387 tokens
llama_perf_context_print:       total time =   68616.85 ms /   387 tokens
INFO 05/04/2025 01:35:18 AM UTC E-mail parsing finished: 377cc415-503b-40f5-ba3b-fc70f80353f2
INFO 05/04/2025 01:35:18 AM UTC E-mail parsing finished: 377cc415-503b-40f5-ba3b-fc70f80353f2
INFO 05/04/2025 01:35:18 AM UTC New e-mail: 9047e9bc-464a-45ea-a69f-2ad8211b56d1
INFO 05/04/2025 01:35:18 AM UTC New e-mail: 9047e9bc-464a-45ea-a69f-2ad8211b56d1
Llama.generate: 489 prefix-match hit, remaining 9768 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 9768 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   58031.19 ms /   305 tokens (  190.27 ms per token,     5.26 tokens per second)
llama_perf_context_print: prompt eval time =   58031.19 ms /   305 tokens (  190.27 ms per token,     5.26 tokens per second)
llama_perf_context_print:        eval time =   16612.18 ms /    76 runs   (  218.58 ms per token,     4.57 tokens per second)
llama_perf_context_print:        eval time =   16612.18 ms /    76 runs   (  218.58 ms per token,     4.57 tokens per second)
llama_perf_context_print:       total time =   76448.01 ms /   381 tokens
llama_perf_context_print:       total time =   76448.01 ms /   381 tokens
INFO 05/04/2025 01:35:59 AM UTC E-mail parsing finished: 5ec79cc7-5902-4bc3-8e09-442bd4429996
INFO 05/04/2025 01:35:59 AM UTC E-mail parsing finished: 5ec79cc7-5902-4bc3-8e09-442bd4429996
INFO 05/04/2025 01:35:59 AM UTC New e-mail: a6b2c211-2238-450b-ad00-d3fa8553694a
INFO 05/04/2025 01:35:59 AM UTC New e-mail: a6b2c211-2238-450b-ad00-d3fa8553694a
Llama.generate: 536 prefix-match hit, remaining 534 prompt tokens to eval
Llama.generate: 536 prefix-match hit, remaining 534 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   63846.30 ms /   534 tokens (  119.56 ms per token,     8.36 tokens per second)
llama_perf_context_print: prompt eval time =   63846.30 ms /   534 tokens (  119.56 ms per token,     8.36 tokens per second)
llama_perf_context_print:        eval time =   20818.61 ms /   106 runs   (  196.40 ms per token,     5.09 tokens per second)
llama_perf_context_print:        eval time =   20818.61 ms /   106 runs   (  196.40 ms per token,     5.09 tokens per second)
llama_perf_context_print:       total time =   87556.73 ms /   640 tokens
llama_perf_context_print:       total time =   87556.73 ms /   640 tokens
INFO 05/04/2025 01:37:27 AM UTC E-mail parsing finished: a6b2c211-2238-450b-ad00-d3fa8553694a
INFO 05/04/2025 01:37:27 AM UTC E-mail parsing finished: a6b2c211-2238-450b-ad00-d3fa8553694a
INFO 05/04/2025 01:37:27 AM UTC New e-mail: be8141b5-a32e-4865-9972-44ab112926e3
INFO 05/04/2025 01:37:27 AM UTC New e-mail: be8141b5-a32e-4865-9972-44ab112926e3
Llama.generate: 489 prefix-match hit, remaining 684 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 684 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  101272.98 ms /   684 tokens (  148.06 ms per token,     6.75 tokens per second)
llama_perf_context_print: prompt eval time =  101272.98 ms /   684 tokens (  148.06 ms per token,     6.75 tokens per second)
llama_perf_context_print:        eval time =   24476.71 ms /   113 runs   (  216.61 ms per token,     4.62 tokens per second)
llama_perf_context_print:        eval time =   24476.71 ms /   113 runs   (  216.61 ms per token,     4.62 tokens per second)
llama_perf_context_print:       total time =  128649.91 ms /   797 tokens
llama_perf_context_print:       total time =  128649.91 ms /   797 tokens
INFO 05/04/2025 01:39:35 AM UTC E-mail parsing finished: be8141b5-a32e-4865-9972-44ab112926e3
INFO 05/04/2025 01:39:35 AM UTC E-mail parsing finished: be8141b5-a32e-4865-9972-44ab112926e3
INFO 05/04/2025 01:39:35 AM UTC New e-mail: 0fc3a201-2f3f-4e7e-bc06-00c86c1e894e
INFO 05/04/2025 01:39:35 AM UTC New e-mail: 0fc3a201-2f3f-4e7e-bc06-00c86c1e894e
Llama.generate: 489 prefix-match hit, remaining 303 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 303 prompt tokens to eval
ERROR 05/04/2025 01:39:35 AM UTC Unknown exception occurred
ERROR 05/04/2025 01:39:35 AM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '2080-5' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '2080-5' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '2080-5' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '2080-5' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 2080, 'tag_id': 5}, {'event_id': 2080, 'tag_id': 6}, {'event_id': 2080, 'tag_id': 1}, {'event_id': 2080, 'tag_id': 5}]]
[parameters: [{'event_id': 2080, 'tag_id': 5}, {'event_id': 2080, 'tag_id': 6}, {'event_id': 2080, 'tag_id': 1}, {'event_id': 2080, 'tag_id': 5}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   51135.70 ms /   303 tokens (  168.76 ms per token,     5.93 tokens per second)
llama_perf_context_print: prompt eval time =   51135.70 ms /   303 tokens (  168.76 ms per token,     5.93 tokens per second)
llama_perf_context_print:        eval time =   18687.64 ms /    90 runs   (  207.64 ms per token,     4.82 tokens per second)
llama_perf_context_print:        eval time =   18687.64 ms /    90 runs   (  207.64 ms per token,     4.82 tokens per second)
llama_perf_context_print:       total time =   72105.83 ms /   393 tokens
llama_perf_context_print:       total time =   72105.83 ms /   393 tokens
INFO 05/04/2025 01:40:47 AM UTC E-mail parsing finished: 0fc3a201-2f3f-4e7e-bc06-00c86c1e894e
INFO 05/04/2025 01:40:47 AM UTC E-mail parsing finished: 0fc3a201-2f3f-4e7e-bc06-00c86c1e894e
INFO 05/04/2025 01:40:47 AM UTC New e-mail: 786fbaf4-fdf3-4926-ab94-89fd34dabe9c
INFO 05/04/2025 01:40:47 AM UTC New e-mail: 786fbaf4-fdf3-4926-ab94-89fd34dabe9c
Llama.generate: 489 prefix-match hit, remaining 591 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 591 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   94530.77 ms /   591 tokens (  159.95 ms per token,     6.25 tokens per second)
llama_perf_context_print: prompt eval time =   94530.77 ms /   591 tokens (  159.95 ms per token,     6.25 tokens per second)
llama_perf_context_print:        eval time =   15180.61 ms /    69 runs   (  220.01 ms per token,     4.55 tokens per second)
llama_perf_context_print:        eval time =   15180.61 ms /    69 runs   (  220.01 ms per token,     4.55 tokens per second)
llama_perf_context_print:       total time =  111333.94 ms /   660 tokens
llama_perf_context_print:       total time =  111333.94 ms /   660 tokens
INFO 05/04/2025 01:42:39 AM UTC E-mail parsing finished: 786fbaf4-fdf3-4926-ab94-89fd34dabe9c
INFO 05/04/2025 01:42:39 AM UTC E-mail parsing finished: 786fbaf4-fdf3-4926-ab94-89fd34dabe9c
INFO 05/04/2025 01:42:39 AM UTC New e-mail: 924c39c9-edfa-4cae-85fb-a1e0e756c466
INFO 05/04/2025 01:42:39 AM UTC New e-mail: 924c39c9-edfa-4cae-85fb-a1e0e756c466
Llama.generate: 489 prefix-match hit, remaining 85 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 85 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   43258.19 ms /    85 tokens (  508.92 ms per token,     1.96 tokens per second)
llama_perf_context_print: prompt eval time =   43258.19 ms /    85 tokens (  508.92 ms per token,     1.96 tokens per second)
llama_perf_context_print:        eval time =     204.23 ms /     1 runs   (  204.23 ms per token,     4.90 tokens per second)
llama_perf_context_print:        eval time =     204.23 ms /     1 runs   (  204.23 ms per token,     4.90 tokens per second)
llama_perf_context_print:       total time =   43503.04 ms /    86 tokens
llama_perf_context_print:       total time =   43503.04 ms /    86 tokens
INFO 05/04/2025 01:43:22 AM UTC E-mail parsing finished: 924c39c9-edfa-4cae-85fb-a1e0e756c466
INFO 05/04/2025 01:43:22 AM UTC E-mail parsing finished: 924c39c9-edfa-4cae-85fb-a1e0e756c466
INFO 05/04/2025 01:43:22 AM UTC New e-mail: 92887f65-4117-4589-a14b-3ea03e0f4c76
INFO 05/04/2025 01:43:22 AM UTC New e-mail: 92887f65-4117-4589-a14b-3ea03e0f4c76
Llama.generate: 489 prefix-match hit, remaining 737 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 737 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  100124.43 ms /   737 tokens (  135.85 ms per token,     7.36 tokens per second)
llama_perf_context_print: prompt eval time =  100124.43 ms /   737 tokens (  135.85 ms per token,     7.36 tokens per second)
llama_perf_context_print:        eval time =   13892.20 ms /    64 runs   (  217.07 ms per token,     4.61 tokens per second)
llama_perf_context_print:        eval time =   13892.20 ms /    64 runs   (  217.07 ms per token,     4.61 tokens per second)
llama_perf_context_print:       total time =  115485.82 ms /   801 tokens
llama_perf_context_print:       total time =  115485.82 ms /   801 tokens
INFO 05/04/2025 01:45:18 AM UTC E-mail parsing finished: 92887f65-4117-4589-a14b-3ea03e0f4c76
INFO 05/04/2025 01:45:18 AM UTC E-mail parsing finished: 92887f65-4117-4589-a14b-3ea03e0f4c76
INFO 05/04/2025 01:45:18 AM UTC New e-mail: 1b7ff33c-8385-455f-80ce-2cf94bd6823c
INFO 05/04/2025 01:45:18 AM UTC New e-mail: 1b7ff33c-8385-455f-80ce-2cf94bd6823c
Llama.generate: 540 prefix-match hit, remaining 743 prompt tokens to eval
Llama.generate: 540 prefix-match hit, remaining 743 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  103333.55 ms /   743 tokens (  139.08 ms per token,     7.19 tokens per second)
llama_perf_context_print: prompt eval time =  103333.55 ms /   743 tokens (  139.08 ms per token,     7.19 tokens per second)
llama_perf_context_print:        eval time =   15650.36 ms /    71 runs   (  220.43 ms per token,     4.54 tokens per second)
llama_perf_context_print:        eval time =   15650.36 ms /    71 runs   (  220.43 ms per token,     4.54 tokens per second)
llama_perf_context_print:       total time =  120540.40 ms /   814 tokens
llama_perf_context_print:       total time =  120540.40 ms /   814 tokens
INFO 05/04/2025 01:47:18 AM UTC E-mail parsing finished: 1b7ff33c-8385-455f-80ce-2cf94bd6823c
INFO 05/04/2025 01:47:18 AM UTC E-mail parsing finished: 1b7ff33c-8385-455f-80ce-2cf94bd6823c
INFO 05/04/2025 01:47:18 AM UTC New e-mail: 8d21367b-5df9-404c-8222-a4e664d2488f
INFO 05/04/2025 01:47:18 AM UTC New e-mail: 8d21367b-5df9-404c-8222-a4e664d2488f
Llama.generate: 489 prefix-match hit, remaining 818 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 818 prompt tokens to eval
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =  100610.37 ms /   818 tokens (  123.00 ms per token,     8.13 tokens per second)
llama_perf_context_print: prompt eval time =  100610.37 ms /   818 tokens (  123.00 ms per token,     8.13 tokens per second)
llama_perf_context_print:        eval time =   26893.44 ms /   116 runs   (  231.84 ms per token,     4.31 tokens per second)
llama_perf_context_print:        eval time =   26893.44 ms /   116 runs   (  231.84 ms per token,     4.31 tokens per second)
llama_perf_context_print:       total time =  130234.98 ms /   934 tokens
llama_perf_context_print:       total time =  130234.98 ms /   934 tokens
INFO 05/04/2025 01:49:29 AM UTC E-mail parsing finished: 8d21367b-5df9-404c-8222-a4e664d2488f
INFO 05/04/2025 01:49:29 AM UTC E-mail parsing finished: 8d21367b-5df9-404c-8222-a4e664d2488f
INFO 05/04/2025 01:49:29 AM UTC New e-mail: b6c38b8a-9acf-430e-a39e-c560f210e109
INFO 05/04/2025 01:49:29 AM UTC New e-mail: b6c38b8a-9acf-430e-a39e-c560f210e109
Llama.generate: 489 prefix-match hit, remaining 769 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 769 prompt tokens to eval
ERROR 05/04/2025 01:49:29 AM UTC Unknown exception occurred
ERROR 05/04/2025 01:49:29 AM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '2085-5' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '2085-5' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '2085-5' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '2085-5' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 2085, 'tag_id': 5}, {'event_id': 2085, 'tag_id': 6}, {'event_id': 2085, 'tag_id': 5}, {'event_id': 2085, 'tag_id': 3}, {'event_id': 2085, 'tag_id': 9}]]
[parameters: [{'event_id': 2085, 'tag_id': 5}, {'event_id': 2085, 'tag_id': 6}, {'event_id': 2085, 'tag_id': 5}, {'event_id': 2085, 'tag_id': 3}, {'event_id': 2085, 'tag_id': 9}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   98547.79 ms /   769 tokens (  128.15 ms per token,     7.80 tokens per second)
llama_perf_context_print: prompt eval time =   98547.79 ms /   769 tokens (  128.15 ms per token,     7.80 tokens per second)
llama_perf_context_print:        eval time =   18506.81 ms /    82 runs   (  225.69 ms per token,     4.43 tokens per second)
llama_perf_context_print:        eval time =   18506.81 ms /    82 runs   (  225.69 ms per token,     4.43 tokens per second)
llama_perf_context_print:       total time =  118885.16 ms /   851 tokens
llama_perf_context_print:       total time =  118885.16 ms /   851 tokens
INFO 05/04/2025 01:51:27 AM UTC E-mail parsing finished: b6c38b8a-9acf-430e-a39e-c560f210e109
INFO 05/04/2025 01:51:27 AM UTC E-mail parsing finished: b6c38b8a-9acf-430e-a39e-c560f210e109
INFO 05/04/2025 01:51:27 AM UTC New e-mail: c826acd5-e89e-48be-a899-2ca1560ad904
INFO 05/04/2025 01:51:27 AM UTC New e-mail: c826acd5-e89e-48be-a899-2ca1560ad904
Llama.generate: 489 prefix-match hit, remaining 302 prompt tokens to eval
Llama.generate: 489 prefix-match hit, remaining 302 prompt tokens to eval
ERROR 05/04/2025 01:51:27 AM UTC Unknown exception occurred
ERROR 05/04/2025 01:51:27 AM UTC Unknown exception occurred
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '2086-5' for key 'tags_to_events.PRIMARY'")
pymysql.err.IntegrityError: (1062, "Duplicate entry '2086-5' for key 'tags_to_events.PRIMARY'")


The above exception was the direct cause of the following exception:
The above exception was the direct cause of the following exception:


Traceback (most recent call last):
Traceback (most recent call last):
  File "/app/modules/validator.py", line 158, in _on_new_events
  File "/app/modules/validator.py", line 158, in _on_new_events
    self.add_events_to_db(data)
    self.add_events_to_db(data)
  File "/app/modules/validator.py", line 144, in add_events_to_db
  File "/app/modules/validator.py", line 144, in add_events_to_db
    db_session.commit()
    db_session.commit()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2028, in commit
    trans.commit(_to_root=True)
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    self.session.flush()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4352, in flush
    self._flush(objects)
    self._flush(objects)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4487, in _flush
    with util.safe_reraise():
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
         ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4448, in _flush
    flush_context.execute()
    flush_context.execute()
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    rec.execute(self)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 591, in execute
    self.dependency_processor.process_saves(uow, states)
    self.dependency_processor.process_saves(uow, states)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1197, in process_saves
    self._run_crud(
    self._run_crud(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/dependency.py", line 1260, in _run_crud
    connection.execute(statement, secondary_insert)
    connection.execute(statement, secondary_insert)
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
    return meth(
           ^^^^^
           ^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1936, in _exec_single_context
    self.dialect.do_executemany(
    self.dialect.do_executemany(
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
  File "/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 170, in do_executemany
    rowcount = cursor.executemany(statement, parameters)
    rowcount = cursor.executemany(statement, parameters)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 182, in executemany
    return self._do_execute_many(
    return self._do_execute_many(
           ^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 220, in _do_execute_many
    rows += self.execute(sql + postfix)
    rows += self.execute(sql + postfix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
  File "/usr/local/lib/python3.12/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
    conn.query(q)
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
    result.read()
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
  File "/usr/local/lib/python3.12/site-packages/pymysql/connections.py", line 775, in _read_packet
    packet.raise_for_error()
    packet.raise_for_error()
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
  File "/usr/local/lib/python3.12/site-packages/pymysql/protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
  File "/usr/local/lib/python3.12/site-packages/pymysql/err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '2086-5' for key 'tags_to_events.PRIMARY'")
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '2086-5' for key 'tags_to_events.PRIMARY'")
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[SQL: INSERT INTO tags_to_events (event_id, tag_id) VALUES (%(event_id)s, %(tag_id)s)]
[parameters: [{'event_id': 2086, 'tag_id': 5}, {'event_id': 2086, 'tag_id': 6}, {'event_id': 2086, 'tag_id': 5}]]
[parameters: [{'event_id': 2086, 'tag_id': 5}, {'event_id': 2086, 'tag_id': 6}, {'event_id': 2086, 'tag_id': 5}]]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
(Background on this error at: https://sqlalche.me/e/20/gkpj)
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print:        load time =  103774.25 ms
llama_perf_context_print: prompt eval time =   50749.39 ms /   302 tokens (  168.04 ms per token,     5.95 tokens per second)
llama_perf_context_print: prompt eval time =   50749.39 ms /   302 tokens (  168.04 ms per token,     5.95 tokens per second)
llama_perf_context_print:        eval time =   16589.94 ms /    79 runs   (  210.00 ms per token,     4.76 tokens per second)
llama_perf_context_print:        eval time =   16589.94 ms /    79 runs   (  210.00 ms per token,     4.76 tokens per second)
llama_perf_context_print:       total time =   69056.04 ms /   381 tokens
llama_perf_context_print:       total time =   69056.04 ms /   381 tokens
INFO 05/04/2025 01:52:37 AM UTC E-mail parsing finished: c826acd5-e89e-48be-a899-2ca1560ad904
INFO 05/04/2025 01:52:37 AM UTC E-mail parsing finished: c826acd5-e89e-48be-a899-2ca1560ad904
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print:        load time =  167862.20 ms
llama_perf_context_print: prompt eval time = 1189645.34 ms /  9768 tokens (  121.79 ms per token,     8.21 tokens per second)
llama_perf_context_print: prompt eval time = 1189645.34 ms /  9768 tokens (  121.79 ms per token,     8.21 tokens per second)
llama_perf_context_print:        eval time =     233.88 ms /     1 runs   (  233.88 ms per token,     4.28 tokens per second)
llama_perf_context_print:        eval time =     233.88 ms /     1 runs   (  233.88 ms per token,     4.28 tokens per second)
llama_perf_context_print:       total time = 1189911.06 ms /  9769 tokens
llama_perf_context_print:       total time = 1189911.06 ms /  9769 tokens
INFO 05/04/2025 01:55:08 AM UTC E-mail parsing finished: 9047e9bc-464a-45ea-a69f-2ad8211b56d1
INFO 05/04/2025 01:55:08 AM UTC E-mail parsing finished: 9047e9bc-464a-45ea-a69f-2ad8211b56d1
